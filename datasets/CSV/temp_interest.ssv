Project#Type#File_Name#Method_Signature#v1#v1_date#v2#v2_date#version_name#CountInput_v1#CountInput_v2#CountOutput_v1#CountOutput_v2#CountLine_v1#CountLine_v2#Cyclomatic_v1#Cyclomatic_v2#MaxNesting_v1#MaxNesting_v2#Debt#Intro_ID#Intro_Comment#Remove_ID#Remove_Comment
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestEditLogTailer.java#waitForStandbyToCatchUp(NameNode,NameNode)#28dbd56de0456c3504ce2d2227a22027c5d46d52#2011-12-01 21:37:08#36d1c49486587c2dbb193e8538b1d4510c462fa6#2011-12-21 03:03:23#-1#5.0#5.0#9.0#9.0#22.0#22.0#3.0#3.0#2.0#2.0#// TODO: we should really just ask for a log roll here#28dbd56de0456c3504ce2d2227a22027c5d46d52#HDFS-2623. Add test case for hot standby capability. Contributed by Todd Lipcon.#31c91706f7d17da006ef2d6c541f8dd092fae077#HDFS-1972. Fencing mechanism for block invalidations and replications. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/AbstractINodeDiffList.java#deleteSnapshotDiff(Snapshot,BlocksMapUpdateInfo)#24d96cbcdb80a2de4ada7aa70056a481da24fcc5#2013-02-02 20:39:01#24d96cbcdb80a2de4ada7aa70056a481da24fcc5#2013-02-02 20:39:01#-1#5.0#5.0#8.0#8.0#21.0#21.0#4.0#4.0#3.0#3.0#// TODO: add a new testcase for this#24d96cbcdb80a2de4ada7aa70056a481da24fcc5#HDFS-4414. Add support for getting snapshot diff from DistributedFileSystem. Contributed by Jing Zhao.#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#HDFS-4446. Support file snapshots with diff lists.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeDirectoryWithSnapshot.java#modify(INode,INode)#00d318378e4b43d36be91b29ae3ef8a879a81e1e#2013-01-15 06:20:22#12e8ba804f9454d9bb07099e35ce7ef63c0d4e1e#2013-01-25 03:09:26#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: fix a bug that previous != oldinode.  Set it to oldinode for now#00d318378e4b43d36be91b29ae3ef8a879a81e1e#HDFS-4397. Fix a bug in INodeDirectoryWithSnapshot.Diff.combinePostDiff(..) that it may put the wrong node into the deleted list.#a3bf2083867db5d848ea14f145d120f02b820af2#HDFS-4441. Move INodeDirectoryWithSnapshot.Diff and the related classes to a package.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeDirectoryWithSnapshot.java#combinePosteriorAndCollectBlocks(INode,INodeDirectory,DirectoryDiff,BlocksMapUpdateInfo)#9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#2013-04-13 02:48:34#3a812e9f3ae66cfa525faceb5af9085a4cc37232#2013-04-24 02:11:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// use null as prior here because we are handling a reference // node stored in the created list of a snapshot diff. This  // snapshot diff must be associated with the latest snapshot of // the dst tree before the rename operation. In this scenario, // the prior snapshot should be the one created in the src tree, // and it can be identified by the cleanSubtree since we call // recordModification before the rename.#9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#HDFS-4675. Fix rename across snapshottable directories.  Contributed by Jing Zhao#0fa5cad0b27780c27a284c23101b1099d4886506#HDFS-4686. Update quota computation for rename and INodeReference.  Contributed by Jing Zhao
hadoop#DESIGN#hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/anonymization/WordListAnonymizerUtility.java#isKnownData(String,String[])#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#a9808de0d9a73a99c10a3e4290ec20778fed4f24#2012-05-08 13:20:56#-1#4.0#3.0#2.0#2.0#11.0#11.0#3.0#3.0#2.0#2.0#// check if the data is known content //TODO [Chunking] Do this for sub-strings of data#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)##
hadoop#DESIGN#src/test/core/org/apache/hadoop/conf/TestConfigurationDeprecation.java#testWasDeprecatedKeySet()#ae6721a85a233e10af18d8d87983afb0f518277a#2009-09-11 00:14:22#97c38f94f57544cdd24fb581fef10d61c7263654#2010-04-21 19:32:32#-1#1.0#1.0#7.0#7.0#19.0#19.0#1.0#1.0#0.0#0.0#// Used the deprecated key rather than the new, therefore should trigger#ae6721a85a233e10af18d8d87983afb0f518277a#HADOOP-6252. Provide a method to determine if a deprecated key is set in config file. Contributed by Jakob Homan.#67c006c322c3925b42322f6ced841a54084f582a#HADOOP-6521. User specified umask using deprecated dfs.umask must override server configured using new dfs.umaskmode for backward compatibility. Contributed by Suresh Srinivas.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/QueueManager.java#reloadAllocsIfNecessary()#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#2012-07-13 00:43:01#a0b5a0a419dfc07b7ac45c06b11b4c8dc7e79958#2015-09-29 07:55:34#-1#10.0#-1#10.0#-1#38.0#-1#7.0#-1#3.0#-1#// Throwing the error further out here won't help - the RPC thread // will catch it and report it in a loop. Instead, just log it and // hope somebody will notice from the log. // We log the error only on the first failure so we don't fill up the // JobTracker's log with these messages.#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#MAPREDUCE-3451. Port Fair Scheduler to MR2 (pwendell via tucu)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityGroupFSTimelineStore.java#reloadAllocsIfNecessary()#02f597c5db36ded385413958bdee793ad7eda40e#2016-01-17 17:37:40#d49cfb350454c2dfa2f3eb70f79b6d5030ce7bec#2016-03-10 10:51:55#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Throwing the error further out here won't help - the RPC thread // will catch it and report it in a loop. Instead, just log it and // hope somebody will notice from the log. // We log the error only on the first failure so we don't fill up the // JobTracker's log with these messages.#02f597c5db36ded385413958bdee793ad7eda40e#YARN-4265. Provide new timeline plugin storage to support fine-grained entity caching. Contributed by Li Lu and Jason Lowe##
hadoop#DESIGN#hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/datatypes/FileName.java#anonymize(String,WordList)#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#10325d97329c214bb3899c8535df5a366bc86d2f#2012-01-18 22:10:12#-1#4.0#4.0#9.0#9.0#32.0#32.0#6.0#6.0#3.0#3.0#// check if the data is known content //TODO [Chunking] Do this for sub-strings of data#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/TestContainerManager.java#testContainerSetup()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6b2f2efe4de4e709a2b9c64b7b3b3138e1939668#2011-09-12 07:11:43#-1#14.0#14.0#31.0#34.0#81.0#85.0#2.0#2.0#1.0#1.0#// Now ascertain that the resources are localised correctly. // TODO: Don't we need clusterStamp in localDir?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#MAPREDUCE-2896. Simplify all apis to in org.apache.hadoop.yarn.api.records.* to be get/set only. Added javadocs to all public records.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/TestContainerManager.java#testContainerLaunchFromPreviousRM()#fbb55784d93e1a819daf55d936e864d344579cbf#2013-04-26 03:50:20#a83fb61ac07c0468cbc7a38526e92683883dd932#2013-06-04 04:05:50#-1#12.0#7.0#25.0#16.0#71.0#59.0#3.0#3.0#1.0#1.0#// TO DO: This should be replaced to explicitly check exception // class name after YARN-142#fbb55784d93e1a819daf55d936e864d344579cbf#YARN-562. Modified NM to reject any containers allocated by a previous ResourceManager. Contributed by Jian He. MAPREDUCE-5167. Update MR App after YARN-562 to use the new builder API for the container. Contributed by Jian He.#c6c41abf683be17c3917a7f94953b55347aaa69f#YARN-737. Throw some specific exceptions directly instead of wrapping them in YarnException. Contributed by Jian He.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java#createSnapshot(String,String,FSDirectory)#820b5495caf032983f6bef2c1cd95af44ed7fa10#2012-10-21 21:35:13#b897bb8992b3ab70febbb0400c565c8141cc9038#2012-10-24 20:39:26#-1#3.0#3.0#3.0#3.0#11.0#11.0#1.0#1.0#0.0#0.0#//TODO: check ns quota#820b5495caf032983f6bef2c1cd95af44ed7fa10#HDFS-4079. Add SnapshotManager which maintains a list for all the snapshottable directories and supports snapshot methods such as setting a directory to snapshottable and creating a snapshot.#9e26fdcda7957962088f2c2bef2b3ba0324e6dd1#HDFS-4111. Support snapshot of subtrees. Contributed by Tsz Wo (Nicholas), Sze.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java#processRecursively(INodeDirectory,INodeDirectory)#9e26fdcda7957962088f2c2bef2b3ba0324e6dd1#2012-10-26 22:02:30#cbbaa93ae09bf5cf643263faf78f99315c4f3a8d#2012-12-17 03:40:27#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: support INodeFileUnderConstruction#9e26fdcda7957962088f2c2bef2b3ba0324e6dd1#HDFS-4111. Support snapshot of subtrees. Contributed by Tsz Wo (Nicholas), Sze.#b9f965de120b5278ac84a7e98aecb32aafde4c16#HDFS-4103. Support O(1) snapshot creation.
hadoop#DESIGN#hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/datatypes/JobProperties.java#getAnonymizedValue(StatePool,Configuration)#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#10325d97329c214bb3899c8535df5a366bc86d2f#2012-01-18 22:10:12#-1#4.0#4.0#11.0#11.0#41.0#41.0#7.0#7.0#4.0#4.0#//TODO Check for null key/value?#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainerLaunch.java#setNewEnvironmentHack(Map<StringString>)#c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b#2011-10-18 01:22:14#0b101bd7e875ee5597ddb8f0d887159076310ffa#2013-04-20 16:57:44#-1#2.0#2.0#9.0#9.0#14.0#14.0#3.0#3.0#2.0#2.0#// this is a dirty hack - but should be ok for a unittest.#c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b#MAPREDUCE-3068. Added a whitelist of environment variables for containers from the NodeManager and set MALLOC_ARENA_MAX for all daemons and containers. Contributed by Chris Riccomini.#27e8c86999bc6a972a99216060b11ef35b7de858#YARN-561. Modified NodeManager to set key information into the environment of every container that it launches. Contributed by Xuan Gong. MAPREDUCE-5175. Updated MR App to not set envs that will be set by NMs anyways after YARN-561. Contributed by Xuan Gong.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/DominantResourceFairnessPolicy.java#computeShares(Collection<?extendsSchedulable>,Resource)#c1b635ed4826b0f9c8574d262dfeb13fa5ceb650#2013-06-03 17:33:55#37d7935a9d7b86635c9c1ffc03f88b49857f88a0#2013-06-21 18:28:57#-1#1.0#1.0#2.0#2.0#11.0#11.0#2.0#2.0#1.0#1.0#// TODO: For now, set all fair shares to 0, because, in the context of DRF, // it doesn't make sense to set a value for each resource.  YARN-736 should // add in a sensible replacement.#c1b635ed4826b0f9c8574d262dfeb13fa5ceb650#YARN-326. Add multi-resource scheduling to the fair scheduler. (sandyr via tucu)#e60fbbcc2e6a0d27d588b620817d29d1c70893a5#YARN-736. Add a multi-resource fair sharing metric. (sandyr via tucu)
hadoop#DESIGN#hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/datatypes/util/MapReduceJobPropertiesParser.java#fromString(String,String)#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#9ae7f9eb7baeb244e1b95aabc93ad8124870b9a9#2015-03-03 18:06:26#-1#9.0#9.0#15.0#15.0#66.0#66.0#12.0#12.0#3.0#3.0#//TODO compression? //TODO Other job configs like FileOutputFormat/FileInputFormat etc#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/IPCLoggerChannel.java#close()#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#6ae2a0d048e133b43249c248a75a4d77d9abb80d#2015-05-01 15:27:28#-1#2.0#3.0#2.0#2.0#11.0#12.0#2.0#2.0#1.0#1.0#// TODO: this can hang for quite some time if the client // is currently in the middle of a call to a downed JN. // We should instead do this asynchronously, and just stop // making any more calls after this point (eg clear the queue)#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/startupprogress/StartupProgressMetrics.java#close()#da8e962e39bd41b73b53966826c82e741b08010b#2013-07-11 05:35:29#da8e962e39bd41b73b53966826c82e741b08010b#2013-07-11 05:35:29#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this can hang for quite some time if the client // is currently in the middle of a call to a downed JN. // We should instead do this asynchronously, and just stop // making any more calls after this point (eg clear the queue)#da8e962e39bd41b73b53966826c82e741b08010b#HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReadStripedFileWithDecoding.java#close()#71329e817b99dbee630f902fa3640c3c93f04a44#2015-06-02 15:35:49#0aa8c828943e184f72699378c67873a406d457cc#2016-02-11 10:14:09#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this can hang for quite some time if the client // is currently in the middle of a call to a downed JN. // We should instead do this asynchronously, and just stop // making any more calls after this point (eg clear the queue)#71329e817b99dbee630f902fa3640c3c93f04a44#HDFS-8517. Fix a decoding issue in stripped block recovering in client side. Contributed by Kai Zheng.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRemoteNameNodeInfo.java#close()#49dfad942970459297f72632ed8dfd353e0c86de#2015-06-23 17:26:11#49dfad942970459297f72632ed8dfd353e0c86de#2015-06-23 17:26:11#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this can hang for quite some time if the client // is currently in the middle of a call to a downed JN. // We should instead do this asynchronously, and just stop // making any more calls after this point (eg clear the queue)#49dfad942970459297f72632ed8dfd353e0c86de#HDFS-6440. Support more than 2 NameNodes. Contributed by Jesse Yates.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler.java#normalizeRequest(ResourceRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9a4e890f4aadc921fa468fd1292d215704429b61#2011-10-05 14:01:32#-1#3.0#3.0#4.0#4.0#8.0#8.0#2.0#2.0#0.0#0.0#// FIXME: TestApplicationCleanup is relying on unnormalized behavior.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#e549ac93694f768f2e26706a54a1b45dea6d2844#MAPREDUCE-2788. Normalize resource requests in FifoScheduler appropriately. Contributed by Ahmed Radwan.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler.java#addApplication(ApplicationAttemptId,String,String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#20d389ce61eaacb5ddfb329015f50e96ad894f8d#2016-03-14 14:19:05#-1#9.0#-1#10.0#-1#14.0#-1#1.0#-1#0.0#-1#// TODO: Fix store#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler.java#recover(RMState)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#40062e1aaa09628c6f45d20298fd66d799fd1f3f#2012-09-27 03:43:57#-1#0.0#0.0#0.0#0.0#9.0#9.0#1.0#1.0#0.0#0.0#// TODO fix recovery#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1943fdbec613715f3cdc3ca60cbd273115f28299#YARN-229. Remove old unused RM recovery code. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/CompletedTaskAttempt.java#getAssignedContainerMgrAddress()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d9ba4670ed0134816d5d063d48394e31b51c3b35#2011-09-15 22:21:00#-1#1.0#1.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO Verify this is correct.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java#recoverUnclosedSegment(long)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#8a8c9c18d37f0c8b219264796c0df4bcae6f4e38#2012-09-11 06:31:42#-1#8.0#8.0#17.0#22.0#67.0#102.0#3.0#6.0#1.0#2.0#// TODO: check that md5s match up between any "tied" logs#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#663e7484c04c197eed53f10a7808140f1c955277#HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java#selectInputStreams(Collection<EditLogInputStream>,long,boolean)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#8021d9199f278345aca6211f318145342ad036f4#2012-09-05 04:13:19#-1#8.0#8.0#17.0#17.0#37.0#35.0#4.0#4.0#2.0#2.0#// TODO: can we do better here?#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#437948ea1c0c9c61c2b5049b82ffd9525f33be97#HDFS-3891. Make selectInputStreams throw IOE instead of RTE. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java#recoverUnclosedSegment(long)#c95a1674b61ef2a6963dc64604986ef90a8c636d#2012-08-15 00:57:24#56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7#2014-03-25 06:48:15#-1#8.0#8.0#18.0#22.0#82.0#98.0#4.0#6.0#2.0#2.0#// Sanity check: we should only get here if none of the responses had // a log. This should be a postcondition of the recovery comparator, // but a bug in the comparator might cause us to get here.#c95a1674b61ef2a6963dc64604986ef90a8c636d#HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/startupprogress/StepType.java#recoverUnclosedSegment(long)#da8e962e39bd41b73b53966826c82e741b08010b#2013-07-11 05:35:29#af1ac9a5e8d8d97a855940d853dd59ab4666f6e2#2013-10-04 17:46:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Sanity check: we should only get here if none of the responses had // a log. This should be a postcondition of the recovery comparator, // but a bug in the comparator might cause us to get here.#da8e962e39bd41b73b53966826c82e741b08010b#HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyCheckpoints.java#testBothNodesInStandbyState()#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#2012-01-05 00:22:54#32c313d51cd2483ea510afe044c55eeaed7c2b2d#2012-02-02 22:21:57#-1#3.0#3.0#13.0#12.0#25.0#25.0#1.0#1.0#0.0#0.0#// TODO: this failed once because it caught a ckpt file -- maybe // this is possible if one of the NNs is really fast and the other is slow? // need to loop this to suss out the race.#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryClientService.java#verifyAndGetJob(JobId)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#c6923061d0384cc22d459ee570f3626d98b3ef69#2012-01-20 20:44:17#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO disable check access for now.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#3cbb9d20d0bf9d4f28c64bd56c5b9c7dd70ed801#MAPREDUCE-3903. Add support for mapreduce admin users. (Contributed by Thomas Graves)
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java#checkFullFile(FileSystem,Path)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#3ae38ec7dfa1aaf451cf889cec6cf862379af32a#2015-02-03 15:01:16#-1#4.0#4.0#0.0#0.0#3.0#3.0#1.0#1.0#0.0#0.0#//TODO: un-comment checkFullFile once the lease recovery is done#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/src/tools/org/apache/hadoop/tools/rumen/state/StatePool.java#setStates(HashMap<StringStatePair>)#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#10325d97329c214bb3899c8535df5a366bc86d2f#2012-01-18 22:10:12#-1#3.0#3.0#2.0#2.0#8.0#8.0#2.0#2.0#1.0#1.0#//TODO Should we do a clone?#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java#initExisting()#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#2012-04-10 18:11:26#4343a4cf7790b47dc7ecd18f8634e6b9c805e775#2016-02-23 17:37:49#-1#2.0#4.0#6.0#9.0#10.0#15.0#2.0#3.0#1.0#1.0#// TODO Could verify the correct format for these directories.#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java#removeDirectoryFromSerialNumberIndex(Path)#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#2012-04-10 18:11:26#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#2012-04-10 18:11:26#-1#4.0#5.0#8.0#7.0#25.0#13.0#5.0#3.0#2.0#2.0#// TODO make this thread safe without the synchronize#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).#7d04a96027ad75877b41b7cd8f67455dd13159d7#MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java#clean(long,HistoryStorage)#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#2012-04-10 18:11:26#4343a4cf7790b47dc7ecd18f8634e6b9c805e775#2016-02-23 17:37:49#-1#5.0#6.0#20.0#19.0#40.0#40.0#5.0#6.0#3.0#4.0#// TODO this should be replaced by something that knows about the directory // structure and will put less of a load on HDFS.#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java#addIfAbsent(HistoryFileInfo)#7d04a96027ad75877b41b7cd8f67455dd13159d7#2012-04-18 01:59:16#4343a4cf7790b47dc7ecd18f8634e6b9c805e775#2016-02-23 17:37:49#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//There is a race here, where more then one thread could be trying to // remove entries.  This could result in too many entries being removed // from the cache.  This is considered OK as the size of the cache // should be rather large, and we would rather have performance over // keeping the cache size exactly at the maximum.#7d04a96027ad75877b41b7cd8f67455dd13159d7#MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java#scanIntermediateDirectory()#7d04a96027ad75877b41b7cd8f67455dd13159d7#2012-04-18 01:59:16#4343a4cf7790b47dc7ecd18f8634e6b9c805e775#2016-02-23 17:37:49#-1#8.0#7.0#10.0#7.0#27.0#19.0#5.0#4.0#3.0#3.0#// TODO it would be great to limit how often this happens, except in the // case where we are looking for a particular job.#7d04a96027ad75877b41b7cd8f67455dd13159d7#MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/MiniMRYarnCluster.java#start()#670fa24b48acb407c22fbfdde87ae3123dcbf449#2011-10-28 06:45:04#04d97f8abb7fcc7b635b9499a48ddaa1fe0ac7e3#2015-11-03 01:48:45#-1#-1#5.0#-1#10.0#-1#19.0#-1#1.0#-1#0.0#//TODO Add a timeout. State.STOPPED check ?#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestWasbUriAndConfiguration.java#serviceStart()#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#2014-06-10 22:26:45#7634d404b750eafa135a37fa275325d0398255fb#2016-02-28 11:22:55#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Add a timeout. State.STOPPED check ?#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java#setup(JobConf)#050fd3a11744cde3d54c1fff23d8fdeb3803bf92#2012-09-26 15:22:21#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#18.0#18.0#44.0#41.0#104.0#103.0#17.0#17.0#3.0#3.0#//PATTERN is not currently used in local mode#050fd3a11744cde3d54c1fff23d8fdeb3803bf92#MAPREDUCE-4647. We should only unjar jobjar if there is a lib directory in it. (Robert Evans via tgraves)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRAMWithNonNormalizedCapabilities.java#setup()#27a50a2bef90faed231585ab535502f2f7bf9563#2013-06-28 18:53:19#15366d922772afaa9457ed946533cdf4b5d01e2f#2014-08-29 19:50:15#-1#5.0#5.0#12.0#12.0#17.0#17.0#3.0#3.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#27a50a2bef90faed231585ab535502f2f7bf9563#MAPREDUCE-5333. Add test that verifies MRAM works correctly when sending requests with non-normalized capabilities. (ywskycn via tucu)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRAppWithCombiner.java#setup()#96247ead035cc4d6b7be477e1875e8112298ce3d#2011-12-20 22:01:13#96247ead035cc4d6b7be477e1875e8112298ce3d#2011-12-20 22:01:13#-1#5.0#5.0#11.0#11.0#21.0#21.0#3.0#3.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#96247ead035cc4d6b7be477e1875e8112298ce3d#MAPREDUCE-3376. Fixed Task to ensure it passes reporter to combiners using old MR api. Contributed by Subroto Sanyal.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHttpPolicy.java#setup()#d598b6ef9f10ae011fecbe198360cde63a4e4d50#2014-02-05 22:48:06#3369a4f6916f12e9d6b97072badd1b176be443bd#2016-02-23 21:37:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#d598b6ef9f10ae011fecbe198360cde63a4e4d50#HDFS-5873. dfs.http.policy should have higher precedence over dfs.https.enable. Contributed by Haohui Mai.##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/pipes/Submitter.java#printUsage()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#27d49e6714ad7fc6038bc001e70ff5be3755f1ef#2015-03-28 11:57:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// The CLI package should do this for us, but I can't figure out how // to make it print something reasonable.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryServerStateStoreServiceFactory.java#printUsage()#2627e352d630d19c35b97eea9ef603342feb379f#2013-09-27 18:19:41#2627e352d630d19c35b97eea9ef603342feb379f#2013-09-27 18:19:41#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// The CLI package should do this for us, but I can't figure out how // to make it print something reasonable.#2627e352d630d19c35b97eea9ef603342feb379f#MAPREDUCE-5332. Support token-preserving restart of history server. Contributed by Jason Lowe##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobs.java#setup()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#f634505d48d97e4d461980d68a0cbdf87223646d#2015-11-24 22:07:26#-1#7.0#13.0#11.0#22.0#19.0#31.0#3.0#4.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHttpPolicy.java#setup()#d598b6ef9f10ae011fecbe198360cde63a4e4d50#2014-02-05 22:48:06#3369a4f6916f12e9d6b97072badd1b176be443bd#2016-02-23 21:37:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#d598b6ef9f10ae011fecbe198360cde63a4e4d50#HDFS-5873. dfs.http.policy should have higher precedence over dfs.https.enable. Contributed by Haohui Mai.##
hadoop#DESIGN#hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/RumenToSLSConverter.java#setup()#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#2013-09-27 20:23:19#355eaaa33d01f06e9efe960b8888fb925e03ffb9#2015-09-03 22:48:53#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobsWithHistoryService.java#setup()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#43cd07b408c6613d2c9aa89203cfa3110d830538#2014-11-09 14:57:37#-1#5.0#5.0#12.0#12.0#19.0#19.0#3.0#3.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMRJobsWithHistoryService.java#testJobHistoryData()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#43cd07b408c6613d2c9aa89203cfa3110d830538#2014-11-09 14:57:37#-1#6.0#7.0#21.0#28.0#30.0#51.0#4.0#5.0#2.0#2.0#//TODO the Assert below worked. need to check //Should we compare each field or convert to V2 counter and compare#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHttpPolicy.java#setup()#d598b6ef9f10ae011fecbe198360cde63a4e4d50#2014-02-05 22:48:06#3369a4f6916f12e9d6b97072badd1b176be443bd#2016-02-23 21:37:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#d598b6ef9f10ae011fecbe198360cde63a4e4d50#HDFS-5873. dfs.http.policy should have higher precedence over dfs.https.enable. Contributed by Haohui Mai.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHttpPolicy.java#testJobHistoryData()#d598b6ef9f10ae011fecbe198360cde63a4e4d50#2014-02-05 22:48:06#3369a4f6916f12e9d6b97072badd1b176be443bd#2016-02-23 21:37:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO the Assert below worked. need to check //Should we compare each field or convert to V2 counter and compare#d598b6ef9f10ae011fecbe198360cde63a4e4d50#HDFS-5873. dfs.http.policy should have higher precedence over dfs.https.enable. Contributed by Haohui Mai.##
hadoop#DESIGN#hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java#setup()#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#2013-09-27 20:23:19#4efdf3a979c361348612f817a3253be6d0de58f7#2016-01-26 18:17:12#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)##
hadoop#DESIGN#hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java#testJobHistoryData()#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#2013-09-27 20:23:19#4efdf3a979c361348612f817a3253be6d0de58f7#2016-01-26 18:17:12#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO the Assert below worked. need to check //Should we compare each field or convert to V2 counter and compare#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/NMTokenSecretManagerInRM.java#clearApplicationNMTokenKeys()#769a0bd8314cd7317c083a9b74abf47242acb58c#2013-06-16 03:11:33#26dee1486b70237a2a47f910472e9aa81ffad349#2015-02-04 11:41:14#-1#2.0#2.0#5.0#5.0#10.0#10.0#2.0#2.0#1.0#1.0#// We should clear all node entries from this set. // TODO : Once we have per node master key then it will change to only // remove specific node from it.#769a0bd8314cd7317c083a9b74abf47242acb58c#YARN-693. Modified RM to send NMTokens on allocate call so that AMs can then use them for authentication with NMs. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/GetJournalEditServlet.java#isValidRequestor(String,Configuration)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#b17018e4b821ec860144d8bd38bc1fcb0d7eeaa5#2012-07-25 21:47:19#-1#6.0#6.0#9.0#9.0#29.0#29.0#6.0#6.0#3.0#3.0#// TODO: create security tests#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#df801074c929d5414b92cc9fc0cc8a2794e02751#HDFS-3893. QJM: Make QJM work with security enabled. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/GetJournalEditServlet.java#isValidRequestor(String,Configuration)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#b17018e4b821ec860144d8bd38bc1fcb0d7eeaa5#2012-07-25 21:47:19#-1#6.0#6.0#9.0#9.0#29.0#29.0#6.0#6.0#3.0#3.0#// TODO: above principal is not correct, since each JN will have a // different hostname.#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#df801074c929d5414b92cc9fc0cc8a2794e02751#HDFS-3893. QJM: Make QJM work with security enabled. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMROldApiJobs.java#setup()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#c27de4bd0b42262a9dbf56830be77fe382f82fd7#2012-01-04 17:51:17#-1#7.0#7.0#13.0#13.0#23.0#23.0#3.0#3.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestLocalResourcesTrackerImpl.java#testHierarchicalLocalCacheDirectories()#e67e3ff05db26437b1d7c6d3dd958362fb8425db#2013-04-03 05:00:28#855d52927b6115e2cfbd97a94d6c1a3ddf0e94bb#2015-11-15 04:43:57#-1#4.0#3.0#26.0#28.0#104.0#120.0#5.0#5.0#3.0#3.0#// lr1 is not used by anyone and will be removed, only lr3 will hang // around#e67e3ff05db26437b1d7c6d3dd958362fb8425db#YARN-467. Modify public distributed cache to localize files such that no local directory hits unix file count limits and thus prevent job failures. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/TestResourceLocalizationService.java#testParallelDownloadAttemptsForPublicResource()#c570309b078d3c6080e89cd90c7c2157a270aaca#2013-04-19 22:35:43#22ca176dfe125a4f7bf38cc63ab8106c40a7a7ba#2016-03-15 10:05:10#-1#11.0#13.0#52.0#40.0#143.0#131.0#3.0#3.0#2.0#2.0#// Now I need to simulate a race condition wherein Event is added to // dispatcher before resource state changes to either FAILED or LOCALIZED // Hence sending event directly to dispatcher.#c570309b078d3c6080e89cd90c7c2157a270aaca#YARN-547. Fixed race conditions in public and private resource localization which used to cause duplicate downloads. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/ReservationsACLsManager.java#testParallelDownloadAttemptsForPublicResource()#23f937e3b718f607d4fc975610ab3a03265f0f7e#2016-02-11 10:47:43#23f937e3b718f607d4fc975610ab3a03265f0f7e#2016-02-11 10:47:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Now I need to simulate a race condition wherein Event is added to // dispatcher before resource state changes to either FAILED or LOCALIZED // Hence sending event directly to dispatcher.#23f937e3b718f607d4fc975610ab3a03265f0f7e#YARN-2575. Create separate ACLs for Reservation create/update/delete/list ops (Sean Po via asuresh)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#newEpoch(NamespaceInfo,long)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#ca4582222e89114e4c61d38fbf973a66d2867abf#2012-09-10 18:51:15#-1#12.0#19.0#10.0#12.0#30.0#30.0#4.0#4.0#1.0#1.0#// TODO: we only need to do this once, not on writer switchover.#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#60c20e559b8036410e2d9081b9c60d1e04e56253#HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#journal(RequestInfo,long,int,byte[])#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#13daca1ef6aa4a24ff9a840397dda1bbddb16e37#2012-09-05 04:30:51#-1#10.0#25.0#8.0#18.0#23.0#62.0#2.0#4.0#1.0#1.0#// TODO: if a JN goes down and comes back up, then it will throw // this exception on every edit. We should instead send back // a response indicating the log needs to be rolled, which would // mark the logger on the client side as "pending" -- and have the // NN code look for this condition and trigger a roll when it happens. // That way the node can catch back up and rejoin#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#cae8116a146cb27d40e4e41cece9a17945bc7f9c#HDFS-3726. If a logger misses an RPC, don't retry that logger until next segment. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#checkRequest(RequestInfo)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#83c14fbd24353b5e882f065faec81e58449afed3#2012-09-17 21:51:40#-1#7.0#10.0#2.0#7.0#15.0#24.0#2.0#3.0#1.0#1.0#// TODO: should other requests check the _exact_ epoch instead of // the <= check? <= should probably only be necessary for the // first calls#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#663e7484c04c197eed53f10a7808140f1c955277#HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#checkRequest(RequestInfo)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#83c14fbd24353b5e882f065faec81e58449afed3#2012-09-17 21:51:40#-1#7.0#10.0#2.0#7.0#15.0#24.0#2.0#3.0#1.0#1.0#// TODO: some check on serial number that they only increase from a given // client#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#663e7484c04c197eed53f10a7808140f1c955277#HDFS-3950. QJM: misc TODO cleanup, improved log messages, etc. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#finalizeLogSegment(RequestInfo,long,long)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#ca4582222e89114e4c61d38fbf973a66d2867abf#2012-09-10 18:51:15#-1#8.0#12.0#12.0#16.0#29.0#41.0#4.0#5.0#2.0#2.0#// TODO: this is slow to validate when in non-recovery cases // we already know the length here!#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#60c20e559b8036410e2d9081b9c60d1e04e56253#HDFS-3900. QJM: avoid validating log segments on log rolls. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java#getEditLogManifest(long)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#-1#3.0#3.0#3.0#3.0#7.0#7.0#1.0#1.0#0.0#0.0#// TODO: check fencing info?#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.#939f4a9f92ab260aee697d3715946218a7ff769a#HDFS-3694. Fix getEditLogManifest to fetch httpPort if necessary. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java#initExisting()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#c3a4de0ec0389064f5468180d1b9024f64b00f40#2012-03-06 23:21:13#-1#1.0#2.0#5.0#6.0#9.0#10.0#2.0#2.0#1.0#1.0#//TODO Could verify the correct format for these directories.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#c3a4de0ec0389064f5468180d1b9024f64b00f40#2012-03-06 23:21:13#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Is this really required.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java#getAllJobsInternal()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#c3a4de0ec0389064f5468180d1b9024f64b00f40#2012-03-06 23:21:13#-1#6.0#5.0#9.0#9.0#26.0#26.0#6.0#6.0#2.0#2.0#//TODO This should ideally be using getAllJobsMetaInfo // or get rid of that method once Job has APIs for user, finishTime etc.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#cbb5f6109097a77f18f5fb0ba62ac132b8fa980f#MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java#getApplicationAttemptId()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#1.0#2.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#//TODO fixme - bogus appAttemptID for now#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java#getApplicationID()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#1.0#2.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#//TODO fixme - bogus appID for now#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestRMNMInfo.java#setup()#7e4725db41674a74846b9b252a575da23a1a2b11#2012-01-30 18:47:55#b8f250a99dd746599c5d9830fa1d52149ca418b0#2014-04-09 11:11:20#-1#7.0#7.0#11.0#11.0#20.0#20.0#3.0#3.0#1.0#1.0#// workaround the absent public distcache.#7e4725db41674a74846b9b252a575da23a1a2b11#MAPREDUCE-3703. ResourceManager should provide node lists in JMX output. (Eric Payne via mahadev)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java#equals(Object)#6cc49f1a8b72eefb91e405d7bde0468906c1819f#2012-12-05 01:45:29#c080fec82be6866ab8d69540fe6ee147b2a0108d#2014-02-26 21:55:47#-1#2.0#2.0#4.0#4.0#13.0#10.0#3.0#3.0#1.0#1.0#// because we have class identity checking above, and for this class // isValid() is always true.#6cc49f1a8b72eefb91e405d7bde0468906c1819f#HDFS-4199. Provide test for HdfsVolumeId. Contributed by Ivan A. Veselovsky.#eee4d716b48074825e1afcd9c74038a393ddeb69#HDFS-8895. Remove deprecated BlockStorageLocation APIs.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/TestFairReservationSystem.java#equals(Object)#a22ffc318801698e86cd0e316b4824015f2486ac#2014-12-19 14:23:43#156f24ead00436faad5d4aeef327a546392cd265#2015-07-25 07:39:47#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// because we have class identity checking above, and for this class // isValid() is always true.#a22ffc318801698e86cd0e316b4824015f2486ac#YARN-2738. [YARN-2574] Add FairReservationSystem for FairScheduler. (Anubhav Dhoot via kasha)#8572a5a14b999a866fa64ce32ee20078ffefdb1e#YARN-3974. Refactor the reservation system test cases to use parameterized base test. (subru via curino)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ContiguousBlockStorageOp.java#equals(Object)#c17439c2ddd921b63b1635e6f1cba634b8da8557#2015-06-12 11:35:39#bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75#2015-07-07 10:08:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// because we have class identity checking above, and for this class // isValid() is always true.#c17439c2ddd921b63b1635e6f1cba634b8da8557#HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.#f4c523b69ba55b1fd35e8995c3011a9f546ac835#Revert "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang."
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FileWithStripedBlocksFeature.java#equals(Object)#9f2f583f401189c3f4a2687795a9e3e0b288322b#2015-02-25 22:10:26#97a2396af685838c9fcb31e48573e758c124d8d7#2015-05-12 11:43:04#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// because we have class identity checking above, and for this class // isValid() is always true.#9f2f583f401189c3f4a2687795a9e3e0b288322b#HDFS-7749. Erasure Coding: Add striped block support in INodeFile. Contributed by Jing Zhao.#7e091de1366f4b57b5433bc19d738199dc05313d#HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestSpeculativeExecution.java#setup()#b62c1b8563c7b870ace40bed424b4e1f90a058d7#2012-01-13 23:41:23#735b50e8bd23f7fbeff3a08cf8f3fff8cbff7449#2012-07-31 19:20:03#-1#5.0#6.0#11.0#11.0#19.0#19.0#3.0#3.0#1.0#1.0#// workaround the absent public distcache.#b62c1b8563c7b870ace40bed424b4e1f90a058d7#MAPREDUCE-3404. Corrected MR AM to honor speculative configuration and enable speculating either maps or reduces. Contributed by Eric Payne.##
hadoop#DESIGN#hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/metrics/AzureMetricsTestUtil.java#setup()#0d91576ec31f63402f2db6107a04155368e2632d#2014-06-24 20:52:44#2217e2f8ff418b88eac6ad36cafe3a9795a11f40#2014-10-08 14:20:23#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// workaround the absent public distcache.#0d91576ec31f63402f2db6107a04155368e2632d#HADOOP-10728. Metrics system for Windows Azure Storage Filesystem. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.##
hadoop#DESIGN#hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/nodemanager/NodeInfo.java#setup()#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#2013-09-27 20:23:19#79c41b1d83e981ae74cb8b58ffcf7907b7612ad4#2015-12-16 13:18:19#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// workaround the absent public distcache.#58b08e11b9f04c9190ab4a07473f0ee04e01ec6b#YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/server/api/protocolrecords/UpdateNodeResourceRequest.java#setup()#49ad07af9782c2c2608799573e815a7cfc26851f#2013-12-16 23:36:16#3da9a97cfbcc3a1c50aaf85b1a129d4d269cd5fd#2015-03-16 23:19:05#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// workaround the absent public distcache.#49ad07af9782c2c2608799573e815a7cfc26851f#YARN-312. Introduced ResourceManagerAdministrationProtocol changes to support changing resources on node. Contributed by Junping Du.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/sharedcache/SharedCacheChecksumFactory.java#setup()#a04143039e7fe310d807f40584633096181cfada#2014-11-12 09:31:05#a04143039e7fe310d807f40584633096181cfada#2014-11-12 09:31:05#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// workaround the absent public distcache.#a04143039e7fe310d807f40584633096181cfada#YARN-2236. [YARN-1492] Shared Cache uploader service on the Node Manager. (Chris Trezzo and Sanjin Lee via kasha)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.java#write(DataOutput)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#e505b7e704ff83893a40190695977ce1393f6248#2012-04-06 00:20:55#-1#4.0#3.0#4.0#5.0#9.0#9.0#1.0#1.0#0.0#0.0#//TODO: move it to DatanodeID once HADOOP-2797 has been committed#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#80447bd35a79ca58a03354d0552fbefd4edd7565#HDFS-3244. Remove dead writable code from hdfs/protocol. Contributed by Eli Collins
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#testSnapshot(Path,ArrayList<Modification[]>)#8b71399abb323698a4850cd4f4a1e3763f13e6a2#2012-11-01 08:29:41#b94cf83a113564ec07880c44d6b03a461f9fc923#2012-11-07 19:38:29#-1#5.0#5.0#7.0#7.0#21.0#21.0#3.0#3.0#2.0#2.0#// 1. create snapshot // TODO: we also need to check creating snapshot for a directory under a // snapshottable directory#8b71399abb323698a4850cd4f4a1e3763f13e6a2#HDFS-4133. Add testcases for testing basic snapshot functionalities. Contributed by Jing Zhao.#1253e02f6654bd05ab063225208dec0324691fc9#HDFS-4175. Additional snapshot tests for more complicated directory structure and modifications. Contributed by Jing Zhao.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#testSnapshottableDirectory()#b3bc2fb76e1aca8e7327d1d1a6e4c8a013c575de#2012-11-05 01:22:54#d32fb8a62b323a21228d864ce0e859464fb1f160#2013-03-09 18:14:30#-1#7.0#6.0#4.0#5.0#9.0#12.0#1.0#1.0#0.0#0.0#/**hadoop,   * Creating snapshots for a directory that is not snapshottable must fail.hadoop,   * hadoop,   * TODO: Listing/Deleting snapshots for a directory that is not snapshottablehadoop,   * should also fail.hadoop,   */#b3bc2fb76e1aca8e7327d1d1a6e4c8a013c575de#HDFS-4147. When there is a snapshot in a subtree, deletion of the subtree should fail. Contributed by Jing Zhao#719c313be12be3afd83b97a5a13dd0585c7f5819#HDFS-4144. Create test for all snapshot-related metrics. Contributed by Jing Zhao.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#prepareModifications(TestDirectoryTree.Node[])#cbbaa93ae09bf5cf643263faf78f99315c4f3a8d#2012-12-17 03:40:27#397835acdf66cf48ebdbc256aa15b6660181c339#2013-01-15 04:33:14#-1#10.0#10.0#19.0#18.0#60.0#61.0#3.0#3.0#2.0#2.0#// TODO: fix append for snapshots //      mList.add(append);#cbbaa93ae09bf5cf643263faf78f99315c4f3a8d#HDFS-4317. Change INode and its subclasses to support HDFS-4103.#b71d3868908a49c1b2e353afea795a76dfb20f7d#HDFS-4098. Add FileWithSnapshot, INodeFileUnderConstructionWithSnapshot and INodeFileUnderConstructionSnapshot for supporting append to snapshotted files.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#prepareModifications(TestDirectoryTree.Node[])#b9f965de120b5278ac84a7e98aecb32aafde4c16#2012-12-21 01:30:49#397835acdf66cf48ebdbc256aa15b6660181c339#2013-01-15 04:33:14#-1#10.0#10.0#18.0#18.0#61.0#61.0#3.0#3.0#2.0#2.0#//      TODO: fix append for snapshots //      Modification append = new FileAppend( //          node.fileList.get((node.nullFileIndex + 2) % node.fileList.size()), //          hdfs, (int) BLOCKSIZE);#b9f965de120b5278ac84a7e98aecb32aafde4c16#HDFS-4103. Support O(1) snapshot creation.#b71d3868908a49c1b2e353afea795a76dfb20f7d#HDFS-4098. Add FileWithSnapshot, INodeFileUnderConstructionWithSnapshot and INodeFileUnderConstructionSnapshot for supporting append to snapshotted files.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#prepareModifications(TestDirectoryTree.Node[])#fe3584aadfc7839abcd03239e4d07afd12b8b90f#2013-01-23 02:48:01#12e8ba804f9454d9bb07099e35ce7ef63c0d4e1e#2013-01-25 03:09:26#-1#10.0#10.0#18.0#18.0#64.0#64.0#3.0#3.0#2.0#2.0#//TODO //mList.add(append);#fe3584aadfc7839abcd03239e4d07afd12b8b90f#HDFS-4126. Add reading/writing snapshot information to FSImage. Contributed by Jing Zhao.#5988208b7d2fa3c0378f17fe67ada99a25342829#HDFS-4432. Support INodeFileUnderConstructionWithSnapshot in FSImage saving/loading. Contributed by Jing Zhao.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java#runTestSnapshot()#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#2013-02-08 02:18:55#afe77ce53d3cf203690aa419e377f26cbd45a96e#2013-02-08 23:19:32#-1#6.0#6.0#10.0#10.0#37.0#37.0#3.0#3.0#2.0#2.0#// check fsimage saving/loading //      TODO: fix fsimage //      checkFSImage();#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#HDFS-4446. Support file snapshots with diff lists.#02e6b72ae148fc8c2ba02ef624536b9e48997b31#HDFS-4481. Change fsimage to support snapshot file diffs.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java#run()#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#f291d82cd49c04a81380bc45c97c279d791b571c#2016-03-14 08:28:38#-1#18.0#25.0#44.0#48.0#212.0#105.0#14.0#8.0#4.0#2.0#// Setup local RPC Server to accept status requests directly from clients  // TODO need to setup a protocol for client to be able to communicate to the RPC server  // TODO use the rpc port info to register with the RM for the client to send requests to this app master#fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java#run()#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#1bd345d6e3855ab330963efd32e0fac102e61d1a#2013-03-20 20:44:35#-1#18.0#21.0#44.0#45.0#212.0#224.0#14.0#14.0#4.0#4.0#// Check what the current available resources in the cluster are // TODO should we do anything if the available resources are not enough? #fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.#28bac402953a4337deedf0472611f5775c7a74c9#YARN-417. Create AMRMClient wrapper that provides asynchronous callbacks. (Sandy Ryza via bikas)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java#run()#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#fdc9412a810564c79fbebf5eb730cb1018a95c6c#2013-06-14 16:10:37#-1#18.0#13.0#44.0#15.0#212.0#66.0#14.0#5.0#4.0#2.0#// TODO do we need to release this container? #fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.#b503b6a07d7210c94657131dcd97239012ecb313#YARN-639. Modified Distributed Shell application to start using the new NMClient library. Contributed by Zhijie Shen.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java#setupContainerAskForRM(int)#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#f291d82cd49c04a81380bc45c97c279d791b571c#2016-03-14 08:28:38#-1#5.0#-1#8.0#-1#27.0#-1#1.0#-1#0.0#-1#// TODO - what is the range for priority? how to decide? #fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/DistCp.java#copy(FileStatus,Path,OutputCollector<WritableComparable<?Text>,Reporter)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#f5c48238d5eb0c1d2b876f390ac6c35221efcb54#2015-05-18 16:13:16#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: when modification times can be set, directories should be // emitted to reducers so they might be preserved. Also, mkdirs does // not currently return an error when the directory already exists; // if this changes, all directory work might as well be done in reduce#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#4aa730ce85d4c69c0ea8227c6c5276d96454c426#HADOOP-11698. Remove DistCpV1 and Logalyzer. Contributed by Brahma Reddy Battula.
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/DistCp.java#setup(Configuration,JobConf,Arguments)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#f5c48238d5eb0c1d2b876f390ac6c35221efcb54#2015-05-18 16:13:16#-1#35.0#36.0#60.0#65.0#304.0#305.0#40.0#40.0#7.0#7.0#// If dst is '/' on S3, it might not exist yet, but dst.getParent() // will return null. In this case, use '/' as its own parent to prevent // NPE errors below.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#4aa730ce85d4c69c0ea8227c6c5276d96454c426#HADOOP-11698. Remove DistCpV1 and Logalyzer. Contributed by Brahma Reddy Battula.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java#run()#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#e9a622606f69dc926a950d4dd61fe3f16f378509#2016-02-10 13:00:48#-1#28.0#55.0#76.0#84.0#287.0#277.0#13.0#23.0#2.0#3.0#// TODO - what is the range for priority? how to decide? #fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java#run()#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#df654cca49c12ab3fa8ec1e626da1bb562bbb6c1#2012-04-19 20:33:11#-1#28.0#28.0#76.0#79.0#287.0#287.0#13.0#14.0#2.0#2.0#// Set the user submitting this application  // TODO can it be empty? #fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.#daa28cc6ce23ef5c8db8b9f896f342cb770dd092#MAPREDUCE-4306. Fix distributed shell to work with users other than the one running the daemons. (Contributed by Ahmed Radwan)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java#killApplication(ApplicationId)#fad230a49d0d4cdbb2062b10c3dea6c755737db5#2011-09-30 22:25:32#e9a622606f69dc926a950d4dd61fe3f16f378509#2016-02-10 13:00:48#-1#4.0#3.0#3.0#1.0#11.0#10.0#1.0#1.0#0.0#0.0#// TODO clarify whether multiple jobs with the same app id can be submitted and be running at  // the same time.  // If yes, can we kill a particular attempt only?#fad230a49d0d4cdbb2062b10c3dea6c755737db5#MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/CapacitySchedulerPage.java#render(Block)#0ea8570be578be60e2f32849900a1c50506d78d3#2011-12-13 23:05:56#0ea8570be578be60e2f32849900a1c50506d78d3#2011-12-13 23:05:56#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// this could be optimized better#0ea8570be578be60e2f32849900a1c50506d78d3#MAPREDUCE-2863. Support web services for YARN and MR components. (Thomas Graves via vinodkv)#4404f20671048ca4066a74094cb0961d664c5330#MAPREDUCE-3326. Added detailed information about queue's to the CapacityScheduler web-ui. Contributed by Jason Lowe.
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java#initNodes(DatanodeInfo[])#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#1f004b3367c57de9e8a67040a57efc31c9ba8ee2#2016-03-29 11:25:41#-1#12.0#-1#23.0#-1#62.0#-1#8.0#-1#3.0#-1#/* Given a data node set, build a network topology and decidehadoop,   * over-utilized datanodes, above average utilized datanodes, hadoop,   * below average utilized datanodes, and underutilized datanodes. hadoop,   * The input data node set is shuffled before the datanodes hadoop,   * are put into the over-utilized datanodes, above average utilizedhadoop,   * datanodes, below average utilized datanodes, andhadoop,   * underutilized datanodes lists. This will add some randomnesshadoop,   * to the node matching later on.hadoop,   * hadoop,   * @return the total number of bytes that are hadoop,   *                needed to move to make the cluster balanced.hadoop,   * @param datanodes a set of datanodeshadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java#run(int,Formatter)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#1f004b3367c57de9e8a67040a57efc31c9ba8ee2#2016-03-29 11:25:41#-1#21.0#-1#14.0#-1#71.0#-1#8.0#-1#3.0#-1#/* Decide all the nodes that will participate in the block move andhadoop,       * the number of bytes that need to be moved from one node to anotherhadoop,       * in this iteration. Maximum bytes to be moved per node ishadoop,       * Min(1 Band worth of bytes,  MAX_SIZE_TO_MOVE).hadoop,       */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/test/aop/org/apache/hadoop/fi/ProbabilityModel.java#injectCriteria(String)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#3.0#3.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO fix this: make it more sophisticated!!!#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#94a1833638df0e23155f5ae61b81416627486a15#HDFS-2261. AOP unit tests are not getting compiled or run. Contributed by Haohui Mai.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/webapp/HsJobBlock.java#render(Block)#0ea8570be578be60e2f32849900a1c50506d78d3#2011-12-13 23:05:56#ccbba4a4deb8ade54a04137c993526e461bcb46e#2016-02-02 15:19:35#-1#11.0#11.0#62.0#68.0#138.0#141.0#10.0#11.0#2.0#2.0#// todo - switch to use JobInfo#0ea8570be578be60e2f32849900a1c50506d78d3#MAPREDUCE-2863. Support web services for YARN and MR components. (Thomas Graves via vinodkv)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeBlockScanner.java#testBlockCorruptionPolicy()#2ba149f85c94d1f2a1d8833b8b9c3b36c5600ce2#2012-09-12 18:36:01#c0af72c7f74b6925786e24543cac433b906dd6d3#2015-01-21 14:41:31#-1#1.0#1.0#18.0#18.0#47.0#47.0#2.0#2.0#1.0#1.0#// Trigger each of the DNs to scan this block immediately. // The block pool scanner doesn't run frequently enough on its own // to notice these, and due to HDFS-1371, the client won't report // bad blocks to the NN when all replicas are bad.#2ba149f85c94d1f2a1d8833b8b9c3b36c5600ce2#HDFS-3902. TestDatanodeBlockScannertestBlockCorruptionPolicy is broken. Contributed by Andy Isaacson#6e62a1a6728b1f782f64065424f92b292c3f163a#HDFS-7430. Refactor the BlockScanner to use O(1) memory and use multiple threads (cmccabe)
hadoop#DESIGN#src/test/ddl/buffer.jr#testBlockCorruptionPolicy()#95a0db602b2e0606af11d666d9d10d64766f9ecf#2009-05-19 04:56:52#07b43463b8cb3aee80510c2cc3f70cd631f9a69b#2009-08-17 03:53:27#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Trigger each of the DNs to scan this block immediately. // The block pool scanner doesn't run frequently enough on its own // to notice these, and due to HDFS-1371, the client won't report // bad blocks to the NN when all replicas are bad.#95a0db602b2e0606af11d666d9d10d64766f9ecf#HADOOP-4687. move test dirs#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/MetricsOverviewTable.java#render(Block)#9a4e890f4aadc921fa468fd1292d215704429b61#2011-10-05 14:01:32#1de56b0448d332717c8316c621b4f6af542a85cc#2015-12-17 15:19:48#-1#7.0#3.0#32.0#63.0#108.0#147.0#8.0#3.0#2.0#2.0#//Yes this is a hack, but there is no other way to insert //CSS in the correct spot#9a4e890f4aadc921fa468fd1292d215704429b61#MAPREDUCE-2738. Added the missing cluster level statisticss on the RM web UI. Contributed by Robert Joseph Evans.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/TestPacketReceiver.java#doTestReceiveAndMirror(PacketReceiver,int,int)#ded304e6a6e74742f6f4a35989f762dcefa234cb#2012-10-16 00:55:29#f761bd8fe472c311bdff7c9d469f2805b867855a#2015-01-12 17:11:03#-1#6.0#6.0#21.0#22.0#35.0#36.0#1.0#1.0#0.0#0.0#// The write should be done in a single call. Otherwise we may hit // nasty interactions with nagling (eg HDFS-4049).#ded304e6a6e74742f6f4a35989f762dcefa234cb#HDFS-4049. Fix hflush performance regression due to nagling delays. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotReplication.java#testReplicationAfterDeletion()#b5a2dd19c46a02f3387be0719f1d2d02b587de0d#2012-11-15 23:08:25#9280468b1acfa346250d0212b5cb7486dc83705c#2013-04-17 02:41:38#-1#7.0#6.0#16.0#15.0#29.0#28.0#3.0#3.0#1.0#1.0#// TODO: check replication after deleting snapshot(s) // Delete file1#b5a2dd19c46a02f3387be0719f1d2d02b587de0d#HDFS-4187. Add tests for replication handling in snapshots. Contributed by Jing Zhao#65752c09ab4c070fbb7013c785d0db1dccd55d8f#HDFS-4735. DisallowSnapshot throws IllegalStateException for nested snapshottable directories.  Contributed by Jing Zhao
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AppSchedulable.java#assignContainer(SchedulerNode,SchedulerApp,Priority,ResourceRequest,NodeType,boolean)#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#2012-07-13 00:43:01#e60fbbcc2e6a0d27d588b620817d29d1c70893a5#2013-06-24 18:33:45#-1#8.0#9.0#17.0#17.0#54.0#54.0#5.0#6.0#2.0#3.0#// TODO this should subtract resource just assigned // TEMPROARY#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#MAPREDUCE-3451. Port Fair Scheduler to MR2 (pwendell via tucu)#c221204ccaadcf70992d9e858ef71c6f8864ff4e#YARN-883. Expose Fair Scheduler-specific queue metrics. (sandyr via tucu)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/JobSubmitter.java#copyRemoteFiles(Path,Path,Configuration,short)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#6.0#-1#7.0#-1#21.0#-1#2.0#-1#1.0#-1#//check if we do not need to copy the files // is jt using the same file system. // just checking for uri strings... doing no dns lookups  // to see if the filesystems are the same. This is not optimal. // but avoids name resolution.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/FSDownload.java#unpack(File,File)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d1c6accb6f87b08975175580e15f1ff1fe29ab04#2015-03-03 14:12:34#-1#7.0#-1#10.0#-1#32.0#-1#8.0#-1#3.0#-1#// TODO Should calculate here before returning //return FileUtil.getDU(destDir);#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/NodesPage.java#render(Block)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#ab0402bc1def44e3d52eea517f4132c460bd5f87#2011-09-29 00:42:47#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: acm: refactor2 FIXME //td(String.valueOf(ni.getNumContainers())). // TODO: FIXME Vinodkv //            td(String.valueOf(ni.getUsedResource().getMemory())). //            td(String.valueOf(ni.getAvailableResource().getMemory())).#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#9a4e890f4aadc921fa468fd1292d215704429b61#MAPREDUCE-2738. Added the missing cluster level statisticss on the RM web UI. Contributed by Robert Joseph Evans.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/webapp/TestNMWebServer.java#testNMWebApp()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d284e187b8db43056236032ebc2114ee462c27f6#2016-02-23 20:49:09#-1#3.0#5.0#25.0#34.0#59.0#90.0#2.0#2.0#0.0#0.0#// TODO: Use builder utils#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/webapp/TestNMWebServer.java#testNMWebApp()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d284e187b8db43056236032ebc2114ee462c27f6#2016-02-23 20:49:09#-1#3.0#5.0#25.0#34.0#59.0#90.0#2.0#2.0#0.0#0.0#//TODO: Gross hack. Fix in code.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/webapp/AppsBlock.java#testNMWebApp()#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#19ee1859071509bba9ecd0a8a7dc6a47e2979c88#2016-03-05 12:38:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Use builder utils#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/webapp/AppsBlock.java#testNMWebApp()#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#19ee1859071509bba9ecd0a8a7dc6a47e2979c88#2016-03-05 12:38:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: Gross hack. Fix in code.#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RmController.java#app()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#ca9f62121e829aeb9fc67122a78ba9f673eba074#2012-04-17 20:05:44#-1#2.0#4.0#29.0#35.0#43.0#54.0#7.0#7.0#1.0#1.0#// TODO: handle redirect to jobhistory server#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#506232da5c762c715dbcfa7d738ccd860ce4f123#MAPREDUCE-4211. Error conditions (missing appid, appid not found) are masked in the RM app page (Jonathan Eagles via bobby)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestEpochsAreUnique.java#testSingleThreaded()#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#53e3bf7e704c332fb119f55cb92520a51b644bfc#2015-12-01 23:21:21#-1#3.0#3.0#12.0#15.0#40.0#55.0#5.0#5.0#4.0#4.0#// With some failures injected, it should still always increase, perhaps // skipping some#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java#computeInvalidateWork(int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#b0944651681337e81b41250f43bd1e8eebc78125#2011-08-17 14:34:29#-1#5.0#4.0#8.0#9.0#30.0#30.0#5.0#5.0#2.0#2.0#// TODO should using recentInvalidateSets be synchronized? // get an array of the keys#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#cc875f0124d1951a4aab0565442242dac3dd35c8#DFS-1257. Fix a race condition on BlockManager.recentInvalidateSets.  Contributed by Eric Payne
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java#isReplicaCorrupt(Block,ReplicaState,BlockInfo,BlockUCState,DatanodeDescriptor)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#90a14f89e178e78cdcb16aec217fab99ad89fbfa#2012-02-23 01:25:14#-1#15.0#15.0#7.0#8.0#25.0#42.0#8.0#11.0#2.0#3.0#/*hadoop,   * The next two methods test the various cases under which we must concludehadoop,   * the replica is corrupt, or under construction.  These are laid outhadoop,   * as switch statements, on the theory that it is easier to understandhadoop,   * the combinatorics of reportedState and ucState that way.  It should behadoop,   * at least as efficient as boolean expressions.hadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#7decf112c0dcbf0445fe33458f7daa3d02617912#HDFS-3024. Improve performance of stringification in addStoredBlock. Contributed by Todd Lipcon.
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BlockManager.java#addStoredBlock(BlockInfo,DatanodeDescriptor,DatanodeDescriptor,boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#32d043d9c5f4615058ea4f65a58ba271ba47fcb5#2016-03-16 16:53:58#-1#18.0#-1#27.0#-1#96.0#-1#13.0#-1#2.0#-1#// we could add this block to invalidate set of this datanode. // it will happen in next block report otherwise.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java#processReportedBlock(DatanodeDescriptor,Block,ReplicaState,Collection<BlockInfo>,Collection<Block>,Collection<BlockInfo>,Collection<StatefulBlockInfo>)#31c91706f7d17da006ef2d6c541f8dd092fae077#2011-12-21 04:32:40#32d043d9c5f4615058ea4f65a58ba271ba47fcb5#2016-03-16 16:53:58#-1#13.0#-1#16.0#-1#54.0#-1#8.0#-1#1.0#-1#/*  TODO: following assertion is incorrect, see HDFS-2668hadoop,assert storedBlock.findDatanode(dn) < 0 : "Block " + blockhadoop,        + " in recentInvalidatesSet should not appear in DN " + dn; */#31c91706f7d17da006ef2d6c541f8dd092fae077#HDFS-1972. Fencing mechanism for block invalidations and replications. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java#checkReplicaCorrupt(Block,ReplicaState,BlockInfo,BlockUCState,DatanodeDescriptor)#475db83b874f5808811d6f2d5be425a6bd14bca5#2012-02-23 01:16:33#550853203b3a76078833f392912896f5442e1db5#2012-06-28 17:54:52#-1#15.0#15.0#9.0#9.0#61.0#61.0#13.0#13.0#3.0#3.0#/*hadoop,   * The next two methods test the various cases under which we must concludehadoop,   * the replica is corrupt, or under construction.  These are laid outhadoop,   * as switch statements, on the theory that it is easier to understandhadoop,   * the combinatorics of reportedState and ucState that way.  It should behadoop,   * at least as efficient as boolean expressions.hadoop,   * hadoop,   * @return a BlockToMarkCorrupt object, or null if the replica is not corrupthadoop,   */#475db83b874f5808811d6f2d5be425a6bd14bca5#HDFS-2985. Improve logging when replicas are marked as corrupt. Contributed by Todd Lipcon.#28e8151ad3defc85a4ac1d19b39a9377253c718f#HDFS-3157. Fix a bug in the case that the generation stamps of the stored block in a namenode and the reported block from a datanode do not match.  Contributed by Ashish Singhi
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/ClusterJspHelper.java#getDecommissionNodeClusterState(Map<StringMap<StringString>)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#876fd8ab7913a259ff9f69c16cc2d9af46ad3f9b#2014-04-23 20:13:32#-1#12.0#12.0#14.0#14.0#66.0#66.0#15.0#15.0#3.0#3.0#// Do not display this data node. Remove this entry from status map.  #a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#6420249d47d2828382dc5f9135d9c9c0dcfa965b#HDFS-6252. Phase out the old web UI in HDFS. Contributed by Haohui Mai.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java#allocate(AllocateRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a124297cf016439ee426d3142627606875b9667a#2012-11-01 00:32:37#-1#10.0#11.0#28.0#47.0#56.0#95.0#4.0#8.0#1.0#3.0#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO:#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#6cd0736cc57849e4f7c5d38a3986432a9717fe39#YARN-230. RM Restart phase 1 - includes support for saving/restarting all applications on an RM bounce. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java#allocate(AllocateRequest)#6cd0736cc57849e4f7c5d38a3986432a9717fe39#2012-12-19 04:21:18#f9da5cdb2b2dd071fd60fc01ea1edf0f79c0819b#2015-10-16 15:26:27#-1#11.0#21.0#47.0#106.0#97.0#230.0#8.0#24.0#3.0#3.0#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO: // Reboot is not useful since after AM reboots, it will send register and  // get an exception. Might as well throw an exception here.#6cd0736cc57849e4f7c5d38a3986432a9717fe39#YARN-230. RM Restart phase 1 - includes support for saving/restarting all applications on an RM bounce. Contributed by Bikas Saha.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMDispatcher.java#allocate(AllocateRequest)#9b15c5b11a565251f85b7cb67be6ee0deee6e0d6#2014-03-07 04:34:16#19b645c93801a53d4486f9a7639186525e51f723#2016-03-23 19:34:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO: // Reboot is not useful since after AM reboots, it will send register and  // get an exception. Might as well throw an exception here.#9b15c5b11a565251f85b7cb67be6ee0deee6e0d6#YARN-1525. Web UI should redirect to active RM when HA is enabled. (Cindy Li via kasha)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/tracing/SpanReceiverHost.java#allocate(AllocateRequest)#6962510f729717f776929708813f99a28e582f34#2014-08-27 14:12:05#a1140959dab3f35accbd6c66abfa14f94ff7dcec#2015-05-28 12:00:55#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO: // Reboot is not useful since after AM reboots, it will send register and  // get an exception. Might as well throw an exception here.#6962510f729717f776929708813f99a28e582f34#HDFS-6879. Adding tracing to Hadoop RPC.  Contributed by Masatake Iwasaki.#892ade689f9bcce76daae8f66fc00a49bee8548e#HDFS-9080. Update htrace version to 4.0.1 (cmccabe)
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/records/impl/pb/RMStateVersionPBImpl.java#allocate(AllocateRequest)#6369c8d81972a9a0b6ef41f4508fcb60d34e3d78#2013-11-27 23:22:33#8a8708582091c87e81e90f7a442624ac1e34ed33#2014-07-21 14:43:59#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO: // Reboot is not useful since after AM reboots, it will send register and  // get an exception. Might as well throw an exception here.#6369c8d81972a9a0b6ef41f4508fcb60d34e3d78#YARN-1239. Modified ResourceManager state-store implementations to start storing version numbers. Contributed by Jian He.#1d6e178144e9e3915ceea92d8c5de8b14cd02714#YARN-2347. Consolidated RMStateVersion and NMDBSchemaVersion into Version in yarn-server-common. Contributed by Junping Du.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileContextAcl.java#allocate(AllocateRequest)#8d297687048c41bd3d78a316eea173c1fc0b2f5c#2014-03-11 16:13:43#31617733aca2025cff1ffb841a533a5b1de016a5#2014-06-27 21:45:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Oh damn! Sending reboot isn't enough. RM state is corrupted. TODO: // Reboot is not useful since after AM reboots, it will send register and  // get an exception. Might as well throw an exception here.#8d297687048c41bd3d78a316eea173c1fc0b2f5c#HDFS-5638. HDFS implementation of FileContext API for ACLs. Contributed by Vinayakumar B.#b066be8115eeee3099f4e16259b13063bd3f1104#HDFS-6619. Clean up encryption-related tests. (wang)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java#finishApplication(FinishApplicationRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#2011-10-19 05:21:18#-1#8.0#10.0#16.0#19.0#29.0#38.0#3.0#3.0#1.0#1.0#// TODO: What if null#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#df2991c0cbc3f35c2640b93680667507c4f810dd#MAPREDUCE-3104. Implemented Application-acls. (vinodkv)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferEncryptor.java#getEncryptedStreams(OutputStream,InputStream,BlockPoolTokenSecretManager,String)#9b4a7900c7dfc0590316eedaa97144f938885651#2012-08-07 16:40:03#c2ef7e239eb0e81cf8a3e971378e9e696202de67#2014-03-24 23:32:37#-1#12.0#12.0#19.0#19.0#51.0#51.0#5.0#5.0#2.0#2.0#// This could just be because the client is long-lived and hasn't gotten // a new encryption key from the NN in a while. Upon receiving this // error, the client will get a new encryption key from the NN and retry // connecting to this DN.#9b4a7900c7dfc0590316eedaa97144f938885651#HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.#3b54223c0f32d42a84436c670d80b791a8e9696d#HDFS-2856. Fix block protocol so that Datanodes don't require root or jsvc. Contributed by Chris Nauroth.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java#testReaderWhileAnotherWrites()#939f4a9f92ab260aee697d3715946218a7ff769a#2012-07-25 21:40:17#ef3f3f6bb14cf44bef1778f1091d8ed8a4b764a3#2015-12-18 16:04:47#-1#4.0#3.0#18.0#19.0#57.0#55.0#2.0#1.0#2.0#1.0#// TODO: check results for selectInputStreams with inProgressOK = true. // This doesn't currently work, due to a bug where RedundantEditInputStream // throws an exception if there are any unvalidated in-progress edits in the list! // But, it shouldn't be necessary for current use cases.#939f4a9f92ab260aee697d3715946218a7ff769a#HDFS-3694. Fix getEditLogManifest to fetch httpPort if necessary. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java#testOrchestratedFailures()#939f4a9f92ab260aee697d3715946218a7ff769a#2012-07-25 21:40:17#e08604907c636fd4c0d005d2ea505dae71d41ff3#2012-07-30 23:35:22#-1#4.0#4.0#17.0#17.0#26.0#26.0#2.0#2.0#1.0#1.0#/**hadoop,   * TODO: this test needs to be fleshed out to be an exhaustive failure testhadoop,   * @throws Exceptionhadoop,   */#939f4a9f92ab260aee697d3715946218a7ff769a#HDFS-3694. Fix getEditLogManifest to fetch httpPort if necessary. Contributed by Todd Lipcon.#3a53ef4a802b51e1d5f268f669cd112c03607755#HDFS-3741. Exhaustive failure injection test for skipped RPCs. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDelegationTokenFetcher.java#testReaderWhileAnotherWrites()#5b3481a750aac0d940c2b26db6cb2d0c49954afc#2014-04-02 20:53:01#b48908033fcac7a4bd4313c1fd1457999fba08e1#2015-07-10 15:47:04#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: check results for selectInputStreams with inProgressOK = true. // This doesn't currently work, due to a bug where RedundantEditInputStream // throws an exception if there are any unvalidated in-progress edits in the list! // But, it shouldn't be necessary for current use cases.#5b3481a750aac0d940c2b26db6cb2d0c49954afc#HDFS-5570. Addendum commit for r1584100.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/NMClientAsync.java#start()#edc6d7d3abac3ebad711dda43d7c6a3aeabe025b#2013-05-29 01:41:41#c99925d6dd0235f0d27536f0bebd129e435688fb#2015-11-10 11:45:46#-1#6.0#4.0#12.0#12.0#68.0#68.0#1.0#1.0#0.0#0.0#// TODO: Group launching of multiple containers to a single // NodeManager into a single connection#edc6d7d3abac3ebad711dda43d7c6a3aeabe025b#YARN-422. Add a NM Client library to help application-writers. Contributed by Zhijie Shen.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/HftpFileSystem.java#initialize(URI,Configuration)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#f2f4e9341387199e04679ebc8de5e05c0fdbd437#2011-12-13 18:07:29#-1#15.0#17.0#33.0#34.0#69.0#75.0#10.0#13.0#4.0#4.0#// in case we open connection to hftp of a different cluster // we need to know this cluster https port // if it is not set we assume it is the same cluster or same port#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#9eb8f4d267ca38c16e3ba191a3b754de7d167669#HDFS-2784. Update hftp and hdfs for host-based token support. Contributed by Kihwal Lee.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HftpFileSystem.java#setDelegationToken(Textends,Token<T>)#9eb8f4d267ca38c16e3ba191a3b754de7d167669#2012-02-02 19:04:40#14556cc5d8fee8f8a846e4f65572828553be386c#2014-03-26 21:27:33#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// no need to change service because we aren't exactly sure what it // should be.  we can guess, but it might be wrong if the local conf // value is incorrect.  the service is a client side field, so the remote // end does not care about the value#9eb8f4d267ca38c16e3ba191a3b754de7d167669#HDFS-2784. Update hftp and hdfs for host-based token support. Contributed by Kihwal Lee.#5b3481a750aac0d940c2b26db6cb2d0c49954afc#HDFS-5570. Addendum commit for r1584100.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction.java#convertToInodeFile()#9a0651b4b86727910ae29d055aac6a23490b5ed3#2012-10-22 00:11:25#397835acdf66cf48ebdbc256aa15b6660181c339#2013-01-15 04:33:14#-1#2.0#3.0#9.0#11.0#14.0#9.0#1.0#1.0#0.0#0.0#//TODO SNAPSHOT: may convert to INodeFileWithLink#9a0651b4b86727910ae29d055aac6a23490b5ed3#HDFS-4078. Handle replication in snapshots.#b71d3868908a49c1b2e353afea795a76dfb20f7d#HDFS-4098. Add FileWithSnapshot, INodeFileUnderConstructionWithSnapshot and INodeFileUnderConstructionSnapshot for supporting append to snapshotted files.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/AMRMClientImpl.java#allocate(float)#0a61990855c23ebfa065145fa01084e84781b51c#2013-01-03 19:11:37#51fc7f542747bf87b48580747f51610e52bdc98b#2016-02-12 10:58:09#-1#7.0#19.0#14.0#49.0#53.0#165.0#4.0#19.0#3.0#5.0#// TODO how to differentiate remote yarn exception vs error in rpc#0a61990855c23ebfa065145fa01084e84781b51c#YARN-103. Add a yarn AM-RM client module. Contributed by Bikas Saha.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#606114d6029758f2be130960b8fc3102457406ba#2012-03-26 05:45:29#-1#26.0#27.0#36.0#46.0#69.0#90.0#2.0#2.0#1.0#1.0#//TODO change this to be random#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#fe7711df98b9dd16259f6534e8461a29f24caadc#MAPREDUCE-3942. Randomize master key generation for ApplicationTokenSecretManager and roll it every so often. (Contributed by Vinod Kumar Vavilapalli)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java#nodeHeartbeat(NodeHeartbeatRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#524bc3c33aff301c1a8d60ed8e6a3b240e305045#2016-03-28 11:12:33#-1#15.0#22.0#28.0#36.0#78.0#104.0#6.0#9.0#2.0#2.0#// TODO: Just sending reboot is not enough. Think more.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java#submitApplication(ApplicationSubmissionContext,long)#df2991c0cbc3f35c2640b93680667507c4f810dd#2011-10-20 11:45:38#df2991c0cbc3f35c2640b93680667507c4f810dd#2011-10-20 11:45:38#-1#15.0#15.0#29.0#29.0#60.0#60.0#7.0#7.0#2.0#2.0#// TODO: Weird setup.#df2991c0cbc3f35c2640b93680667507c4f810dd#MAPREDUCE-3104. Implemented Application-acls. (vinodkv)#29c6c3ed328965a73fe7b68eb29cb30794beef38#MAPREDUCE-2977. Fix ResourceManager to renew HDFS delegation tokens for applications.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java#submitApplication(ApplicationSubmissionContext,long)#c074cfd6f0ec695d85a73cddba1404c9db79342e#2012-10-09 01:56:05#6cd0736cc57849e4f7c5d38a3986432a9717fe39#2012-12-19 04:21:18#-1#15.0#15.0#33.0#32.0#74.0#73.0#8.0#8.0#2.0#2.0#// TODO: This needs to move to per-AppAttempt#c074cfd6f0ec695d85a73cddba1404c9db79342e#YARN-134. Fixes ClientToAMSecretManager creates keys without checking for validity of the appID. (Contributed by Vinod Kumar Vavilapalli)#6a2f2551fd13f6d3c932cc9b592e2a23b616a7f5#YARN-135. Client tokens should be per app-attempt, and should be unregistered on App-finish. Contributed by Vinod Kumar Vavilapalli
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/test/java/org/apache/hadoop/mapreduce/v2/hs/TestJobHistoryEvents.java#verifyAttempt(TaskAttempt)#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#2011-10-19 05:21:18#06c15b6a3e07bfbdb5ef4db697737a7b0765da74#2014-04-21 23:44:41#-1#3.0#5.0#7.0#8.0#8.0#11.0#1.0#1.0#0.0#0.0#//Verify the wrong ctor is not being used. Remove after mrv1 is removed.#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/java/org/apache/hadoop/mapred/nativetask/handlers/BufferPuller.java#verifyAttempt(TaskAttempt)#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#2014-07-17 17:44:55#683987be7c160e67ddb8534eeb3c464bbe2796dd#2014-09-03 13:07:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//Verify the wrong ctor is not being used. Remove after mrv1 is removed.#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#Import initial code for MAPREDUCE-2841 (native output collector)##
hadoop#DESIGN#src/test/core/org/apache/hadoop/fs/TestHardLink.java#testWindowsSyntax()#527bac7e2265548d8611723109f7f91b629079ed#2011-03-10 23:33:52#db51548f706ccd2d0200745ab89e27610c6d10bc#2015-01-15 20:54:44#-1#5.0#1.0#4.0#4.0#22.0#14.0#1.0#1.0#0.0#0.0#/*hadoop,   * Assume that this test won't usually be run on a Windows box.hadoop,   * This test case allows testing of the correct syntax of the Windowshadoop,   * commands, even though they don't actually get executed on a non-Win box.hadoop,   * The basic idea is to have enough here that substantive changes willhadoop,   * fail and the author will fix and add to this test as appropriate.hadoop,   * hadoop,   * Depends on the HardLinkCGWin class and member fields being accessiblehadoop,   * from this test method.hadoop,   */#527bac7e2265548d8611723109f7f91b629079ed#HADOOP-7133. Batch the calls in DataStorage to FileUtil.createHardLink().  Contributed by Matt Foley.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/test/java/org/apache/hadoop/mapreduce/v2/hs/TestJobHistoryParsing.java#testHistoryParsing()#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#2011-10-19 05:21:18#7af4c3888bf7be0822dc880170e5e3d09e9280f1#2014-09-24 16:09:33#-1#5.0#17.0#74.0#98.0#131.0#222.0#6.0#13.0#2.0#3.0#//Verify the wrong ctor is not being used. Remove after mrv1 is removed.#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/java/org/apache/hadoop/mapred/nativetask/handlers/BufferPushee.java#checkHistoryParsing(int,int,int)#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#2014-07-17 17:44:55#683987be7c160e67ddb8534eeb3c464bbe2796dd#2014-09-03 13:07:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Verify the wrong ctor is not being used. Remove after mrv1 is removed.#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#Import initial code for MAPREDUCE-2841 (native output collector)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/recover/RecoveryService.java#handle(Event)#ade0f0560f729e50382c6992f713f29e2dd5b270#2011-08-31 11:38:32#408656614495674992349fbda3981559ada3de0b#2011-10-24 08:41:48#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO need to get the real port number MAPREDUCE-2666#ade0f0560f729e50382c6992f713f29e2dd5b270#MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.#a5037559905db131efaa590a605001a7361098bf#MAPREDUCE-3249. Ensure shuffle-port is correctly used duringMR AM recovery. Contributed by Vinod K V.
hadoop#DESIGN#mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java#setJobConf()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cc70df98e74142331043a611a3bd8a53ff6a2242#2015-06-03 18:41:45#-1#30.0#31.0#58.0#58.0#251.0#250.0#45.0#45.0#4.0#4.0#// The correct FS must be set before this is called! // (to resolve local vs. dfs drive letter differences)  // (mapreduce.job.working.dir will be lazily initialized ONCE and depends on FS)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper.java#dumpAllContainersLogs(ApplicationId,DataOutputStream)#670fa24b48acb407c22fbfdde87ae3123dcbf449#2011-10-28 06:45:04#34ef1a092bcab369bb845481efffb8c47adef53a#2015-09-15 14:36:30#-1#6.0#-1#17.0#-1#44.0#-1#5.0#-1#5.0#-1#//TODO Change this to get a list of files from the LAS.#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/Dispatcher.java#service(HttpServletRequest,HttpServletResponse)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d9cdcb9474528733c488d4a5c73d2e4abb1af6fb#2014-03-14 02:39:59#-1#21.0#21.0#32.0#36.0#80.0#90.0#16.0#18.0#3.0#3.0#// quick hack to restart servers in dev mode without OS commands#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/Dispatcher.java#service(HttpServletRequest,HttpServletResponse)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d9cdcb9474528733c488d4a5c73d2e4abb1af6fb#2014-03-14 02:39:59#-1#21.0#21.0#32.0#36.0#80.0#90.0#16.0#18.0#3.0#3.0#// TODO: support args converted from /path/:arg1/...#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/webapp/ContainerBlock.java#service(HttpServletRequest,HttpServletResponse)#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#85f6d67fa78511f255fcfa810afc9a156a7b483b#2015-03-11 19:35:19#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// quick hack to restart servers in dev mode without OS commands#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/webapp/ContainerBlock.java#service(HttpServletRequest,HttpServletResponse)#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#85f6d67fa78511f255fcfa810afc9a156a7b483b#2015-03-11 19:35:19#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: support args converted from /path/:arg1/...#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java#testReportChecksumFailure()#5c791948de6e768032d6fe1278c915661d0eb14b#2013-02-01 21:09:05#0ef7ff47d5d031783ce61e93d36dc30703b5b28b#2015-09-23 19:33:55#-1#2.0#2.0#21.0#21.0#71.0#71.0#4.0#4.0#2.0#2.0#// this is a hack to force the reportChecksumFailure() method to stop // climbing up at the 'base' directory and use 'dir1/bad_files' as the  // corrupted files storage:#5c791948de6e768032d6fe1278c915661d0eb14b#HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockInfo.java#testBlockListMoveToHead()#db13c99940136b05424393fcfc16a1846bc11f5c#2011-11-04 21:49:15#dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a#2016-02-02 11:23:00#-1#2.0#-1#19.0#-1#78.0#-1#6.0#-1#1.0#-1#// move head of the list to the head - this should not change the list#db13c99940136b05424393fcfc16a1846bc11f5c#Add the missing test file to HDFS-2477.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java#registerDatanode(DatanodeRegistration)#233a7aa34f37350bf7bcdd9c84b97d613e7344c9#2011-07-22 04:20:21#fde8ac5d8514f5146f438f8d0794116aaef20416#2016-03-25 17:10:31#-1#8.0#25.0#37.0#54.0#117.0#159.0#10.0#14.0#3.0#4.0#// The same datanode has been just restarted to serve the same data  // storage. We do not need to remove old data blocks, the delta will // be calculated on the next block report from the datanode#233a7aa34f37350bf7bcdd9c84b97d613e7344c9#HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestLinuxResourceCalculatorPlugin.java#testParsingProcStatAndCpuFile()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#6.0#6.0#11.0#11.0#51.0#51.0#2.0#2.0#1.0#1.0#// Advance very short period of time (one jiffy length). // In this case, CPU usage should not be updated.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#d41e67b966b4ced602ae27e6ccc6a73cd4068a05#MAPREDUCE-5077. Remove mapreduce.util.ResourceCalculatorPlugin and related code. Contributed by Karthik Kambatla.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/webapp/Router.java#addController(WebApp.HTTP,String,Class<?extendsController>,String,List<String>)#e16f8a9fdfc37a9dc3b0c45fafd0195dc97b811c#2011-09-19 22:51:46#d9cdcb9474528733c488d4a5c73d2e4abb1af6fb#2014-03-14 02:39:59#-1#8.0#8.0#7.0#7.0#26.0#26.0#4.0#4.0#2.0#2.0#// Look for the method in all public methods declared in the class // or inherited by the class. // Note: this does not distinguish methods with the same signature // but different return types. // TODO: We may want to deal with methods that take parameters in the future#e16f8a9fdfc37a9dc3b0c45fafd0195dc97b811c#MAPREDUCE-3038. job history server not starting because conf() missing HsController (Jeffrey Naisbitt via mahadev)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/security/ContainerTokenSecretManager.java#createContainerToken(ContainerId,NodeId,Resource)#3bfb26ad3b5ac46f992a632541c97ca2bc897638#2012-07-10 21:26:48#e1fdf62123625e4ba399af02f8aad500637d29d1#2012-08-08 05:22:27#-1#8.0#9.0#8.0#8.0#18.0#18.0#2.0#2.0#1.0#1.0#// this could be because DNS is down - in which case we just want // to retry and not bring RM down. Caller should note and act on the fact // that container is not creatable.#3bfb26ad3b5ac46f992a632541c97ca2bc897638#MAPREDUCE-3940. ContainerTokens should have an expiry interval. Contributed by Siddharth Seth and Vinod Kumar Vavilapalli.#ffd2e01604be814fa3db1dded7cd7cff26a79b1e#YARN-39. RM-NM secret-keys should be randomly generated and rolled every so often. (Contributed by Vinod Kumar Vavilapalli and Siddharth Seth)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/client/ClientToAMSecretManager.java#getMasterKey(ApplicationTokenIdentifier)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e1fdf62123625e4ba399af02f8aad500637d29d1#2012-08-08 05:22:27#-1#5.0#5.0#5.0#5.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO: Handle the masterKey invalidation.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#c074cfd6f0ec695d85a73cddba1404c9db79342e#YARN-134. Fixes ClientToAMSecretManager creates keys without checking for validity of the appID. (Contributed by Vinod Kumar Vavilapalli)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKStore.java#createNodeManagerInfo(RMNode)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e1fdf62123625e4ba399af02f8aad500637d29d1#2012-08-08 05:22:27#-1#4.0#3.0#8.0#8.0#12.0#12.0#1.0#1.0#0.0#0.0#// TODO: FIXME //    node.setUsed(nodeInfo.getUsedResource()); // TODO: acm: refactor2 FIXME //  node.setNumContainers(rmNode.getNumContainers());#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1943fdbec613715f3cdc3ca60cbd273115f28299#YARN-229. Remove old unused RM recovery code. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKStore.java#storeNode(RMNode)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#3.0#3.0#18.0#18.0#2.0#2.0#1.0#1.0#// TODO FinBugs - will be fixed after the subsequent fixme#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1f46b991da9b91585608a0babd3eda39485dce09#MAPREDUCE-2908. Fix all findbugs warnings. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKStore.java#removeNode(RMNode)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e1fdf62123625e4ba399af02f8aad500637d29d1#2012-08-08 05:22:27#-1#1.0#1.0#0.0#0.0#16.0#16.0#2.0#2.0#1.0#1.0#//    TODO: FIXME VINODKV //    /** remove a storage node **/#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1943fdbec613715f3cdc3ca60cbd273115f28299#YARN-229. Remove old unused RM recovery code. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKStore.java#getNextNodeId()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e1fdf62123625e4ba399af02f8aad500637d29d1#2012-08-08 05:22:27#-1#1.0#1.0#1.0#1.0#15.0#15.0#1.0#1.0#0.0#0.0#//    TODO: FIXME VINODKV //    int num = nodeId.getId(); //    num++; //    nodeId.setId(num);#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1943fdbec613715f3cdc3ca60cbd273115f28299#YARN-229. Remove old unused RM recovery code. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKStore.java#load()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: FindBugs Valid. Fix#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#1f46b991da9b91585608a0babd3eda39485dce09#MAPREDUCE-2908. Fix all findbugs warnings. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/test/java/org/apache/hadoop/yarn/lib/TestZKClient.java#createTmpDir(File)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#7944eab64a3aa28c5abb8b4cc1574eb6d0e91324#2014-03-17 20:03:35#-1#2.0#2.0#6.0#6.0#9.0#9.0#1.0#1.0#0.0#0.0#// don't delete tmpFile - this ensures we don't attempt to create // a tmpDir with a duplicate name#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#mapreduce/src/contrib/raid/src/java/org/apache/hadoop/raid/BlockFixer.java#sortCorruptFiles(List<Path>)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#277b3dd7369e0462888c9e09a7790da38f691ebc#2012-06-19 00:55:28#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: We should first fix the files that lose more blocks#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#370c65f2827862dff9cdbbdee3e3540eb4767f88#Revert MAPREDUCE-3868. Reenable Raid.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientCache.java#getClient(JobID)#f2b91a8367a762091482074505618b570a520b19#2011-08-25 06:35:58#59a212b6e1265adfa9b55c71b65a22157dfccf77#2016-02-01 16:05:06#-1#15.0#16.0#8.0#8.0#16.0#16.0#4.0#4.0#2.0#2.0#//TODO: evict from the cache on some threshold#f2b91a8367a762091482074505618b570a520b19# MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientCache.java#instantiateHistoryProxy()#f2b91a8367a762091482074505618b570a520b19#2011-08-25 06:35:58#fafe8cd28e726566509c679e19d7da622f29f90d#2011-09-09 01:44:58#-1#6.0#7.0#8.0#8.0#14.0#14.0#1.0#1.0#0.0#0.0#//TODO This should ideally be using it's own class (instead of ClientRMSecurityInfo)#f2b91a8367a762091482074505618b570a520b19# MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.#cb48bc1c93a4a1d8b2b936982a5e6b18494b5956#MAPREDUCE-3007. Fixed Yarn Mapreduce client to be able to connect to JobHistoryServer in secure mode. Contributed by Vinod Kumar Vavilapalli.
hadoop#DESIGN#src/test/org/apache/hadoop/fs/TestTruncatedInputBug.java#testTruncatedInputBug()#abe7be913432053f6d419ea4ca4f9cd2be938bc7#2009-05-19 04:35:56#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#1.0#1.0#16.0#15.0#57.0#57.0#6.0#6.0#3.0#3.0#// Now set mark() to trigger the bug // NOTE: in the fixed code, mark() does nothing (not supported) and //   hence won't trigger this bug.#abe7be913432053f6d419ea4ca4f9cd2be938bc7#HADOOP-4687 Moving directories around##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java#instantiateHistoryProxy(String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#6.0#6.0#7.0#7.0#12.0#12.0#1.0#1.0#0.0#0.0#//TODO This should ideally be using it's own class (instead of ClientRMSecurityInfo)#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#f2b91a8367a762091482074505618b570a520b19# MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ClientServiceDelegate.java#getJobStatus(JobID)#f2b91a8367a762091482074505618b570a520b19#2011-08-25 06:35:58#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#5.0#10.0#9.0#9.0#14.0#12.0#1.0#1.0#0.0#0.0#//TODO: add tracking url in JobReport#f2b91a8367a762091482074505618b570a520b19# MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java#setupTokensInEnv(ApplicationSubmissionContext)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cf23f2c2b5b4eb9e51de1a66b7aa57dee7ff30b5#2015-10-15 17:12:36#-1#11.0#7.0#30.0#24.0#53.0#34.0#3.0#3.0#2.0#1.0#// TODO: Security enabled/disabled info should come from RM.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java#setupTokensInEnv(ApplicationSubmissionContext)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cf23f2c2b5b4eb9e51de1a66b7aa57dee7ff30b5#2015-10-15 17:12:36#-1#11.0#7.0#30.0#24.0#53.0#34.0#3.0#3.0#2.0#1.0#// TODO: Don't do this kind of checks everywhere.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/NotRunningJob.java#getJobReport(GetJobReportRequest)#6bdf5746d5d677f9c17598768c4ae86384c000c6#2011-09-03 06:22:03#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#5.0#5.0#7.0#7.0#14.0#14.0#1.0#1.0#0.0#0.0#// TODO: Add jobName & other job information that is available#6bdf5746d5d677f9c17598768c4ae86384c000c6#MAPREDUCE-2716. MRReliabilityTest job fails because of missing job-file. Contributed by Jeffrey Naisbitt.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/NotRunningJob.java#getConnectAddress()#aa60da6c2ec049cc70897afee6c368cb70493773#2012-05-08 15:07:40#6529c87551e07e9da1e1b273eff4c6bad6b3e838#2016-03-15 17:28:40#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#/* Should not be invoked by anyone.  Normally used to set token service */#aa60da6c2ec049cc70897afee6c368cb70493773#MAPREDUCE-4162. Correctly set token service (Daryn Sharp via bobby)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ResourceMgrDelegate.java#getBlacklistedTrackers()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9875325d5c63f343809907d06bf48a298035a611#2016-02-02 10:17:33#-1#2.0#2.0#2.0#2.0#6.0#6.0#1.0#1.0#0.0#0.0#// TODO: Implement getBlacklistedTrackers#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ResourceMgrDelegate.java#getDelegationToken(Text)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9b75b051634fcb1ff85613ef6a16a36cef69e524#2011-12-12 23:56:26#-1#2.0#2.0#2.0#2.0#6.0#6.0#1.0#1.0#0.0#0.0#// TODO: Implement getDelegationToken#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#bc4b1f48d3aba7f7a324ae76ab65a0920b1e609e#MAPREDUCE-3380. Token infrastructure for running clients which are not kerberos authenticated. (mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/ResourceMgrDelegate.java#renewDelegationToken(Token<DelegationTokenIdentifier>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#aa049397f1c32ea7821de95ed76e62fbebdfc429#2012-09-05 19:34:03#-1#2.0#2.0#2.0#2.0#6.0#6.0#1.0#1.0#0.0#0.0#// TODO: Implement renewDelegationToken#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#e17cecf5505dddb92e2212147505c7c900184431#MAPREDUCE-4894. Renewal / cancellation of JobHistory tokens (Siddharth Seth via tgraves
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#createApplicationSubmissionContext(Configuration,String,Credentials)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#59a212b6e1265adfa9b55c71b65a22157dfccf77#2016-02-01 16:05:06#-1#27.0#77.0#44.0#75.0#106.0#246.0#5.0#12.0#1.0#2.0#// TODO gross hack#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#createApplicationSubmissionContext(Configuration,String,Credentials)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#2011-09-13 00:05:51#-1#27.0#27.0#44.0#44.0#106.0#106.0#5.0#5.0#1.0#1.0#// TODO - Remove this!#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#createApplicationSubmissionContext(Configuration,String,Credentials)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#2011-09-13 00:05:51#-1#27.0#27.0#44.0#44.0#106.0#106.0#5.0#5.0#1.0#1.0#// TODO: RM should get this from RPC.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#parseTimeStamps(String[])#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#2011-09-13 00:05:51#-1#2.0#2.0#2.0#2.0#10.0#10.0#3.0#3.0#1.0#1.0#/**hadoop,   *    * TODO: Copied for now from TaskAttemptImpl.java ... fixmehadoop,   * @param strshadoop,   * @returnhadoop,   */#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#setupDistributedCache(Configuration,ApplicationSubmissionContext)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#2011-09-13 00:05:51#-1#7.0#7.0#11.0#11.0#19.0#19.0#1.0#1.0#0.0#0.0#/**hadoop,   * TODO: Copied for now from TaskAttemptImpl.java ... fixmehadoop,   * hadoop,   * TODO: This is currently needed in YarnRunner as user code like setupJob,hadoop,   * cleanupJob may need access to dist-cache. Once we separate distcache forhadoop,   * maps, reduces, setup etc, this can include only a subset of artificats.hadoop,   * This is also needed for uberAM case where we run everything inside AM.hadoop,   */#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#getFileSizes(Configuration,String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#2011-09-13 00:05:51#-1#3.0#3.0#3.0#3.0#11.0#11.0#3.0#3.0#1.0#1.0#// TODO - Move this to MR!#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java#createApplicationSubmissionContext(Configuration,String,Credentials)#ab787f44aabfff0cd01b79a08a52ffaf923558b3#2011-10-18 21:45:38#59a212b6e1265adfa9b55c71b65a22157dfccf77#2016-02-01 16:05:06#-1#33.0#77.0#44.0#75.0#121.0#246.0#5.0#12.0#1.0#2.0#// TODO: why do we use 'conf' some places and 'jobConf' others?#ab787f44aabfff0cd01b79a08a52ffaf923558b3#MAPREDUCE-3165. Ensure logging options are set correctly for MR AM and tasks. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DefaultContainerExecutor.java#startLocalizer(Path,InetSocketAddress,String,String,String,List<Path>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d7fdec1e6b465395d2faca6e404e329d20f6c3d8#2016-02-25 16:35:58#-1#8.0#-1#14.0#-1#24.0#-1#1.0#-1#0.0#-1#// TODO: Why pick first app dir. The same in LCE why not random?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DefaultContainerExecutor.java#startLocalizer(Path,InetSocketAddress,String,String,String,List<Path>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d7fdec1e6b465395d2faca6e404e329d20f6c3d8#2016-02-25 16:35:58#-1#8.0#-1#14.0#-1#24.0#-1#1.0#-1#0.0#-1#// TODO: DO it over RPC for maintaining similarity?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DeletionService.java#delete(String,Path,Path...)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO if parent owned by NM, rename within parent inline#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#mapreduce/src/test/aop/org/apache/hadoop/fi/ProbabilityModel.java#injectCriteria(String)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#10325d97329c214bb3899c8535df5a366bc86d2f#2012-01-18 22:10:12#-1#2.0#2.0#3.0#3.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO fix this: make it more sophisticated!!!#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/buffer/TestByteBufferReadWrite.java#injectCriteria(String)#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#2014-07-17 17:44:55#7c91f9b1484d487e792dca051fbd418697049422#2014-09-05 13:41:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO fix this: make it more sophisticated!!!#b2551c06a09fb80a9e69adbc01c4c34b93ad0139#Import initial code for MAPREDUCE-2841 (native output collector)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DefaultContainerExecutor.java#startLocalizer(Path,InetSocketAddress,String,String,String,List<Path>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#dfcbbddb0963c89c0455d41223427165b9f9e537#2015-12-14 11:13:22#-1#8.0#-1#14.0#-1#24.0#-1#1.0#-1#0.0#-1#// TODO: Why pick first app dir. The same in LCE why not random?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DefaultContainerExecutor.java#startLocalizer(Path,InetSocketAddress,String,String,String,List<Path>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#dfcbbddb0963c89c0455d41223427165b9f9e537#2015-12-14 11:13:22#-1#8.0#-1#14.0#-1#24.0#-1#1.0#-1#0.0#-1#// TODO: DO it over RPC for maintaining similarity?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d284e187b8db43056236032ebc2114ee462c27f6#2016-02-23 20:49:09#-1#6.0#19.0#18.0#47.0#52.0#88.0#2.0#3.0#0.0#1.0#// TODO add local dirs to del#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/metrics/SystemMetricsPublisher.java#serviceInit(Configuration)#6b8b1608e64e300e4e1d23c60476febaca29ca38#2014-09-12 10:04:51#f385851141522633184ce394899c659af5ace92a#2016-01-18 16:58:39#-1#10.0#10.0#10.0#10.0#21.0#21.0#2.0#2.0#1.0#1.0#// TODO add local dirs to del#6b8b1608e64e300e4e1d23c60476febaca29ca38#YARN-2033. Merging generic-history into the Timeline Store (Contributed by Zhijie Shen)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/CompressionEmulationUtil.java#map(NullWritable,LongWritable,Context)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#c4cba6165a3afbf4f1f8ff6b7f11286772d70d6f#2015-01-12 21:22:58#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Control the extra data written .. //TODO Should the key\tvalue\n be considered for measuring size? //     Can counters like BYTES_WRITTEN be used? What will be the value of //     such counters in LocalJobRunner?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/CompressionEmulationUtil.java#getPossiblyDecompressedInputStream(Path,Configuration,long)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#c4cba6165a3afbf4f1f8ff6b7f11286772d70d6f#2015-01-12 21:22:58#-1#7.0#7.0#10.0#10.0#25.0#25.0#4.0#4.0#3.0#3.0#//TODO Seek doesnt work with compressed input stream.  //     Use SplittableCompressionCodec?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java#getNodeStatus()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fafe8cd28e726566509c679e19d7da622f29f90d#2011-09-09 01:44:58#-1#10.0#10.0#27.0#27.0#49.0#49.0#5.0#5.0#2.0#2.0#// TODO: don't set everytime.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#817ead65b99f465fc2dfa18072cf23cadf5f05d0#MAPREDUCE-2933. Change allocate call to return ContainerStatus for completed containers rather than Container.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java#startStatusUpdater()#670fa24b48acb407c22fbfdde87ae3123dcbf449#2011-10-28 06:45:04#92b7e0d41302b6b110927f99de5c2b4a4a93c5fd#2016-03-18 16:11:06#-1#1.0#3.0#1.0#3.0#42.0#161.0#1.0#1.0#0.0#0.0#// TODO Better error handling. Thread can die with the rest of the // NM still running.#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/nodelabels/RMNodeLabelsManager.java#startStatusUpdater()#db7f1653198b950e89567c06898d64f6b930a0ee#2014-10-10 11:44:21#29a582ada0fe195989eca25e5a995895e178f4ea#2015-10-06 11:55:51#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Better error handling. Thread can die with the rest of the // NM still running.#db7f1653198b950e89567c06898d64f6b930a0ee#YARN-2494. Added NodeLabels Manager internal API and implementation. Contributed by Wangda Tan.##
hadoop#DESIGN#mapreduce/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/dfs/DFSFolder.java#upload(IProgressMonitor,File)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#4.0#4.0#10.0#10.0#22.0#22.0#5.0#5.0#3.0#3.0#// XXX don't know what the file is?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#readNextPacket()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#83cf475050dba27e72b4e399491638c670621175#2012-05-30 19:10:09#-1#10.0#10.0#15.0#16.0#78.0#79.0#12.0#12.0#2.0#2.0#/* This dances around buf a little bit, mainly to read hadoop,     * full packet with single read and to accept arbitarary size  hadoop,     * for next packet at the same time.hadoop,     */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#e0ef844280b98dc699ed3f9d948b83828bb8d297#HDFS-3170. Add more useful metrics for write latency. Contributed by Matthew Jacobs.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#readNextPacket()#e0ef844280b98dc699ed3f9d948b83828bb8d297#2012-07-05 22:18:30#0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9#2012-07-16 02:58:03#-1#10.0#10.0#16.0#16.0#79.0#79.0#12.0#12.0#2.0#2.0#/* This dances around buf a little bit, mainly to read hadoop,     * full packet with single read and to accept arbitrary size  hadoop,     * for next packet at the same time.hadoop,     */#e0ef844280b98dc699ed3f9d948b83828bb8d297#HDFS-3170. Add more useful metrics for write latency. Contributed by Matthew Jacobs.#9ea7c06468d236452f03c38a31d1a45f7f09dc50#HDFS-3721. hsync support broke wire compatibility. Contributed by Todd Lipcon and Aaron T. Myers.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java#verifyChunks(ByteBuffer,ByteBuffer)#98a692fd6361365db4afb9523a5d83ee32774112#2013-05-21 13:42:23#a7d8f2b3960d27c74abb17ce2aa4bcd999706ad2#2016-03-22 14:56:02#-1#12.0#12.0#6.0#6.0#21.0#21.0#4.0#4.0#3.0#3.0#// No need to report to namenode when client is writing.#98a692fd6361365db4afb9523a5d83ee32774112#HDFS-3875. Issue handling checksum errors in write pipeline. Contributed by Kihwal Lee.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/diff/Diff.java#modify(E,E)#a3bf2083867db5d848ea14f145d120f02b820af2#2013-01-26 00:01:51#43bdc22e9207a74678665de5f109dd7e56fe979a#2013-04-22 22:13:58#-1#7.0#9.0#9.0#8.0#25.0#25.0#3.0#3.0#2.0#2.0#//TODO: fix a bug that previous != oldElement.Set it to oldElement for now#a3bf2083867db5d848ea14f145d120f02b820af2#HDFS-4441. Move INodeDirectoryWithSnapshot.Diff and the related classes to a package.#65752c09ab4c070fbb7013c785d0db1dccd55d8f#HDFS-4735. DisallowSnapshot throws IllegalStateException for nested snapshottable directories.  Contributed by Jing Zhao
hadoop#DESIGN#mapreduce/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/launch/HadoopApplicationLaunchShortcut.java#findLaunchConfiguration(IType,ILaunchConfigurationType)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#4.0#4.0#20.0#20.0#66.0#66.0#7.0#7.0#2.0#2.0#// FIXME Error dialog#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/Application.java#getResources()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#22a2b2231d2601eb8743cc2801653e7612123f48#2016-02-04 13:48:22#-1#6.0#6.0#11.0#17.0#32.0#34.0#2.0#5.0#1.0#2.0#// TODO: Fix //       resourceManager.getRMContext().getRMApps() //        .get(applicationId).getRMAppAttempt(applicationAttemptId) //        .pullNewlyAllocatedContainers();#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#reportBadBlocks(ExtendedBlock)#39ce694d05c6d8c428bd87bc1b9c95f94dfdf6fd#2011-11-21 19:27:00#8be9441b9b13bea6e23c2cbcf638162c93052740#2012-02-11 01:20:59#-1#6.0#6.0#5.0#5.0#15.0#15.0#2.0#2.0#1.0#1.0#/* One common reason is that NameNode could be in safe mode.hadoop,       * Should we keep on retrying in that case?hadoop,       */#39ce694d05c6d8c428bd87bc1b9c95f94dfdf6fd#HDFS-2566. Move BPOfferService to be a non-inner class. Contributed by Todd Lipcon.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#isInitialized()#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#b3f28dbb3d1ab6b2f686efdd7bdb064426177f21#2011-12-05 06:36:00#-1#3.0#3.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO(HA) is this right?#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#6016e95feec93f0e17a8a1370c0ede735ca13f55#HDFS-2627. Determine DN's view of which NN is active based on heartbeat responses. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#isAlive()#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#b3f28dbb3d1ab6b2f686efdd7bdb064426177f21#2011-12-05 06:36:00#-1#6.0#6.0#2.0#2.0#5.0#5.0#1.0#1.0#0.0#0.0#// TODO: should || all the bp actors probably?#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#6016e95feec93f0e17a8a1370c0ede735ca13f55#HDFS-2627. Determine DN's view of which NN is active based on heartbeat responses. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#shutdownActor(BPServiceActor)#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#846f97312c6db7b84b7401174acd0fc943baa093#2012-01-30 19:16:15#-1#6.0#6.0#5.0#5.0#15.0#15.0#4.0#4.0#2.0#2.0#// TODO: synchronization should be a little better here#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#28eadb7cd71e99d563fb5c41aec563ab11e293e5#HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#getActiveNN()#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#846f97312c6db7b84b7401174acd0fc943baa093#2012-01-30 19:16:15#-1#3.0#4.0#1.0#1.0#3.0#7.0#1.0#2.0#0.0#1.0#/**hadoop,   * TODO: this is still used in a few places where we need to sort outhadoop,   * what to do in HA!hadoop,   * @return a proxy to the active NNhadoop,   */#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#28eadb7cd71e99d563fb5c41aec563ab11e293e5#HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#processCommandFromActive(DatanodeCommand,BPServiceActor)#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#846f97312c6db7b84b7401174acd0fc943baa093#2012-01-30 19:16:15#-1#22.0#22.0#26.0#26.0#77.0#77.0#16.0#16.0#3.0#3.0#// TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#28eadb7cd71e99d563fb5c41aec563ab11e293e5#HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#processCommandFromActive(DatanodeCommand,BPServiceActor)#978a8050e28b2afb193a3e00d82a8475fa4d2428#2012-02-29 01:09:07#2759689d7d23001f007cb0dbe2521de90734dd5c#2016-03-04 15:29:50#-1#22.0#21.0#26.0#34.0#78.0#90.0#16.0#16.0#3.0#2.0#// TODO: DNA_SHUTDOWN appears to be unused - the NN never sends this command // See HDFS-2987.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java#reportBadBlocks(ExtendedBlock)#39ce694d05c6d8c428bd87bc1b9c95f94dfdf6fd#2011-11-21 19:27:00#c2140d05efaf18b41caae8c61d9f6d668ab0e874#2016-03-07 21:10:24#-1#6.0#-1#5.0#-1#15.0#-1#2.0#-1#1.0#-1#/* One common reason is that NameNode could be in safe mode.hadoop,       * Should we keep on retrying in that case?hadoop,       */#39ce694d05c6d8c428bd87bc1b9c95f94dfdf6fd#HDFS-2566. Move BPOfferService to be a non-inner class. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java#sendHeartBeat()#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#8dbb5237684bb9de78430b5cef27be40c78a8474#2011-12-01 08:03:41#-1#6.0#6.0#12.0#12.0#12.0#12.0#1.0#1.0#0.0#0.0#// TODO: saw an NPE here - maybe if the two BPOS register at // same time, this one won't block on the other one?#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#b3f28dbb3d1ab6b2f686efdd7bdb064426177f21#HDFS-2626. BPOfferService.verifyAndSetNamespaceInfo needs to be synchronized. Contributed by Todd Lipcon.
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/GridmixRecord.java#writeRandomText(DataOutput,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#dcf84707ab50662add112bd6b01c0bfd63374853#2012-05-17 15:06:33#-1#5.0#5.0#4.0#4.0#26.0#26.0#3.0#3.0#1.0#1.0#//TODO Should we use long for size. What if the data is more than 4G?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/GridmixRecord.java#write(DataOutput)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#dcf84707ab50662add112bd6b01c0bfd63374853#2012-05-17 15:06:33#-1#5.0#5.0#5.0#5.0#15.0#15.0#4.0#4.0#2.0#2.0#//TODO What is compressible is turned on? LOG is a bad idea!#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#reportBadBlocks(ExtendedBlock)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#67f25b0a1bec03da5eb556fdf2bb004ef6e1ba1e#2011-11-20 15:18:14#-1#5.0#5.0#3.0#3.0#7.0#7.0#2.0#2.0#1.0#1.0#/* One common reason is that NameNode could be in safe mode.hadoop,         * Should we keep on retrying in that case?hadoop,         */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#39ce694d05c6d8c428bd87bc1b9c95f94dfdf6fd#HDFS-2566. Move BPOfferService to be a non-inner class. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#registerBlockPoolWithSecretManager(DatanodeRegistration,String)#0864ef19089f703232107d8aa26c4a7571ff132e#2011-11-18 00:45:31#527933f4f351a3df5e369c8bb6e2cfc4937e0836#2012-07-16 21:26:58#-1#8.0#7.0#10.0#10.0#25.0#30.0#3.0#5.0#1.0#2.0#// TODO should we check that all federated nns are either enabled or // disabled?#0864ef19089f703232107d8aa26c4a7571ff132e#HDFS-2560. Refactor BPOfferService to be a static inner class. Contributed by Todd Lipcon.#9b4a7900c7dfc0590316eedaa97144f938885651#HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#getDNRegistrationByMachineName(String)#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#c14912785d22734d735b5c4f8638b57dff009a97#2012-02-22 20:31:52#-1#4.0#4.0#4.0#4.0#12.0#12.0#3.0#3.0#2.0#2.0#// TODO: all the BPs should have the same name as each other, they all come // from getName() here! and the use cases only are in tests where they just // call with getName(). So we could probably just make this method return // the first BPOS's registration#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#syncBlock(RecoveringBlock,List<BlockRecord>)#1e346aa829519f8a2aa830e76d9856f914861805#2011-12-01 01:10:28#846f97312c6db7b84b7401174acd0fc943baa093#2012-01-30 19:16:15#-1#19.0#19.0#28.0#28.0#107.0#108.0#20.0#20.0#3.0#3.0#// TODO: how does this work in HA??#1e346aa829519f8a2aa830e76d9856f914861805#HDFS-1971. Send block report from datanode to both active and standby namenodes. (sanjay, todd via suresh)#da7b0d90c68d60492f49627186f1be42919880ff#HDFS-2868. Expose xceiver counts via the DataNode MXBean. (harsh)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java#getDNRegistrationByMachineName(String)#978a8050e28b2afb193a3e00d82a8475fa4d2428#2012-02-29 01:09:07#8bd825bb6f35fd6fef397e3ccae0898bf7bed201#2012-03-31 19:58:51#-1#4.0#4.0#4.0#4.0#12.0#12.0#3.0#3.0#2.0#2.0#// TODO: all the BPs should have the same name as each other, they all come // from getName() here! and the use cases only are in tests where they just // call with getName(). So we could probably just make this method return // the first BPOS's registration. See HDFS-2609.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.#0663dbaac0a19719ddf9cd4290ba893bfca69da2#HDFS-3171. The DatanodeID "name" field is overloaded. Contributed by Eli Collins
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderFactory.java#newBlockReader(Params)#239b2742d0e80d13c970fd062af4930e672fe903#2013-01-08 20:44:09#239b2742d0e80d13c970fd062af4930e672fe903#2013-01-08 20:44:09#-1#10.0#10.0#10.0#10.0#25.0#25.0#2.0#2.0#1.0#1.0#// The legacy BlockReader doesn't require that the Peers it uses // have associated ReadableByteChannels.  This makes it easier to use  // with some older Socket classes like, say, SocksSocketImpl. // // TODO: create a wrapper class that makes channel-less sockets look like // they have a channel, so that we can finally remove the legacy // RemoteBlockReader.  See HDFS-2534.#239b2742d0e80d13c970fd062af4930e672fe903#HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.#837e17b2eac1471d93e2eff395272063b265fee7#svn merge -c -1430507 . for reverting HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/FileNameIndexUtils.java#getNonEmptyString(String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#df99ea8a92d600e669606d41d3887bd004e7a3cc#2016-01-29 16:19:28#-1#3.0#4.0#2.0#2.0#6.0#6.0#2.0#2.0#1.0#1.0#//TODO Maybe handle default values for longs and integers here?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobFactory.java#getNextJobFiltered()#8a2073cc61699f5692fcf638f4bae4d1c544870a#2012-02-23 10:41:07#dcf84707ab50662add112bd6b01c0bfd63374853#2012-05-17 15:06:33#-1#5.0#5.0#12.0#12.0#39.0#45.0#8.0#8.0#0.0#0.0#// TODO This should never happen. Probably we missed something!#8a2073cc61699f5692fcf638f4bae4d1c544870a#MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java#submissionFailed(Job)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#-1#4.0#4.0#3.0#3.0#4.0#4.0#1.0#1.0#0.0#0.0#/**hadoop,   * Add a submission failed job , such tht it can be communicatedhadoop,   * back to serial.hadoop,   * TODO: Cleaner solution for this problemhadoop,   * @param jobhadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#787dcfb8cd6e1f30a2a508b052e9d31f314b2169#MAPREDUCE-2596. [Gridmix] Summarize Gridmix runs. (amarrk)
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java#submissionFailed(Job)#787dcfb8cd6e1f30a2a508b052e9d31f314b2169#2011-07-08 17:53:36#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#4.0#4.0#3.0#3.0#4.0#4.0#1.0#1.0#0.0#0.0#/**hadoop,   * Add a submission failed job , such that it can be communicatedhadoop,   * back to serial.hadoop,   * TODO: Cleaner solution for this problemhadoop,   * @param jobhadoop,   */#787dcfb8cd6e1f30a2a508b052e9d31f314b2169#MAPREDUCE-2596. [Gridmix] Summarize Gridmix runs. (amarrk)#8a2073cc61699f5692fcf638f4bae4d1c544870a#MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)
hadoop#DESIGN#hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java#submissionFailed(JobStats)#8a2073cc61699f5692fcf638f4bae4d1c544870a#2012-02-23 10:41:07#070916130a538968f8e01a1e895f3092d50983ae#2013-04-03 21:22:02#-1#5.0#5.0#5.0#5.0#7.0#7.0#1.0#1.0#0.0#0.0#/**hadoop,   * Add a submission failed job's status, such that it can be communicatedhadoop,   * back to serial.hadoop,   * TODO: Cleaner solution for this problemhadoop,   * @param jobhadoop,   */#8a2073cc61699f5692fcf638f4bae4d1c544870a#MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/DFSClient.java#createClientDatanodeProtocolProxy(DatanodeID,Configuration,int,LocatedBlock)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f#2011-07-13 01:11:01#-1#9.0#10.0#16.0#16.0#28.0#28.0#2.0#2.0#1.0#1.0#// Since we're creating a new UserGroupInformation here, we know that no // future RPC proxies will be able to re-use the same connection. And // usages of this proxy tend to be one-off calls. // // This is a temporary fix: callers should really achieve this by using // RPC.stopProxy() on the resulting object, but this is currently not // working in trunk. See the discussion on HDFS-1965.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#710e5a960e8af1d4c73e386041096aacfee8b828#HDFS-2161. Move createNamenode(..), createClientDatanodeProtocolProxy(..) and Random object creation to DFSUtil; move DFSClient.stringifyToken(..) to DelegationTokenIdentifier.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java#getFailoverProxyProviderClass(URI,Configuration)#afd0333196ebd273b7eaeedfaec00ec68a358ea8#2011-12-15 00:42:50#afd0333196ebd273b7eaeedfaec00ec68a358ea8#2011-12-15 00:42:50#-1#6.0#6.0#6.0#6.0#32.0#32.0#6.0#6.0#3.0#3.0#// If we found a proxy provider, then this URI should be a logical NN. // Given that, it shouldn't have a non-default port number.#afd0333196ebd273b7eaeedfaec00ec68a358ea8#HDFS-2683. Authority-based lookup of proxy provider fails if path becomes canonicalized. Contributed by Todd Lipcon.#075122690c5c17ac443a8eb3fb7387001e4907c0#HDFS-1314. Make dfs.blocksize accept size-indicating prefixes (Sho Shimauchi via harsh)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/jobhistory/JobHistoryUtils.java#getHistoryUrl(Configuration,ApplicationId)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fb498926becbbf5c281bb9012ae3473ac3af93b0#2012-02-07 20:55:10#-1#6.0#11.0#14.0#18.0#21.0#31.0#2.0#2.0#1.0#1.0#// TODO This will change when the history server // understands apps. // TOOD Use JobId toString once UI stops using _id_id#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#7a082ec2bd29d04abe0dc86349d163d6e03250eb#MAPREDUCE-2793. Corrected AppIDs, JobIDs, TaskAttemptIDs to be of correct format on the web pages. Contributed by Bikas Saha.
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobSubmitter.java#run()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#dcf84707ab50662add112bd6b01c0bfd63374853#2012-05-17 15:06:33#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// abort execution, remove splits if nesc // TODO release ThdLoc#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/DFSInputStream.java#readBlockLength(LocatedBlock)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#d8383c687c95dbb37effa307ab2d41497da1cfc2#2016-03-28 15:44:25#-1#7.0#5.0#12.0#24.0#48.0#80.0#9.0#14.0#3.0#4.0#// Namenode told us about these locations, but none know about the replica // means that we hit the race between pipeline creation start and end. // we require all 3 because some other exception could have happened // on a DN that has it.  we want to report that error#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs-nfs/src/test/java/org/apache/hadoop/hdfs/nfs/nfs3/TestExportsTable.java#readBlockLength(LocatedBlock)#ec9ec0084eccdd45a8c3e37ef8121fb8bd44ecd0#2013-11-10 04:07:39#42391d260da400593812396c1ffd45d1a371d3cb#2014-05-30 23:53:00#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Namenode told us about these locations, but none know about the replica // means that we hit the race between pipeline creation start and end. // we require all 3 because some other exception could have happened // on a DN that has it.  we want to report that error#ec9ec0084eccdd45a8c3e37ef8121fb8bd44ecd0#HDFS-5469. Add configuration property for the sub-directroy export path. Contributed by Brandon Li##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#initApp(String,ApplicationId,ByteBuffer)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#7.0#4.0#12.0#6.0#17.0#6.0#2.0#1.0#1.0#0.0#// TODO these bytes should be versioned#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#initApp(String,ApplicationId,ByteBuffer)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#7.0#7.0#12.0#9.0#17.0#16.0#2.0#2.0#1.0#1.0#// TODO: Once SHuffle is out of NM, this can use MR APIs#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#initApp(String,ApplicationId,ByteBuffer)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#7.0#3.0#12.0#3.0#17.0#9.0#2.0#2.0#1.0#1.0#// TODO add API to AuxiliaryServices to report failures#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#start()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#4.0#17.0#10.0#27.0#9.0#34.0#1.0#2.0#0.0#1.0#// TODO change AbstractService to throw InterruptedException#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#messageReceived(ChannelHandlerContext,MessageEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO refactor the following into the pipeline#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#sendMapOutput(ChannelHandlerContext,Channel,String,String,String,int)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO replace w/ rsrc alloc // $x/$user/appcache/$appId/output/$mapId // TODO: Once Shuffle is out of NM, this can use MR APIs to convert between App and Job#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#sendMapOutput(ChannelHandlerContext,Channel,String,String,String,int)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO error handling; distinguish IO/connection failures, //      attribute to appropriate spill output#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java#deserializeMetaData(ByteBuffer)#ade0f0560f729e50382c6992f713f29e2dd5b270#2011-08-31 11:38:32#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#3.0#3.0#4.0#4.0#7.0#7.0#1.0#1.0#0.0#0.0#//TODO this should be returning a class not just an int#ade0f0560f729e50382c6992f713f29e2dd5b270#MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/DFSOutputStream.java#processDatanodeError()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#352d299cf8ebe330d24117df98d1e6a64ae38c26#2016-03-08 10:43:17#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// If we had an error while closing the pipeline, we go through a fast-path // where the BlockReceiver does not run. Instead, the DataNode just finalizes // the block immediately during the 'connect ack' process. So, we want to pull // the end-of-block packet from the dataQueue, since we don't actually have // a true pipeline to send it over. // // We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that // a client waiting on close() will be aware that the flush finished.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestHttpsFileSystem.java#processDatanodeError()#fef8f49c5885ba05dcd73e8a02de7c2be5ec3f0e#2013-11-16 01:00:42#f6f2a3f1c73266bfedd802eacde60d8b19b81015#2014-12-11 15:40:45#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// If we had an error while closing the pipeline, we go through a fast-path // where the BlockReceiver does not run. Instead, the DataNode just finalizes // the block immediately during the 'connect ack' process. So, we want to pull // the end-of-block packet from the dataQueue, since we don't actually have // a true pipeline to send it over. // // We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that // a client waiting on close() will be aware that the flush finished.#fef8f49c5885ba05dcd73e8a02de7c2be5ec3f0e#HDFS-5502. Fix HTTPS support in HsftpFileSystem. Contributed by Haohui Mai.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java#test()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2#2011-10-27 06:24:22#-1#12.0#12.0#99.0#100.0#252.0#246.0#7.0#7.0#0.0#0.0#// TODO: Use a resource to work around bugs. Today NM doesn't create local // app-dirs if there are no file to download!!#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#7f4dc277572df6ba25fa961073b99a5bdb086c00#MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerTokenSecretManager.java#test()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#db8ac0ec3cbec046f9cf32644c16fd2a51dd85a2#2011-10-27 06:24:22#-1#12.0#12.0#99.0#100.0#252.0#246.0#7.0#7.0#0.0#0.0#// TODO: FIX. Be in Sync with // ResourceManager.java#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#7f4dc277572df6ba25fa961073b99a5bdb086c00#MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/AuxServices.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#9.0#9.0#8.0#8.0#21.0#21.0#4.0#4.0#3.0#3.0#// TODO better use use s.getName()?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ade0f0560f729e50382c6992f713f29e2dd5b270#MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/AuxServices.java#init(Configuration)#ade0f0560f729e50382c6992f713f29e2dd5b270#2011-08-31 11:38:32#1ea36299a47af302379ae0750b571ec021eb54ad#2015-07-10 18:58:10#-1#10.0#9.0#11.0#21.0#29.0#53.0#5.0#7.0#3.0#3.0#// TODO better use s.getName()?#ade0f0560f729e50382c6992f713f29e2dd5b270#MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.##
hadoop#DESIGN#hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenAnonymization.java#testJobPropertiesAnonymization()#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#a238f931ea7dce0ca620d1798156c84ff77097ff#2011-12-16 14:20:58#-1#3.0#3.0#6.0#6.0#28.0#28.0#1.0#1.0#0.0#0.0#//TODO Support deprecated and un-supported keys#a238f931ea7dce0ca620d1798156c84ff77097ff#MAPREDUCE-778. Rumen Anonymizer. (Amar Kamat and Chris Douglas via amarrk)#355ba013747637e71936eab499055446616ed9d3#MAPREDUCE-3705. ant build fails on 0.23 branch. (Thomas Graves via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java#setInitialClasspath(Map<StringString>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#4102e5882e17b75507ae5cf8b8979485b3e24cbc#2015-05-27 14:21:05#-1#3.0#13.0#14.0#9.0#47.0#43.0#5.0#9.0#2.0#2.0#// TODO: Remove duplicates.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapreduce/v2/util/MRApps.java#getFileSizes(Configuration,String)#88b82a0f6687ce103817fbb460fd30d870f717a0#2011-09-14 07:26:37#4102e5882e17b75507ae5cf8b8979485b3e24cbc#2015-05-27 14:21:05#-1#3.0#3.0#3.0#3.0#11.0#11.0#3.0#3.0#1.0#1.0#// TODO - Move this to MR!#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java#testRMAppSubmitInvalidResourceRequest()#2638bc67a48f923404d57ed2026c4997df6bd06e#2013-05-10 21:49:28#8310b2e9ff3d6804bad703c4c15458b0dfeeb4af#2015-12-30 15:30:12#-1#4.0#4.0#7.0#7.0#18.0#18.0#2.0#2.0#1.0#1.0#// Exception is expected // TODO Change this to assert the expected exception type - post YARN-142 // sub-task related to specialized exceptions.#2638bc67a48f923404d57ed2026c4997df6bd06e#YARN-634. Modified YarnRemoteException to be not backed by PB and introduced a separate SerializedException record. Contributed by Siddharth Seth. MAPREDUCE-5239. Updated MR App to reflect YarnRemoteException changes after YARN-634. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolR23Compatible/ClientDatanodeProtocolTranslatorR23.java#createClientDatanodeProtocolProxy(DatanodeID,Configuration,int,LocatedBlock)#e4db38bdbe25752ebf7040f4ac99c91dc08ea71f#2011-10-06 21:58:22#2ab10e29d9cca5018064be46a40e3c74423615a8#2011-11-22 02:57:04#-1#9.0#9.0#16.0#16.0#29.0#29.0#2.0#2.0#1.0#1.0#// Since we're creating a new UserGroupInformation here, we know that no // future RPC proxies will be able to re-use the same connection. And // usages of this proxy tend to be one-off calls. // // This is a temporary fix: callers should really achieve this by using // RPC.stopProxy() on the resulting object, but this is currently not // working in trunk. See the discussion on HDFS-1965.#e4db38bdbe25752ebf7040f4ac99c91dc08ea71f#	HDFS-2181 Separate HDFS Client wire protocol data types (sanjay)#2a9e430ff9327ad311db7954400ff664ae66ec45#HDS-2895. Remove Writable wire protocol types and translators to complete transition to protocol buffers. Contributed by Suresh Srinivas.
hadoop#DESIGN#mapreduce/src/examples/org/apache/hadoop/examples/BaileyBorweinPlouffe.java#cleanup(Context)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#c7729efee8727b59f2c78cd5a3ad23fa84139068#2015-06-10 21:05:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this is conservative.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestZombieJob.java#testSecondJob()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#7.0#7.0#30.0#30.0#1.0#1.0#0.0#0.0#// get a failed map task attempt, with different locality // TODO: this test does not make sense here, because I don't have // available data set.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#355ba013747637e71936eab499055446616ed9d3#MAPREDUCE-3705. ant build fails on 0.23 branch. (Thomas Graves via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ApplicationTokenSecretManager.java#setMasterKey(SecretKey)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#3.0#1.0#1.0#1.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: this should go away.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#fe7711df98b9dd16259f6534e8461a29f24caadc#MAPREDUCE-3942. Randomize master key generation for ApplicationTokenSecretManager and roll it every so often. (Contributed by Vinod Kumar Vavilapalli)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java#stopContainer(StopContainerRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#55ae1439233e8585d624b2872e1e4753ef63eebb#2016-03-27 20:22:12#-1#9.0#-1#10.0#-1#22.0#-1#2.0#-1#1.0#-1#// TODO: Move this code to appropriate place once kill_container is // implemented.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java#startContainer(StartContainerRequest)#243bcd367ff3130d74676280233041f88aca62a5#2013-06-18 23:19:49#55ae1439233e8585d624b2872e1e4753ef63eebb#2016-03-27 20:22:12#-1#24.0#-1#46.0#-1#94.0#-1#5.0#-1#1.0#-1#/*hadoop,     * 1) It should save the NMToken into NMTokenSecretManager. This is donehadoop,     * here instead of RPC layer because at the time of opening/authenticatinghadoop,     * the connection it doesn't know what all RPC calls user will make on it.hadoop,     * Also new NMToken is issued only at startContainer (once it gets renewed).hadoop,     * hadoop,     * 2) It should validate containerToken. Need to check below things. a) Ithadoop,     * is signed by correct master key (part of retrieve password). b) Ithadoop,     * belongs to correct Node Manager (part of retrieve password). c) It hashadoop,     * correct RMIdentifier. d) It is not expired.hadoop,     */#243bcd367ff3130d74676280233041f88aca62a5#YARN-694. Starting to use NMTokens to authenticate all communication with NodeManagers. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/ReplicaInPipeline.java#createStreams(boolean,DataChecksum)#f84552ac35bb5221290be68fece9c779ebeaf4bc#2011-11-03 00:35:37#63c966a3fbeb675959fc4101e65de9f57aecd17d#2016-03-18 10:24:59#-1#5.0#5.0#17.0#19.0#73.0#74.0#8.0#8.0#3.0#3.0#// the checksum that should actually be used -- this // may differ from requestedChecksum for appends.#f84552ac35bb5221290be68fece9c779ebeaf4bc#HDFS-2130. Switch default checksum to CRC32C. Contributed by Todd Lipcon.##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/SleepJob.java#cleanup(Context)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#070916130a538968f8e01a1e895f3092d50983ae#2013-04-03 21:22:02#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//This is a hack to pass the sleep duration via Gridmix key //TODO: We need to come up with better solution for this.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#src/test/system/java/org/apache/hadoop/test/system/process/HadoopDaemonRemoteCluster.java#getCommand(String,String)#69693b6a8625dba4c783c61e9b49cfd722e1a74e#2010-05-14 23:56:34#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// XXX Twenty internal version does not support --script option.#69693b6a8625dba4c783c61e9b49cfd722e1a74e#HADOOP-6332. Large-scale Automated Test Framework. Contributed by Sharad Agarwal, Sreekanth Ramakrishnan, Konstantin Boudnik, at all.#30807fec82e80044cd39fb154208c6fb32d980da#HADOOP-8450. Remove src/test/system. Contributed by Eli Collins
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#7ce1c4ab352bca4b59ecbafdf237e5817cf833e5#2011-10-24 17:09:37#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//FIXME:  race condition here?  or do we have same kind of lock on TA handler => MapTask can't send TA_UPDATE before TA_CONTAINER_LAUNCHED moves TA to RUNNING state?  (probably latter)#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java#runSubtask(org.apache.hadoop.mapred.Task,TaskType,TaskAttemptId,int,boolean)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#7ce1c4ab352bca4b59ecbafdf237e5817cf833e5#2011-10-24 17:09:37#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//CODE-REVIEWER QUESTION: why not task.getConf() or map.getConf() instead of conf? do we need Task's localizeConfiguration() run on this first?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java#runSubtask(org.apache.hadoop.mapred.Task,TaskType,TaskAttemptId,int,boolean)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//check if event-queue empty?  whole idea of counting maps vs. checking event queue is a tad wacky...but could enforce ordering (assuming no "lost events") at LocalMRAppMaster [CURRENT BUG(?):  doesn't send reduce event until maps all done]#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java#setVMEnv(Map<StringString>,List<String>,String,String,String,Task,CharSequence)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a003f71cacd35834a1abbc2ffb5446a1166caf73#2015-01-21 18:41:43#-1#13.0#8.0#17.0#9.0#86.0#47.0#8.0#4.0#4.0#2.0#// TODO: The following is useful for instance in streaming tasks. Should be // set in ApplicationMaster's env by the RM.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java#setVMEnv(Map<StringString>,List<String>,String,String,String,Task,CharSequence)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a003f71cacd35834a1abbc2ffb5446a1166caf73#2015-01-21 18:41:43#-1#13.0#8.0#17.0#9.0#86.0#47.0#8.0#4.0#4.0#2.0#// FIXME: don't think this is also needed given we already set java // properties.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/MapReduceChildJVM.java#setVMEnv(Map<StringString>,List<String>,String,String,String,Task,CharSequence)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#13.0#13.0#17.0#17.0#86.0#86.0#8.0#8.0#4.0#4.0#//This should not be set here (If an OS check is requied. moved to ContainerLuanch) // env.put("JVM_PID", "`echo $$`");#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java#run()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#d239307d00c7eb1c4d0c849de39ff1c000a9cff5#2012-05-21 01:55:44#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: We need to take care of scenario when one map/reduce // takes more than 1 slot.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java#toString()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#d239307d00c7eb1c4d0c849de39ff1c000a9cff5#2012-05-21 01:55:44#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Use StringBuilder instead#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java#checkLoadAndGetSlotsToBackfill()#8a2073cc61699f5692fcf638f4bae4d1c544870a#2012-02-23 10:41:07#d239307d00c7eb1c4d0c849de39ff1c000a9cff5#2012-05-21 01:55:44#-1#6.0#6.0#30.0#30.0#173.0#173.0#22.0#22.0#5.0#5.0#// Note that this is a hack! Ideally, ClusterStats.getRunningJobStats() // should be smart enough to take care of completed jobs.#8a2073cc61699f5692fcf638f4bae4d1c544870a#MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)##
hadoop#DESIGN#hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java#checkLoadAndGetSlotsToBackfill()#8a2073cc61699f5692fcf638f4bae4d1c544870a#2012-02-23 10:41:07#d239307d00c7eb1c4d0c849de39ff1c000a9cff5#2012-05-21 01:55:44#-1#6.0#6.0#30.0#30.0#173.0#173.0#22.0#22.0#5.0#5.0#// consider polling for jobs where maps>0 and reds>0 // TODO: What about setup/cleanup tasks for cases where m=0 and r=0 //       What otherwise?#8a2073cc61699f5692fcf638f4bae4d1c544870a#MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java#write(DataOutput)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de#2011-09-21 02:56:08#-1#12.0#12.0#7.0#7.0#16.0#16.0#2.0#2.0#0.0#0.0#//TODO: move it to DatanodeID once DatanodeID is not stored in FSImage#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#e4db38bdbe25752ebf7040f4ac99c91dc08ea71f#	HDFS-2181 Separate HDFS Client wire protocol data types (sanjay)
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java#testSuccessiveVolumeFailures()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#1de1641f17f890059e85e57304ce33c7070a08de#2016-02-12 12:41:04#-1#6.0#6.0#26.0#24.0#139.0#141.0#1.0#1.0#0.0#0.0#/*hadoop,     * Make the 1st volume directories on the first two datanodeshadoop,     * non-accessible.  We don't make all three 1st volume directorieshadoop,     * readonly since that would cause the entire pipeline tohadoop,     * fail. The client does not retry failed nodes even thoughhadoop,     * perhaps they could succeed because just a single volume failed.hadoop,     */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java#testSuccessiveVolumeFailures()#63d9f1596c92206cce3b72e3214d2fb5f6242b90#2015-09-22 20:52:37#73b94d789969354bb9a6872d99976763ca8470d7#2015-11-10 09:55:29#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#/*hadoop,     * Make the 1st volume directories on the first two datanodeshadoop,     * non-accessible.  We don't make all three 1st volume directorieshadoop,     * readonly since that would cause the entire pipeline tohadoop,     * fail. The client does not retry failed nodes even thoughhadoop,     * perhaps they could succeed because just a single volume failed.hadoop,     */#63d9f1596c92206cce3b72e3214d2fb5f6242b90#HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java#shuffleError(TaskAttemptID,String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6b710a42e00acca405e085724c89cda016cf7442#2015-05-14 16:07:56#-1#0.0#0.0#0.0#0.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: This isn't really used in any MR code. Ask for removal.    #dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java#getMapCompletionEvents(JobID,int,int,TaskAttemptID)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6b710a42e00acca405e085724c89cda016cf7442#2015-05-14 16:07:56#-1#7.0#7.0#16.0#10.0#27.0#18.0#3.0#1.0#2.0#0.0#// TODO: shouldReset is never used. See TT. Ask for Removal.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java#statusUpdate(TaskAttemptID,TaskStatus)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6b710a42e00acca405e085724c89cda016cf7442#2015-05-14 16:07:56#-1#7.0#10.0#34.0#39.0#69.0#89.0#6.0#9.0#2.0#2.0#//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster. //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask(). //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes //    // This was used by TT to do counter updates only once every minute. So this //    // isn't ever changed by the Task itself. //    taskStatus.getIncludeCounters();#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java#getTask(JvmContext)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6b710a42e00acca405e085724c89cda016cf7442#2015-05-14 16:07:56#-1#5.0#9.0#9.0#12.0#28.0#40.0#2.0#3.0#1.0#2.0#// TODO: Child.java's firstTaskID isn't really firstTaskID. Ask for update // to jobId and task-type.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java#unregister(org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId,WrappedJvmID)#0c278b0f636a01c81aba9e46fe7658fcdfb0f33c#2012-01-13 21:31:40#6b710a42e00acca405e085724c89cda016cf7442#2015-05-14 16:07:56#-1#6.0#6.0#2.0#2.0#19.0#19.0#1.0#1.0#0.0#0.0#// Remove from launchedJVMs before jvmIDToActiveAttemptMap to avoid // synchronization issue with getTask(). getTask should be checking // jvmIDToActiveAttemptMap before it checks launchedJVMs.#0c278b0f636a01c81aba9e46fe7658fcdfb0f33c#MAPREDUCE-3656. Fixed a race condition in MR AM which is failing the sort benchmark consistently. Contributed by Siddarth Seth.##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestLinuxResourceCalculatorPlugin.java#testParsingProcStatAndCpuFile()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#89d1fd5dac4bccf42d82686e146b02eb60d14736#2016-01-19 21:26:38#-1#6.0#-1#11.0#-1#51.0#-1#2.0#-1#1.0#-1#// Advance very short period of time (one jiffy length). // In this case, CPU usage should not be updated.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/ShortCircuitRegistry.java#testParsingProcStatAndCpuFile()#6465b0b55f263c06f4d37800db951adba314a9fd#2014-03-03 04:01:26#778146eaae5b1e17928a1f26fb1e46536a6ee510#2016-01-04 14:32:09#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Advance very short period of time (one jiffy length). // In this case, CPU usage should not be updated.#6465b0b55f263c06f4d37800db951adba314a9fd#add missing file for HDFS-5950##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl.java#getApplicationState()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e3bb120e9fefb21168edd7cd06f0cbfb92a5e02b#2011-10-19 06:40:03#-1#1.0#2.0#2.0#2.0#5.0#5.0#1.0#1.0#0.0#0.0#// TODO: Synchro should be at statemachine level. // This is only for tests?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#df2991c0cbc3f35c2640b93680667507c4f810dd#MAPREDUCE-3104. Implemented Application-acls. (vinodkv)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl.java#transition(ApplicationImpl,ApplicationEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#df2991c0cbc3f35c2640b93680667507c4f810dd#2011-10-20 11:45:38#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Fix#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl.java#handleAppFinishWithContainersCleanedup()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#37e1c3d82a96d781e1c9982988b7de4aa5242d0c#2015-08-22 16:25:24#-1#4.0#6.0#3.0#4.0#8.0#12.0#1.0#1.0#0.0#0.0#// TODO: Trigger the LogsManager#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl.java#transition(ApplicationImpl,ApplicationEvent)#df2991c0cbc3f35c2640b93680667507c4f810dd#2011-10-20 11:45:38#df2991c0cbc3f35c2640b93680667507c4f810dd#2011-10-20 11:45:38#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Also make logService write the acls to the aggregated file.#df2991c0cbc3f35c2640b93680667507c4f810dd#MAPREDUCE-3104. Implemented Application-acls. (vinodkv)#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/records/impl/pb/RMStateVersionPBImpl.java#handleAppFinishWithContainersCleanedup()#6369c8d81972a9a0b6ef41f4508fcb60d34e3d78#2013-11-27 23:22:33#3122daa80261b466e309e88d88d1e2c030525e3f#2014-09-12 10:33:33#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Trigger the LogsManager#6369c8d81972a9a0b6ef41f4508fcb60d34e3d78#YARN-1239. Modified ResourceManager state-store implementations to start storing version numbers. Contributed by Jian He.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/RemoteBlockReader.java#getStreams()#9b4a7900c7dfc0590316eedaa97144f938885651#2012-08-07 16:40:03#3052ad1f0069af5caee621374b29d17d7f12ab51#2013-01-14 20:47:08#-1#0.0#0.0#1.0#1.0#5.0#5.0#1.0#1.0#0.0#0.0#// This class doesn't support encryption, which is the only thing this // method is used for. See HDFS-3637.#9b4a7900c7dfc0590316eedaa97144f938885651#HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.#a18fd620d070cf8e84aaf80d93807ac9ee207a0f#HDFS-4661. A few little code cleanups of some HDFS-347-related code. Contributed by Colin Patrick McCabe.
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/emulators/resourceusage/CumulativeCpuUsageEmulatorPlugin.java#performUnitComputation()#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#2011-06-14 07:44:16#d41e67b966b4ced602ae27e6ccc6a73cd4068a05#2013-03-26 18:15:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO can this be configurable too. Users/emulators should be able to  // pick and choose what MATH operations to run. // Example : //           BASIC : ADD, SUB, MUL, DIV //           ADV   : SQRT, SIN, COSIN.. //           COMPO : (BASIC/ADV)* // Also define input generator. For now we can use the random number  // generator. Later this can be changed to accept multiple sources.#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#MAPREDUCE-2106. [Gridmix] Cumulative CPU usage emulation in Gridmix. (amarrk)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/emulators/resourceusage/CumulativeCpuUsageEmulatorPlugin.java#calibrate(ResourceCalculatorPlugin,long)#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#2011-06-14 07:44:16#d41e67b966b4ced602ae27e6ccc6a73cd4068a05#2013-03-26 18:15:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Make this configurable // 100 ms#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#MAPREDUCE-2106. [Gridmix] Cumulative CPU usage emulation in Gridmix. (amarrk)##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/emulators/resourceusage/CumulativeCpuUsageEmulatorPlugin.java#calibrate(ResourceCalculatorPlugin,long)#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#2011-06-14 07:44:16#d41e67b966b4ced602ae27e6ccc6a73cd4068a05#2013-03-26 18:15:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// compute the 1% of the total CPU usage desired //TODO Make this configurable#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#MAPREDUCE-2106. [Gridmix] Cumulative CPU usage emulation in Gridmix. (amarrk)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryCopyService.java#start()#64e4fb983e022d8d3375a3e1b8facbf95f7ba403#2013-01-04 20:35:56#b9efe6bd4a1277b4067ecde715a7713a85968886#2013-06-17 06:39:33#-1#1.0#1.0#2.0#2.0#9.0#9.0#2.0#2.0#1.0#1.0#//TODO should we parse on a background thread???#64e4fb983e022d8d3375a3e1b8facbf95f7ba403#MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapreduce/v2/jobhistory/TestJobHistoryUtils.java#serviceStart()#84cec3c805867cf0c880c9ecb9fc220733032bc9#2013-10-28 23:48:38#84cec3c805867cf0c880c9ecb9fc220733032bc9#2013-10-28 23:48:38#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO should we parse on a background thread???#84cec3c805867cf0c880c9ecb9fc220733032bc9#MAPREDUCE-4680. Job history cleaner should only check timestamps of files in old enough directories (Robert Kanter via Sandy Ryza)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#14.0#32.0#24.0#40.0#84.0#136.0#7.0#11.0#3.0#3.0#// TODO Temporary toShort till new FsPermission(FsPermissions) // respects // sticky#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#setupEventWriter(JobId,JobSubmittedEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#12.0#-1#23.0#-1#64.0#-1#10.0#-1#3.0#-1#// TODO Ideally this should be written out to the job dir // (.staging/jobid/files - RecoveryService will need to be patched)#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#processEventForJobSummary(HistoryEvent,JobSummary,JobId)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#13.0#16.0#31.0#41.0#48.0#62.0#11.0#14.0#2.0#2.0#// context.getJob could be used for some of this info as well.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#closeEventWriter(JobId)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#10.0#5.0#23.0#5.0#87.0#21.0#10.0#4.0#2.0#1.0#// Writing out the summary file. // TODO JH enhancement - reuse this file to store additional indexing info // like ACLs, etc. JHServer can use HDFS append to build an index file // with more info than is available via the filename.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#moveToDoneNow(Path,Path)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#8.0#7.0#7.0#8.0#21.0#19.0#4.0#4.0#2.0#2.0#// TODO temporarily removing the existing dst#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#getFileNameFromTmpFN(String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#a0b1f10a30dc2736cc136f257b0d3bf0140158bb#2016-02-10 03:03:49#-1#2.0#2.0#3.0#3.0#4.0#4.0#1.0#1.0#0.0#0.0#//TODO. Some error checking here.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/container/ContainerImpl.java#transition(ContainerImpl,ContainerEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#11b9dd4e844c762f8c53e5fafa25f29eece1bc87#2011-10-11 04:45:28#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Inform the ContainersMonitor to start monitoring the container's // resource usage. // TODO: Fix pmem limits below#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#237154982bd5853c6a374cb265520e0602adc52f#MAPREDUCE-3205. Fix memory specifications to be physical rather than virtual, allowing for a ratio between the two to be configurable. Contributed by Todd Lipcon.
hadoop#DESIGN#mapreduce/src/contrib/vertica/src/java/org/apache/hadoop/vertica/VerticaOutputFormat.java#optimize(Configuration)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#3.0#3.0#22.0#22.0#83.0#83.0#13.0#13.0#4.0#4.0#// TODO: consider more tables and skip tables with non-temp projections #a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java#createJob(JobFinishEvent,Configuration,Credentials)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#408656614495674992349fbda3981559ada3de0b#2011-10-24 08:41:48#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: this is required because rpc server does not shut down // in spite of calling server.stop(). //Bring the process down by force. //Not needed after HADOOP-7140#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#6288dfa873364d1bb735bdb811002f0080e9a1be#MAPREDUCE-3028. Added job-end notification support. Contributed by Ravi Prakash.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java#startJobs()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d40859fab1ad977636457a6cc96b6a4f9b903afc#2016-01-18 10:58:14#-1#4.0#4.0#4.0#4.0#6.0#7.0#1.0#1.0#0.0#0.0#/**hadoop,   * This can be overridden to instantiate multiple jobs and create a hadoop,   * workflow.hadoop,   *hadoop,   * TODO:  Rework the design to actually support this.  Currently much of thehadoop,   * job stuff has been moved to init() above to support uberization (MR-1220).hadoop,   * In a typical workflow, one presumably would want to uberize only a subsethadoop,   * of the jobs (the "small" ones), which is awkward with the current design.hadoop,   */#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java#start()#61900651b1b85cf235e01142acf2a51727fc5537#2011-09-18 07:16:18#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#8.0#8.0#15.0#16.0#41.0#41.0#2.0#2.0#1.0#1.0#// This is a synchronous call, not an event through dispatcher. We want // job-init to be done completely here.#61900651b1b85cf235e01142acf2a51727fc5537#MAPREDUCE-3006. Fixed MapReduce AM to exit only after properly writing out history file. (vinodkv)#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java#start()#312a7e71001d55f88781e56b331ab1b40a72a980#2011-09-28 07:31:03#d40859fab1ad977636457a6cc96b6a4f9b903afc#2016-01-18 10:58:14#-1#8.0#24.0#16.0#36.0#41.0#90.0#2.0#6.0#1.0#2.0#// Send init to the job (this does NOT trigger job execution) // This is a synchronous call, not an event through dispatcher. We want // job-init to be done completely here.#312a7e71001d55f88781e56b331ab1b40a72a980#MAPREDUCE-3078. Ensure MapReduce AM reports progress correctly for displaying on the RM Web-UI. Contributed by Vinod K V.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java#init(Configuration)#25e96e455b3473387df865fbc1c3ad7ebf9ff1e4#2012-08-31 20:43:46#7d7553c4eb7d9a282410a3213d26a89fea9b7865#2013-03-15 21:09:25#-1#31.0#40.0#49.0#66.0#121.0#215.0#4.0#12.0#1.0#3.0#//TODO this is a hack, we really need the RM to inform us when we // are the last one.  This would allow us to configure retries on // a per application basis.#25e96e455b3473387df865fbc1c3ad7ebf9ff1e4#MAPREDUCE-4611. MR AM dies badly when Node is decommissioned (Robert Evans via tgraves)#46315a2d914058969c7234272420c063ce268bf5#MAPREDUCE-5062. Fix MR AM to read max-retries from the RM. Contributed by *Zhijie Shen.
hadoop#DESIGN#mapreduce/src/contrib/vertica/src/java/org/apache/hadoop/vertica/VerticaRecordReader.java#getProgress()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#1.0#1.0#6.0#6.0#2.0#2.0#1.0#1.0#// TODO: figure out why length would be 0#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java#testOldRenameWithQuota()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#1b56d1ce324165688d40c238858e1e19a1e60f7e#2015-02-10 01:45:29#-1#4.0#4.0#7.0#7.0#33.0#33.0#1.0#1.0#0.0#0.0#/* hadoop,     * Test1: src does not exceed quota and dst has no quota check and hence hadoop,     * accommodates renamehadoop,     */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/test/java/org/apache/hadoop/yarn/util/TestRackResolver.java#resolve(List<String>)#c6282df3e59eb1e5481158184c344034872d2a89#2012-02-06 22:06:58#d55f3780fbf9308554ef3362c2be89651db43f46#2013-10-05 22:20:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// I should not be reached again as RackResolver is supposed to do // caching.#c6282df3e59eb1e5481158184c344034872d2a89#MAPREDUCE-3813. Added a cache for resolved racks. Contributed by Vinod K V.##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java#setSessionTimeZone(Configuration,Connection)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#73325f23f691e93cf88a445ce8bb0f94b7b2cfbf#2014-08-18 18:25:50#-1#9.0#9.0#9.0#9.0#38.0#38.0#4.0#4.0#2.0#2.0#// need to use reflection to call the method setSessionTimeZone on // the OracleConnection class because oracle specific java libraries are // not accessible in this context.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java#call()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#b41a7e89d1eb8650975ac7092532ed9563ac60f2#2016-01-22 14:43:14#-1#27.0#34.0#45.0#80.0#138.0#223.0#7.0#15.0#3.0#3.0#// TODO: Should we instead work via symlinks without this grammar?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java#writeLaunchEnv(OutputStream,Map<StringString>,Map<PathString>,List<String>,List<Path>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#9.0#9.0#15.0#15.0#44.0#44.0#10.0#10.0#2.0#2.0#// TODO: Get from whitelist.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java#sanitizeEnv(Map<StringString>,Path,List<Path>)#638801cce16fc1dc3259c541dc30a599faaddda1#2013-03-06 19:15:18#b41a7e89d1eb8650975ac7092532ed9563ac60f2#2016-01-22 14:43:14#-1#20.0#-1#14.0#-1#62.0#-1#4.0#-1#1.0#-1#// TODO: Remove Windows check and use this approach on all platforms after // additional testing.  See YARN-358.#638801cce16fc1dc3259c541dc30a599faaddda1#HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/ReservationAllocation.java#call()#cf4b34282aafee9f6b09d3433c4de1ae4b359168#2014-09-12 17:22:08#742632e346604fd2b263bd42367165638fcf2416#2015-12-05 21:26:16#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Should we instead work via symlinks without this grammar?#cf4b34282aafee9f6b09d3433c4de1ae4b359168#YARN-1709. In-memory data structures used to track resources over time to enable reservations. (cherry picked from commit 0d8b2cd88b958b1e602fd4ea4078ef8d4742a7c3)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/ReservationAllocation.java#sanitizeEnv(Map<StringString>,Path,List<Path>,List<String>,Map<PathList<String>)#cf4b34282aafee9f6b09d3433c4de1ae4b359168#2014-09-12 17:22:08#742632e346604fd2b263bd42367165638fcf2416#2015-12-05 21:26:16#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Remove Windows check and use this approach on all platforms after // additional testing.  See YARN-358.#cf4b34282aafee9f6b09d3433c4de1ae4b359168#YARN-1709. In-memory data structures used to track resources over time to enable reservations. (cherry picked from commit 0d8b2cd88b958b1e602fd4ea4078ef8d4742a7c3)##
hadoop#DESIGN#mapreduce/src/contrib/vertica/src/java/org/apache/hadoop/vertica/VerticaStreamingRecordReader.java#getProgress()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#1.0#1.0#6.0#6.0#2.0#2.0#1.0#1.0#// TODO: figure out why length would be 0#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/MRBench.java#run(String[])#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#fcf47eb4b8cf0cb39f0c70845048f5cf4d9ef947#2012-05-28 13:26:35#-1#6.0#6.0#16.0#17.0#101.0#101.0#17.0#17.0#3.0#3.0#// delete output -- should we really do this?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainersLauncher.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#2.0#2.0#3.0#3.0#9.0#9.0#2.0#2.0#1.0#1.0#//TODO Is this required?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#src/test/ddl/string.jr#serviceInit(Configuration)#95a0db602b2e0606af11d666d9d10d64766f9ecf#2009-05-19 04:56:52#07b43463b8cb3aee80510c2cc3f70cd631f9a69b#2009-08-17 03:53:27#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Is this required?#95a0db602b2e0606af11d666d9d10d64766f9ecf#HADOOP-4687. move test dirs#dbd07f9e8c2824cdb04d44d07d27c2b56f68c1d5#HADOOP-6978. Adds support for NativeIO using JNI. Contributed by Todd Lipcon, Devaraj Das & Owen O'Malley.
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java#addToReplicasMap(String,ReplicasMap,File,boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#99a68a14237b4cd1936ba5e9468d25d35dad594c#2012-03-28 20:37:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO move this up // dfsUsage.incDfsUsed(b.getNumBytes()+metaFile.length());#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#bc13dfb1426944ce45293cb8f444239a7406762c#HDFS-3130. Move fsdataset implementation to a package.
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/FSDataset.java#checkAndUpdate(String,long,File,File,FSVolume)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#63c966a3fbeb675959fc4101e65de9f57aecd17d#2016-03-18 10:24:59#-1#13.0#13.0#31.0#33.0#135.0#148.0#20.0#25.0#3.0#4.0#// TODO: Should the diskFile be deleted?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsDisable.java#checkAndUpdate(String,long,File,File,FsVolumeSpi)#9ad19eec6f20530c9f2b9b80ee858ac9ca02827b#2013-08-01 01:04:29#4147a5214349896dc40112e22c9e10aa8e5b5ea6#2014-04-04 15:50:46#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Should the diskFile be deleted?#9ad19eec6f20530c9f2b9b80ee858ac9ca02827b#HADOOP-9758.  Provide configuration option for FS/FC symlink resolution.  (Andrew Wang via Colin Patrick McCabe)##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/NotificationTestCase.java#testMR()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#1.0#5.0#13.0#26.0#29.0#44.0#2.0#3.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.java#addToReplicasMap(String,ReplicaMap,File,boolean)#bc13dfb1426944ce45293cb8f444239a7406762c#2012-04-02 17:38:56#63c966a3fbeb675959fc4101e65de9f57aecd17d#2016-03-18 10:24:59#-1#5.0#-1#2.0#-1#7.0#-1#1.0#-1#0.0#-1#// TODO move this up // dfsUsage.incDfsUsed(b.getNumBytes()+metaFile.length());#bc13dfb1426944ce45293cb8f444239a7406762c#HDFS-3130. Move fsdataset implementation to a package.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java#addToReplicasMap(String,ReplicaMap,File,boolean)#8767e4cde172b6e6070e3fd45325ede617b99343#2013-07-11 21:31:04#8767e4cde172b6e6070e3fd45325ede617b99343#2013-07-11 21:31:04#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO move this up // dfsUsage.incDfsUsed(b.getNumBytes()+metaFile.length());#8767e4cde172b6e6070e3fd45325ede617b99343#HADOOP-9418.  Add symlink support to DistributedFileSystem (Andrew Wang via Colin Patrick McCabe)##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/FileInputFormat.java#getSplitHosts(BlockLocation[],long,long,NetworkTopology)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#1babe50a2cbaae3c8165229347e743d0dc94e979#2015-06-18 11:42:22#-1#6.0#5.0#18.0#2.0#100.0#5.0#11.0#1.0#3.0#0.0#// NOTE: This code currently works only for one level of // hierarchy (rack/host). However, it is relatively easy // to extend this to support aggregation at different // levels #a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestClientRedirect.java#start(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9875325d5c63f343809907d06bf48a298035a611#2016-02-02 10:17:33#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO : use fixed port ??#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestClientRedirect.java#testRedirect()#f2b91a8367a762091482074505618b570a520b19#2011-08-25 06:35:58#9875325d5c63f343809907d06bf48a298035a611#2016-02-02 10:17:33#-1#9.0#10.0#32.0#29.0#81.0#86.0#1.0#1.0#0.0#0.0#// Same client //results are returned from fake (not started job)#f2b91a8367a762091482074505618b570a520b19# MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.##
hadoop#DESIGN#mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestResourceUsageEmulators.java#emulate()#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#2011-06-14 07:44:16#d41e67b966b4ced602ae27e6ccc6a73cd4068a05#2013-03-26 18:15:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// delete the touch file //TODO Search for a better touch utility // recreate it#3fd40ae8d0b45d7bf6186fe14851ca87eb9ee3ef#MAPREDUCE-2106. [Gridmix] Cumulative CPU usage emulation in Gridmix. (amarrk)##
hadoop#DESIGN#mapreduce/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/FairScheduler.java#dump()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#ca333f17c125735c1de412bb27db599ee752b24c#2011-09-16 22:22:34#-1#12.0#12.0#18.0#18.0#56.0#56.0#5.0#5.0#3.0#3.0#// TODO: Fix //runningMaps += info.runningMaps; //runningReduces += info.runningReduces;#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#1ad8415b72cb2b2dbfa85d27771177873c2a5c4c#MAPREDUCE-2736. Remove unused contrib components dependent on MR1. Contributed by Eli Collins
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/protocol/Block.java#hashCode()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#9a43094e12ab8d35d49ceda2e2c5f83093bb3a5b#2016-03-14 14:59:11#-1#10.0#10.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#//GenerationStamp is IRRELEVANT and should not be used here#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.java#write(DataOutput)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#f2f4e9341387199e04679ebc8de5e05c0fdbd437#2011-12-13 18:07:29#-1#4.0#5.0#4.0#4.0#9.0#9.0#1.0#1.0#0.0#0.0#//TODO: move it to DatanodeID once HADOOP-2797 has been committed#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#2a9e430ff9327ad311db7954400ff664ae66ec45#HDS-2895. Remove Writable wire protocol types and translators to complete transition to protocol buffers. Contributed by Suresh Srinivas.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/ClientBaseWithFixes.java#createTmpDir(File)#3646705f7a17779189f1de9fab946ba4c35d9c42#2012-04-07 22:17:17#f0f984e4e63d0dbafe93062a122ee051330db301#2015-09-27 14:12:07#-1#3.0#3.0#6.0#6.0#10.0#10.0#1.0#1.0#0.0#0.0#// don't delete tmpFile - this ensures we don't attempt to create // a tmpDir with a duplicate name#3646705f7a17779189f1de9fab946ba4c35d9c42#HADOOP-8260. Replace ClientBaseWithFixes with our own modified copy of the class. Contributed by Todd Lipcon.##
hadoop#DESIGN#mapreduce/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/PoolManager.java#reloadAllocsIfNecessary()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#ca333f17c125735c1de412bb27db599ee752b24c#2011-09-16 22:22:34#-1#9.0#9.0#9.0#9.0#38.0#38.0#7.0#7.0#3.0#3.0#// Throwing the error further out here won't help - the RPC thread // will catch it and report it in a loop. Instead, just log it and // hope somebody will notice from the log. // We log the error only on the first failure so we don't fill up the // JobTracker's log with these messages.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#1ad8415b72cb2b2dbfa85d27771177873c2a5c4c#MAPREDUCE-2736. Remove unused contrib components dependent on MR1. Contributed by Eli Collins
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JobInProgress.java#setFirstTaskLaunchTime(TaskInProgress)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#b89b6bd75f1c4d86778242c30d018aa13cb9af26#2012-04-17 19:21:34#-1#3.0#3.0#4.0#4.0#10.0#10.0#2.0#2.0#1.0#1.0#// Could be optimized to do only one lookup with a little more code#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JobInProgress.java#failedTask(TaskInProgress,TaskAttemptID,TaskStatus,TaskTracker,boolean,boolean,boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#b89b6bd75f1c4d86778242c30d018aa13cb9af26#2012-04-17 19:21:34#-1#23.0#23.0#53.0#56.0#177.0#181.0#27.0#27.0#4.0#4.0#// Put the task back in the cache. This will help locality for cases // where we have a different TaskTracker from the same rack/switch // asking for a task.  // We bother about only those TIPs that were successful // earlier (wasComplete and !isComplete)  // (since they might have been removed from the cache of other  // racks/switches, if the input split blocks were present there too)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestFileOutputFormat.java#testCustomFile()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#0.0#2.0#33.0#34.0#66.0#68.0#5.0#5.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/NLineInputFormat.java#getSplitsForFile(FileStatus,Configuration,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#5.0#5.0#11.0#11.0#48.0#48.0#7.0#7.0#4.0#4.0#// NLineInputFormat uses LineRecordReader, which always reads // (and consumes) at least one character out of its upper split // boundary. So to make sure that each mapper gets N lines, we // move back the upper split limits of each split  // by one character here.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#1f40b8b4e8ce8c4876c1b57012cbd12332d0c096#MAPREDUCE-4782. NLineInputFormat skips first line of last InputSplit (Mark Fuhs via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JobTracker.java#updateRestartCount()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#ce778462ee5426421edb679f091e31e4b6fc1ef5#2012-02-13 21:12:03#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Write back the new restart count and rename the old info file //TODO This is similar to jobhistory recovery, maybe this common code //      can be factored out.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JobTracker.java#initJob(JobInProgress)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#ce778462ee5426421edb679f091e31e4b6fc1ef5#2012-02-13 21:12:03#-1#10.0#9.0#16.0#16.0#49.0#49.0#7.0#7.0#2.0#2.0#// Here the job *should* be in the PREP state. // From here there are 3 ways : //  - job requires setup : the job remains in PREP state and  //    setup is launched to move the job in RUNNING state //  - job is complete (no setup required and no tasks) : complete  //    the job and move it to SUCCEEDED //  - job has tasks but doesnt require setup : make the job RUNNING. // is the job empty? // complete it // setup/cleanup not required // complete setup and make job running#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JobTracker.java#updateTaskStatuses(TaskTrackerStatus)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#ce778462ee5426421edb679f091e31e4b6fc1ef5#2012-02-13 21:12:03#-1#8.0#8.0#23.0#23.0#82.0#82.0#12.0#12.0#5.0#5.0#// Clone TaskStatus object here, because JobInProgress // or TaskInProgress can modify this object and // the changes should not get reflected in TaskTrackerStatus. // An old TaskTrackerStatus is used later in countMapTasks, etc.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/protocol/DatanodeInfo.java#write(DataOutput)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#0475795066ad89fc3ac4bfbe0dbe061555f3fbf7#2012-03-28 19:33:22#-1#12.0#5.0#7.0#16.0#16.0#16.0#2.0#1.0#0.0#0.0#//TODO: move it to DatanodeID once DatanodeID is not stored in FSImage#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#a8cbf195480826c25a95e1ef1cbcffa7b3ba4947#HDFS-3138. Move DatanodeInfoipcPort to DatanodeID. Contributed by Eli Collins
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/JvmManager.java#spawnNewJvm(JobID,JvmEnv,TaskRunner)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//spawn the JVM in a new thread. Note that there will be very little //extra overhead of launching the new thread for a new JVM since //most of the cost is involved in launching the process. Moreover, //since we are going to be using the JVM for running many tasks, //the thread launch cost becomes trivial when amortized over all //tasks. Doing it this way also keeps code simple.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java#launchWordCount(JobConf,Path,Path,String,int,int,String)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#0050fa5f1c20087009bd76a0bb2183a479f787f0#2016-03-29 18:17:52#-1#9.0#10.0#31.0#31.0#44.0#44.0#2.0#2.0#1.0#1.0#// Checking that the Job Client system dir is not used#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java#runWordCount(MiniMRCluster,JobConf,String)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#0050fa5f1c20087009bd76a0bb2183a479f787f0#2016-03-29 18:17:52#-1#6.0#6.0#5.0#5.0#18.0#18.0#1.0#1.0#0.0#0.0#// Checking if the Job ran successfully in spite of different system dir config //  between Job Client & Job Tracker#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ContainerLocalizer.java#runLocalization(InetSocketAddress)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#11.0#16.0#16.0#20.0#57.0#61.0#5.0#5.0#1.0#2.0#// assume credentials in cwd // TODO: Fix#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ContainerLocalizer.java#localizeFiles(LocalizationProtocol,ExecutorService,UserGroupInformation)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#13.0#10.0#13.0#23.0#52.0#39.0#13.0#5.0#6.0#3.0#// TODO: Synchronization??#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ContainerLocalizer.java#localizeFiles(LocalizationProtocol,ExecutorService,UserGroupInformation)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#ea17da82f7fc4b7fcc05bba82d141e27289fd7cb#2011-11-29 23:17:54#-1#13.0#13.0#13.0#13.0#52.0#52.0#13.0#13.0#6.0#6.0#// TODO HB immediately when rsrc localized#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#cd90b822278bf98a166e34e31aa2503ee4e48083#MAPREDUCE-3399. Modifying ContainerLocalizer to send a heartbeat to NM immediately after downloading a resource instead of always waiting for a second. Contributed by Siddarth Seth.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ContainerLocalizer.java#localizeFiles(LocalizationProtocol,ExecutorService,UserGroupInformation)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#13.0#7.0#13.0#15.0#52.0#39.0#13.0#10.0#6.0#5.0#// TODO cleanup#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ContainerLocalizer.java#createStatus()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#10.0#10.0#23.0#23.0#39.0#39.0#5.0#5.0#3.0#3.0#// TODO shouldn't remove until ACK#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/fs/HdfsVolumeId.java#equals(Object)#6cc49f1a8b72eefb91e405d7bde0468906c1819f#2012-12-05 01:45:29#12f4df043fb6922c6ce1c470a2e020b4111f8739#2015-04-22 09:10:12#-1#2.0#6.0#4.0#4.0#13.0#20.0#3.0#4.0#1.0#1.0#// because we have class identity checking above, and for this class // isValid() is always true.#6cc49f1a8b72eefb91e405d7bde0468906c1819f#HDFS-4199. Provide test for HdfsVolumeId. Contributed by Ivan A. Veselovsky.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java#handshake(NamenodeProtocol)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#2151716832ad14932dd65b1a4e47e64d8d6cd767#2016-02-29 15:34:43#-1#4.0#4.0#7.0#7.0#18.0#18.0#2.0#2.0#1.0#1.0#// TODO: move to a common with DataNode util class#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalizedResource.java#release(ContainerId)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#050fd3a11744cde3d54c1fff23d8fdeb3803bf92#2012-09-26 15:22:21#-1#6.0#6.0#4.0#5.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO: FIX#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#YARN-539. Addressed memory leak of LocalResource objects NM when a resource localization fails. Contributed by Omkar Vinit Joshi.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalResourcesTracker.java#contains(LocalResourceRequest)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#854d25b0c30fd40f640c052e79a8747741492042#2015-09-30 14:59:44#-1#0.0#-1#1.0#-1#1.0#-1#1.0#-1#0.0#-1#// TODO: Not used at all!!#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalResourcesTracker.java#localizationCompleted(LocalResourceRequest,boolean)#e67e3ff05db26437b1d7c6d3dd958362fb8425db#2013-04-03 05:00:28#3a54a5653bf1ea0b5b98e223c7500a9606abf04d#2013-04-09 19:56:10#-1#2.0#3.0#0.0#0.0#1.0#1.0#1.0#1.0#0.0#0.0#// TODO: Remove this in favour of EventHandler.handle#e67e3ff05db26437b1d7c6d3dd958362fb8425db#YARN-467. Modify public distributed cache to localize files such that no local directory hits unix file count limits and thus prevent job failures. Contributed by Omkar Vinit Joshi.#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#YARN-539. Addressed memory leak of LocalResource objects NM when a resource localization fails. Contributed by Omkar Vinit Joshi.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#init(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#0057600a82cb6dc6bb8858a033003e8f9769b023#2013-02-27 15:30:10#-1#26.0#22.0#25.0#21.0#49.0#41.0#4.0#4.0#2.0#2.0#// TODO queue deletions here, rather than NM init?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#6a482a88b8f56a4c5590e71ce6713d7f63830e92#YARN-71. Fix the NodeManager to clean up local-dirs on restart. Contributed by Xuan Gong.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#handle(LocalizationEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#23.0#6.0#34.0#9.0#129.0#15.0#15.0#1.0#2.0#0.0#// TODO: FIXME assert doesn't help // ^ The condition is benign. Tests should fail and it //   should appear in logs, but it's an internal error //   that should have no effect on applications#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#handle(LocalizationEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#23.0#12.0#34.0#17.0#129.0#48.0#15.0#6.0#2.0#4.0#// TODO: What to do with appLocalRsrcsTracker?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#processHeartbeat(LocalizerStatus)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO process resources anyway#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO shutdown, better error handling esp. DU#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#update(List<LocalResourceStatus>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fafe8cd28e726566509c679e19d7da622f29f90d#2011-09-09 01:44:58#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO this sucks. Fix it later#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#8fb67650b146573c20ae010e28b1eca6e16433b3#MAPREDUCE-2691. Finish up the cleanup of distributed cache file resources and related tests. Contributed by Siddharth Seth.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#update(List<LocalResourceStatus>)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#3a54a5653bf1ea0b5b98e223c7500a9606abf04d#2013-04-09 19:56:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Why is this event going directly to the container. Why not // the resource itself? What happens to the resource? Is it removed?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#YARN-539. Addressed memory leak of LocalResource objects NM when a resource localization fails. Contributed by Omkar Vinit Joshi.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO handle ExitCodeException separately?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#update(List<LocalResourceStatus>)#8fb67650b146573c20ae010e28b1eca6e16433b3#2011-09-11 06:21:39#3a54a5653bf1ea0b5b98e223c7500a9606abf04d#2013-04-09 19:56:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO this sucks. Fix it later // dispatcher not typed#8fb67650b146573c20ae010e28b1eca6e16433b3#MAPREDUCE-2691. Finish up the cleanup of distributed cache file resources and related tests. Contributed by Siddharth Seth.#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#YARN-539. Addressed memory leak of LocalResource objects NM when a resource localization fails. Contributed by Omkar Vinit Joshi.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#update(List<LocalResourceStatus>)#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#2013-04-11 02:08:11#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#/*hadoop,        * TODO : It doesn't support multiple downloads per ContainerLocalizerhadoop,        * at the same time. We need to think whether we should support this.hadoop,        */#4234bc87b3e0bf7e9716d6ca1873b8bb0239472e#YARN-539. Addressed memory leak of LocalResource objects NM when a resource localization fails. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java#addResource(LocalizerResourceRequestEvent)#c570309b078d3c6080e89cd90c7c2157a270aaca#2013-04-19 22:35:43#fa00d3e20560bee412b49e5792595749a247a8ab#2016-02-11 12:06:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Need to Fix IO Exceptions - Notifying resource#c570309b078d3c6080e89cd90c7c2157a270aaca#YARN-547. Fixed race conditions in public and private resource localization which used to cause duplicate downloads. Contributed by Omkar Vinit Joshi.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRChildTask.java#setup()#76b653a36738a4f420f14c53c7a0a4006dbf066e#2012-01-31 02:23:38#0ef8bbfd8791899c7cfed3dd9c1670182fd87575#2016-03-29 10:32:21#-1#7.0#7.0#15.0#15.0#23.0#23.0#3.0#3.0#1.0#1.0#// Copy MRAppJar and make it private. TODO: FIXME. This is a hack to // workaround the absent public discache.#76b653a36738a4f420f14c53c7a0a4006dbf066e#MAPREDUCE-3716. Fixing YARN+MR to allow MR jobs to be able to use java.io.File.createTempFile to create temporary files as part of their tasks. Contributed by Jonathan Eagles.##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/TaskInProgress.java#updateStatus(TaskStatus)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#17.0#17.0#30.0#31.0#91.0#95.0#9.0#9.0#2.0#3.0#// The task is not allowed to move from completed back to running. // We have seen out of order status messagesmoving tasks from complete // to running. This is a spot fix, but it should be addressed more // globally.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/TaskTracker.java#offerService()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#23.0#23.0#40.0#40.0#121.0#121.0#22.0#22.0#6.0#6.0#//The check below may not be required every iteration but we are  //erring on the side of caution here. We have seen many cases where //the call to jetty's getLocalPort() returns different values at  //different times. Being a real paranoid here.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/lib/join/ResetableIterator.java#close()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#2.0#0.0#0.0#1.0#1.0#1.0#1.0#0.0#0.0#// XXX is this necessary?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java#transition(RMAppAttemptImpl,RMAppAttemptEvent)#6cd0736cc57849e4f7c5d38a3986432a9717fe39#2012-12-19 04:21:18#308d63f382e1992ea2b8ccf3130edaaa751c644d#2016-02-04 13:32:54#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Send the acceptance to the app // Ideally this should have been done when the scheduler accepted the app. // But its here because until the attempt is saved the client should not // launch the unmanaged AM. Client waits for the app status to be accepted // before doing so. So we have to delay the accepted state until we have  // completed storing the attempt#6cd0736cc57849e4f7c5d38a3986432a9717fe39#YARN-230. RM Restart phase 1 - includes support for saving/restarting all applications on an RM bounce. Contributed by Bikas Saha.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/TestRMAppAttemptTransitions.java#testAppAttemptLaunchedState(Container)#063e33a862f99ce93b8399924c35d39ccd880f01#2011-09-30 12:46:32#772ea7b41b06beaa1f4ac4fa86eac8d6e6c8cd36#2016-01-29 21:48:54#-1#4.0#5.0#3.0#6.0#7.0#11.0#1.0#2.0#0.0#1.0#// TODO - need to add more checks relevant to this state#063e33a862f99ce93b8399924c35d39ccd880f01#MAPREDUCE-3098. Fixed RM and MR AM to report YarnApplicationState and application's FinalStatus separately. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#getReport()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#11.0#13.0#15.0#17.0#24.0#26.0#2.0#2.0#2.0#2.0#// TODO - Fix to correctly setup report and to check state#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#getTotalMaps()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#1.0#2.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#//FIXME: why indirection? return numMapTasks... // unless race?  how soon can this get called?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#getTotalReduces()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#1.0#2.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#//FIXME: why indirection? return numReduceTasks#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#transition(JobImpl,JobEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#30.0#-1#14.0#-1#99.0#-1#11.0#-1#2.0#//FIXME:  need new memory criterion for uber-decision (oops, too late here; until AM-resizing supported, must depend on job client to pass fat-slot needs) // these are no longer "system" settings, necessarily; user may override#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#transition(JobImpl,JobEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9fe9f42c8fad872f7aab5f9bbdac4a860edb0d43#2011-11-08 07:28:56#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//FIXME (see above) // ignoring overhead due to UberTask and statics as negligible here: //  FIXME   && (Math.max(memoryPerMap, memoryPerReduce) <= sysMemSizeForUberSlot //              || sysMemSizeForUberSlot == JobConf.DISABLED_MEMORY_LIMIT)#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#transition(JobImpl,JobEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9fe9f42c8fad872f7aab5f9bbdac4a860edb0d43#2011-11-08 07:28:56#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: also note which node?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#transition(JobImpl,JobEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#b43deb9af85575ee71e29b385737436139ec5b13#2012-11-28 17:52:45#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO XXX Should JobInitedEvent be generated here (instead of in StartTransition)#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#402eb1851341fce72c8e46266a2578bb67b5b684#MAPREDUCE-4813. AM timing out during job commit (jlowe via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#transition(JobImpl,JobEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Is this JH event required.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#makeUberDecision(long)#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#2011-12-13 23:35:11#7d04a96027ad75877b41b7cd8f67455dd13159d7#2012-04-18 01:59:16#-1#21.0#22.0#13.0#14.0#79.0#80.0#8.0#8.0#2.0#2.0#//FIXME: handling multiple reduces within a single AM does not seem to //work. // int sysMaxReduces = //     job.conf.getInt(MRJobConfig.JOB_UBERTASK_MAXREDUCES, 1);#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.#e3806060ce01557ba75094665b032dcca5656a19#MAPREDUCE-4159. Job is running in Uber mode after setting "mapreduce.job.ubertask.maxreduces" to zero (Devaraj K via bobby)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#makeUberDecision(long)#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#2011-12-13 23:35:11#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#21.0#30.0#13.0#14.0#79.0#99.0#8.0#11.0#2.0#2.0#//FIXME: this is // wrong; get FS from [File?]InputFormat and default block size from that#b7ae5a6cb7b2d3e3112ac53007e984caeb07de58#MAPREDUCE-3426. Fixed MR AM in uber mode to write map intermediate outputs in the correct directory to work properly in secure mode. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java#makeUberDecision(long)#e3806060ce01557ba75094665b032dcca5656a19#2012-04-19 16:22:22#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#23.0#30.0#14.0#14.0#82.0#99.0#9.0#11.0#2.0#2.0#//FIXME: handling multiple reduces within a single AM does not seem to //work.#e3806060ce01557ba75094665b032dcca5656a19#MAPREDUCE-4159. Job is running in Uber mode after setting "mapreduce.job.ubertask.maxreduces" to zero (Devaraj K via bobby)##
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestAllowFormat.java#setUp()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#5eb618ee1f90ccf901edb5d89be181fad1f67d7f#2013-09-06 03:06:41#-1#7.0#7.0#12.0#10.0#29.0#26.0#2.0#2.0#1.0#1.0#// Test has multiple name directories. // Format should not really prompt us if one of the directories exist, // but is empty. So in case the test hangs on an input, it means something // could be wrong in the format prompting code. (HDFS-1636)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/contrib/mumak/src/java/org/apache/hadoop/mapred/SimulatorTaskTracker.java#processHeartbeatEvent(HeartbeatEvent)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#16.0#16.0#19.0#19.0#63.0#63.0#4.0#4.0#1.0#1.0#// 0 means failures == 0 here. Undocumented in TaskTracker, but does not  // seem to be used at all in org.apache.hadoop.mapred .#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#1ad8415b72cb2b2dbfa85d27771177873c2a5c4c#MAPREDUCE-2736. Remove unused contrib components dependent on MR1. Contributed by Eli Collins
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#createLocalResource(FileSystem,RecordFactory,Path,LocalResourceType,LocalResourceVisibility)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#8fa0a3c737f27ff9d12fb657a7b22865754a5fd8#2011-12-22 22:34:40#-1#7.0#7.0#13.0#13.0#14.0#14.0#1.0#1.0#0.0#0.0#/**hadoop,   * Create a {@link LocalResource} record with all the given parameters.hadoop,   * TODO: This should pave way for Builder pattern.hadoop,   */#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#0870734787d7005d85697549eab5b6479d97d453#MAPREDUCE-3566. Fixed MR AM to construct CLC only once across all tasks. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#getInitialClasspath()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#8fa0a3c737f27ff9d12fb657a7b22865754a5fd8#2011-12-22 22:34:40#-1#5.0#5.0#5.0#6.0#12.0#12.0#2.0#2.0#1.0#1.0#/**hadoop,   * Lock this on initialClasspath so that there is only one fork in the AM forhadoop,   * getting the initial class-path. TODO: This should go away once we constructhadoop,   * a parent CLC and use it for all the containers.hadoop,   */#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#0870734787d7005d85697549eab5b6479d97d453#MAPREDUCE-3566. Fixed MR AM to construct CLC only once across all tasks. Contributed by Vinod K V.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#createContainerLaunchContext()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9992cae54120d2742922745c1f513c6bfbde67a9#2011-09-29 00:33:34#-1#24.0#24.0#46.0#48.0#117.0#125.0#5.0#5.0#3.0#3.0#// TODO: Fix#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ab0402bc1def44e3d52eea517f4132c460bd5f87#Merging trunk to HDFS-1623 branch
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#getFileSizes(Configuration,String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#53f921418d25cb232c7a0e1fa24c17bda729ac35#2011-09-13 18:12:02#-1#3.0#3.0#3.0#3.0#11.0#11.0#3.0#3.0#1.0#1.0#// TODO - Move this to MR!#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#88b82a0f6687ce103817fbb460fd30d870f717a0#MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#isFinished()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#32b3dc11eba8f2d8f22ca502bf30d6aa8839460e#2015-12-28 11:03:23#-1#4.0#4.0#4.0#4.0#11.0#11.0#1.0#1.0#1.0#1.0#// TODO: Use stateMachine level method?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#transition(TaskAttemptImpl,TaskAttemptEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#e4c55e17fea55e2fcbef182bb2b0c4b22686f38c#2013-04-11 19:28:51#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Resolve to host / IP in case of a local address.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#cb78a65a152a4f576a3255df3676c3b788c84eb5#MAPREDUCE-5152. Make MR App to simply pass through the container from RM instead of extracting and populating information itself to start any container. Contributed by Vinod Kumar Vavilapalli.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#getInitialClasspath()#0870734787d7005d85697549eab5b6479d97d453#2012-01-05 01:29:52#32b3dc11eba8f2d8f22ca502bf30d6aa8839460e#2015-12-28 11:03:23#-1#5.0#7.0#6.0#7.0#12.0#13.0#2.0#2.0#1.0#1.0#/**hadoop,   * Lock this on initialClasspath so that there is only one fork in the AM forhadoop,   * getting the initial class-path. TODO: We already constructhadoop,   * a parent CLC and use it for all the containers, so this should go awayhadoop,   * once the mr-generated-classpath stuff is gone.hadoop,   */#0870734787d7005d85697549eab5b6479d97d453#MAPREDUCE-3566. Fixed MR AM to construct CLC only once across all tasks. Contributed by Vinod K V.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java#transition(TaskAttemptImpl,TaskAttemptEvent)#cb78a65a152a4f576a3255df3676c3b788c84eb5#2013-04-18 20:13:40#32b3dc11eba8f2d8f22ca502bf30d6aa8839460e#2015-12-28 11:03:23#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Resolve to host / IP in case of a local address. // TODO: Costly to create sock-addr?#cb78a65a152a4f576a3255df3676c3b788c84eb5#MAPREDUCE-5152. Make MR App to simply pass through the container from RM instead of extracting and populating information itself to start any container. Contributed by Vinod Kumar Vavilapalli.##
hadoop#DESIGN#mapreduce/src/test/system/test/org/apache/hadoop/mapred/TestDistributedCachePrivateFile.java#testDistributedCache()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#8.0#8.0#50.0#50.0#161.0#161.0#15.0#15.0#5.0#5.0#//Private Distributed cache will always be stored under //mapre.local.dir/taskTracker/<username>/distcache //Checking for username directory to check if it has the //proper permissions#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#30807fec82e80044cd39fb154208c6fb32d980da#HADOOP-8450. Remove src/test/system. Contributed by Eli Collins
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#isFinished()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#439f43ad3defbac907eda2d139a793f153544430#2015-10-02 20:34:34#-1#5.0#5.0#4.0#4.0#11.0#11.0#1.0#1.0#1.0#1.0#// TODO: Use stateMachine level method?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#selectBestAttempt()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#53f921418d25cb232c7a0e1fa24c17bda729ac35#2011-09-13 18:12:02#-1#3.0#3.0#3.0#3.0#16.0#16.0#4.0#4.0#2.0#2.0#//TODO: consider the nextAttemptNumber only if it is not failed/killed ? // calculate the best progress#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#d6546fc0a444228c9d45b5bef89aeef120f98831#MAPREDUCE-3125. Modified TaskImpl to consider only non-failed, non-killed task-attempts for obtaining task's progress. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#handleTaskAttemptCompletion(TaskAttemptId,TaskAttemptCompletionEventStatus)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#10.0#10.0#15.0#15.0#23.0#23.0#3.0#3.0#2.0#2.0#//TODO: XXXXXX  hardcoded port#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#ade0f0560f729e50382c6992f713f29e2dd5b270#MAPREDUCE-2652. Enabled multiple NMs to be runnable on a single node by making shuffle service port to be truely configurable. Contributed by Robert Joseph Evans.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#transition(TaskImpl,TaskEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#439f43ad3defbac907eda2d139a793f153544430#2015-10-02 20:34:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: validate attemptID#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#transition(TaskImpl,TaskEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#439f43ad3defbac907eda2d139a793f153544430#2015-10-02 20:34:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// This is okay because it can only talk us out of sending a //  TA_KILL message to an attempt that doesn't need one for //  other reasons.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#transition(TaskImpl,TaskEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#9d16c9354b0c05edb30d23003dcdec4cc44ed925#2012-07-26 13:23:05#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//verify that this occurs only for map task //TODO: consider moving it to MapTaskImpl#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#3b46295c283cb73d9487d82a4102b77b3b362f03#MAPREDUCE-4607. Race condition in ReduceTask completion can result in Task being incorrectly failed. Contributed by Bikas Saha.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#transition(TaskImpl,TaskEvent)#3b46295c283cb73d9487d82a4102b77b3b362f03#2012-09-11 14:04:03#439f43ad3defbac907eda2d139a793f153544430#2015-10-02 20:34:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// a successful REDUCE task should not be overridden //TODO: consider moving it to MapTaskImpl#3b46295c283cb73d9487d82a4102b77b3b362f03#MAPREDUCE-4607. Race condition in ReduceTask completion can result in Task being incorrectly failed. Contributed by Bikas Saha.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl.java#recover(TaskInfo,OutputCommitter,boolean)#6a1c41111edcdc58c846fc50e53554fbba230171#2013-04-11 04:52:38#439f43ad3defbac907eda2d139a793f153544430#2015-10-02 20:34:34#-1#26.0#26.0#40.0#40.0#98.0#98.0#15.0#15.0#3.0#3.0#// don't clobber the successful attempt completion event // TODO: this shouldn't be necessary after MAPREDUCE-4330#6a1c41111edcdc58c846fc50e53554fbba230171#MAPREDUCE-5079. Changes job recovery to restore state directly from job history, instaed of simulating state machine events. Contributed by Jason Lowe and Robert Parker.##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/s3/S3OutputStream.java#endBlock()#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#5ec7fcd9dd6bb86858c6e2583321bb9a615bd392#2014-09-10 16:14:08#-1#7.0#7.0#10.0#10.0#25.0#25.0#2.0#2.0#1.0#1.0#// // Send it to S3 // // TODO: Use passed in Progressable to report progress.#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch##
hadoop#DESIGN#hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftObjectFileStatus.java#endBlock()#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// // Send it to S3 // // TODO: Use passed in Progressable to report progress.#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#HADOOP-8545. Filesystem Implementation for OpenStack Swift##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java#start()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#3.0#2.0#7.0#8.0#30.0#63.0#1.0#1.0#0.0#0.0#// TODO: Group launching of multiple containers to a single // NodeManager into a single connection#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Load ContainerManager tokens before creating a connection. // TODO: Do it only once per NodeManager.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/launcher/ContainerLauncherImpl.java#run()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#239a5549eadeccb0ab433abb38079dbe19f862ff#2012-01-09 22:20:23#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Any synchro needed? //deallocate the container#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#849c68c7b5f80064de3692d766444c2f8864f47a#MAPREDUCE-3312. Modified MR AM to not send a stop-container request for a container that isn't launched at all. Contributed by Robert Joseph Evans.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/local/LocalContainerAllocator.java#handle(ContainerAllocatorEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#547ded7bfeadddcb633f74de62fea310d61ba233#2012-02-29 15:49:27#-1#10.0#10.0#22.0#22.0#30.0#30.0#3.0#3.0#2.0#2.0#// use negative ids to denote that these are local. Need a better way ??#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#4e44259cbda1d5c5e923f979c6f6f8bdb3056198#MAPREDUCE-3682 Tracker URL says AM tasks run on localhost. (Ravi Prakash via tgraves)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/records/ProtoBase.java#hashCode()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#b776bd46aed2f5b3aa226af36c0081a7d1f69eda#2013-08-15 07:20:14#-1#1.0#0.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#//TODO Force a comparator?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/main/java/org/apache/hadoop/registry/client/types/ServiceRecord.java#hashCode()#6a326711aa27e84fd4c53937afc5c41a746ec65a#2014-10-08 12:54:37#1670578018b3210d518408530858a869e37b23cb#2014-11-06 20:21:25#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Force a comparator?#6a326711aa27e84fd4c53937afc5c41a746ec65a#YARN-913 service registry: YARN-2652 add hadoop-yarn-registry package under hadoop-yarn##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/sharedcache/SharedCacheUploader.java#hashCode()#a04143039e7fe310d807f40584633096181cfada#2014-11-12 09:31:05#470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080#2015-05-19 10:49:17#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO Force a comparator?#a04143039e7fe310d807f40584633096181cfada#YARN-2236. [YARN-1492] Shared Cache uploader service on the Node Manager. (Chris Trezzo and Sanjin Lee via kasha)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java#unprotectedRenameTo(String,String,long,Options.Rename...)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#27e0681f28ee896ada163bbbc08fd44d113e7d15#2016-03-02 14:43:03#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Rename failed - restore dst#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java#updateCountForINodeWithQuota(INodeDirectory,INode.DirCounts,ArrayList<INode>)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#a4bae51b7dac4301942ed28d0128fc9ef6a0d13a#2013-05-02 06:02:12#-1#7.0#9.0#16.0#17.0#54.0#54.0#7.0#7.0#3.0#3.0#/* We don't need nodesInPath if we could use 'parent' field in hadoop,     * INode. using 'parent' is not currently recommended. */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#59801391400f3fa0ed1f029b7af75627d3288f22#HDFS-4809. When a QuotaExceededException is thrown during rename, the quota usage should be subtracted back.  Contributed by Jing Zhao
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java#unprotectedRenameTo(String,String,long)#1096917649fd951be633e5619518764f23cca645#2013-04-01 23:24:42#1096917649fd951be633e5619518764f23cca645#2013-04-01 23:24:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO: setLocalName breaks created/deleted lists#1096917649fd951be633e5619518764f23cca645#HDFS-4611. Update FSImage for INodeReference.#ca848beb533790ae8abb6498f5d4676594fbae4c#HDFS-4647. Rename should call setLocalName after an inode is removed from snapshots.  Contributed by Arpit Agarwal
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java#unprotectedRenameTo(String,String,long)#9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#2013-04-13 02:48:34#27e0681f28ee896ada163bbbc08fd44d113e7d15#2016-03-02 14:43:03#-1#8.0#-1#46.0#-1#169.0#-1#21.0#-1#3.0#-1#// src and dst file/dir are in the same directory, and the dstParent has // been replaced when we removed the src. Refresh the dstIIP and // dstParent.#9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#HDFS-4675. Fix rename across snapshottable directories.  Contributed by Jing Zhao##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeStartupFixesLegacyStorageIDs.java#unprotectedRenameTo(String,String,long)#d34074e237ee10b83aeb02294f595714d43e39e4#2015-01-22 14:08:20#d34074e237ee10b83aeb02294f595714d43e39e4#2015-01-22 14:08:20#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// src and dst file/dir are in the same directory, and the dstParent has // been replaced when we removed the src. Refresh the dstIIP and // dstParent.#d34074e237ee10b83aeb02294f595714d43e39e4#HDFS-7575. Upgrade should generate a unique storage ID for each volume. (Contributed by Arpit Agarwal)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeStartupFixesLegacyStorageIDs.java#unprotectedRenameTo(String,String,long,Options.Rename...)#d34074e237ee10b83aeb02294f595714d43e39e4#2015-01-22 14:08:20#d34074e237ee10b83aeb02294f595714d43e39e4#2015-01-22 14:08:20#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Rename failed - restore dst#d34074e237ee10b83aeb02294f595714d43e39e4#HDFS-7575. Upgrade should generate a unique storage ID for each volume. (Contributed by Arpit Agarwal)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java#unprotectedRenameTo(String,String,long)#8e8a769e7f5ce806ffdf584f017512ab58cd84e8#2014-06-18 01:00:32#843806d03ab1a24f191782f42eb817505228eb9f#2015-02-03 14:45:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// src and dst file/dir are in the same directory, and the dstParent has // been replaced when we removed the src. Refresh the dstIIP and // dstParent.#8e8a769e7f5ce806ffdf584f017512ab58cd84e8#HDFS-6527. Edit log corruption due to defered INode removal. Contributed by Kihwal Lee and Jing Zhao.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java#unprotectedRenameTo(String,String,long,Options.Rename...)#8e8a769e7f5ce806ffdf584f017512ab58cd84e8#2014-06-18 01:00:32#843806d03ab1a24f191782f42eb817505228eb9f#2015-02-03 14:45:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Rename failed - restore dst#8e8a769e7f5ce806ffdf584f017512ab58cd84e8#HDFS-6527. Edit log corruption due to defered INode removal. Contributed by Kihwal Lee and Jing Zhao.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java#unprotectedRenameTo(String,String,long)#3b54223c0f32d42a84436c670d80b791a8e9696d#2014-07-14 18:10:03#7136e8c5582dc4061b566cb9f11a0d6a6d08bb93#2015-10-03 11:06:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// src and dst file/dir are in the same directory, and the dstParent has // been replaced when we removed the src. Refresh the dstIIP and // dstParent.#3b54223c0f32d42a84436c670d80b791a8e9696d#HDFS-2856. Fix block protocol so that Datanodes don't require root or jsvc. Contributed by Chris Nauroth.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java#unprotectedRenameTo(String,String,long,Options.Rename...)#3b54223c0f32d42a84436c670d80b791a8e9696d#2014-07-14 18:10:03#7136e8c5582dc4061b566cb9f11a0d6a6d08bb93#2015-10-03 11:06:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Rename failed - restore dst#3b54223c0f32d42a84436c670d80b791a8e9696d#HDFS-2856. Fix block protocol so that Datanodes don't require root or jsvc. Contributed by Chris Nauroth.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/ResourceCalculatorUtils.java#unprotectedRenameTo(String,String,long)#376233cdd4a4ddbde5a92a0627f78338cb4c38b7#2014-09-22 09:28:47#1773aac780585871072960a5863af461e112a030#2015-05-09 14:43:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// src and dst file/dir are in the same directory, and the dstParent has // been replaced when we removed the src. Refresh the dstIIP and // dstParent.#376233cdd4a4ddbde5a92a0627f78338cb4c38b7#MAPREDUCE-5279. Made MR headroom calculation honor cpu dimension when YARN scheduler resource type is memory plus cpu. Contributed by Peng Zhang and Varun Vasudev.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/ResourceCalculatorUtils.java#unprotectedRenameTo(String,String,long,Options.Rename...)#376233cdd4a4ddbde5a92a0627f78338cb4c38b7#2014-09-22 09:28:47#1773aac780585871072960a5863af461e112a030#2015-05-09 14:43:18#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Rename failed - restore dst#376233cdd4a4ddbde5a92a0627f78338cb4c38b7#MAPREDUCE-5279. Made MR headroom calculation honor cpu dimension when YARN scheduler resource type is memory plus cpu. Contributed by Peng Zhang and Varun Vasudev.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMCommunicator.java#startAllocatorThread()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#8dfec7a1979e8f70f8355c096874921d368342ef#2015-08-15 00:52:11#-1#2.0#2.0#2.0#3.0#22.0#5.0#1.0#1.0#0.0#0.0#// TODO: for other exceptions#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java#waitTillNTasksStartRunning(JobInProgress,boolean,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#5.0#5.0#5.0#5.0#13.0#13.0#4.0#4.0#1.0#1.0#/**hadoop,   * Wait till noOfTasksToBeRunning number of tasks of type specified by isMaphadoop,   * started running. This currently uses a jip object and directly uses its apihadoop,   * to determine the number of tasks running.hadoop,   * hadoop,   * <p>hadoop,   * hadoop,   * TODO: It should eventually use a JobID and then get the information fromhadoop,   * the JT to check the number of running tasks.hadoop,   * hadoop,   * @param jiphadoop,   * @param isMaphadoop,   * @param noOfTasksToBeRunninghadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java#assertNumTasksRunning(JobInProgress,boolean,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#3.0#3.0#2.0#2.0#8.0#8.0#3.0#3.0#1.0#1.0#/**hadoop,   * Make sure that the number of tasks of type specified by isMap running inhadoop,   * the given job is the same as noOfTasksToBeRunninghadoop,   * hadoop,   * <p>hadoop,   * hadoop,   * TODO: It should eventually use a JobID and then get the information fromhadoop,   * the JT to check the number of running tasks.hadoop,   * hadoop,   * @param jiphadoop,   * @param isMaphadoop,   * @param noOfTasksToBeRunninghadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java#waitTillNTotalTasksFinish(JobInProgress,boolean,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#5.0#5.0#5.0#5.0#14.0#14.0#4.0#4.0#1.0#1.0#/**hadoop,   * Wait till noOfTasksToFinish number of tasks of type specified by isMaphadoop,   * are finished. This currently uses a jip object and directly uses its api tohadoop,   * determine the number of tasks finished.hadoop,   * hadoop,   * <p>hadoop,   * hadoop,   * TODO: It should eventually use a JobID and then get the information fromhadoop,   * the JT to check the number of finished tasks.hadoop,   * hadoop,   * @param jiphadoop,   * @param isMaphadoop,   * @param noOfTasksToFinishhadoop,   * @throws InterruptedExceptionhadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java#testMultiLevelQueues()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa7a43529d529f0006c8033c2003f15b9b93f103#2016-03-16 17:02:10#-1#19.0#18.0#21.0#26.0#125.0#140.0#1.0#1.0#0.0#0.0#// a should be capped at 3/30 // shouldn't be  // allocated due  // to max-cap#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java#addMap(ContainerRequestEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#ab0402bc1def44e3d52eea517f4132c460bd5f87#2011-09-29 00:42:47#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//host comes from data splitLocations which are hostnames. Containers // use IP addresses. //TODO Temporary fix for locality. Use resolvers from h-common.  // Cache to make this more efficient ?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#74748ec62570f92d57dbad3ba4cca47402990db5#MAPREDUCE-2693. Fix NPE in job-blacklisting. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor.java#containerFailedOnHost(String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#ab0402bc1def44e3d52eea517f4132c460bd5f87#2011-09-29 00:42:47#-1#9.0#9.0#6.0#6.0#32.0#32.0#8.0#8.0#4.0#4.0#//TODO: remove from rack#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#74748ec62570f92d57dbad3ba4cca47402990db5#MAPREDUCE-2693. Fix NPE in job-blacklisting. Contributed by Hitesh Shah.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor.java#containerFailedOnHost(String)#74748ec62570f92d57dbad3ba4cca47402990db5#2011-10-19 22:02:21#4aa9b3e75ca86917125e56e1b438668273a5d87f#2015-10-04 23:49:02#-1#9.0#11.0#9.0#18.0#55.0#64.0#10.0#12.0#5.0#5.0#// TODO handling of rack blacklisting // Removing from rack should be dependent on no. of failures within the rack  // Blacklisting a rack on the basis of a single node's blacklisting  // may be overly aggressive.  // Node failures could be co-related with other failures on the same rack  // but we probably need a better approach at trying to decide how and when  // to blacklist a rack#74748ec62570f92d57dbad3ba4cca47402990db5#MAPREDUCE-2693. Fix NPE in job-blacklisting. Contributed by Hitesh Shah.##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java#numericalCompare(byte[],int,int,byte[],int,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#10.0#10.0#4.0#4.0#87.0#87.0#23.0#23.0#2.0#2.0#//check for cases like -0.0 and 0.0 (they should be declared equal)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java#numericalCompare(byte[],int,int,byte[],int,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#10.0#10.0#4.0#4.0#87.0#87.0#23.0#23.0#2.0#2.0#//check for cases like 0.0 and -0.0 (they should be declared equal)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java#createClientDatanodeProtocolProxy(DatanodeID,Configuration,int,LocatedBlock)#2740112bb64e1cc8132a1dc450d9e461c2e4729e#2011-12-11 18:53:21#86c95cb31a392d2ee4dcf3cc36e924ad34000b27#2015-12-04 20:24:08#-1#7.0#8.0#16.0#14.0#26.0#25.0#2.0#1.0#1.0#0.0#// Since we're creating a new UserGroupInformation here, we know that no // future RPC proxies will be able to re-use the same connection. And // usages of this proxy tend to be one-off calls. // // This is a temporary fix: callers should really achieve this by using // RPC.stopProxy() on the resulting object, but this is currently not // working in trunk. See the discussion on HDFS-1965.#2740112bb64e1cc8132a1dc450d9e461c2e4729e#HDFS-2647. Used protobuf based RPC for InterDatanodeProtocol, ClientDatanodeProtocol, JournalProtocol, NamenodeProtocol. Contributed by Suresh Srinivas.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogAggregationService.java#initApp(ApplicationId,String,Credentials,ContainerLogsRetentionPolicy)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#954dd57043d2de4f962876c1b89753bfc7e4ce55#2016-02-24 15:00:24#-1#9.0#3.0#9.0#1.0#46.0#53.0#5.0#2.0#1.0#1.0#// TODO: Reuse FS for user?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogAggregationService.java#getRemoteLogSuffixedDir(Path,String,String)#670fa24b48acb407c22fbfdde87ae3123dcbf449#2011-10-28 06:45:04#a75c4cf4e4400a2dcb3edc88df7f35a763f93c4e#2011-10-31 09:55:29#-1#5.0#5.0#4.0#4.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO Maybe support suffix to be more than a single file.#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.#c27601fefebd0af887a12d684bfc6f90d9fc0321#MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSAddressConfig.java#testDFSAddressConfig()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#e2253b539e5d18b7006e8645a573659ca3e77699#2012-07-18 03:46:28#-1#1.0#4.0#17.0#17.0#69.0#69.0#3.0#3.0#1.0#1.0#/*-------------------------------------------------------------------------hadoop,     * Shut down the datanodes, reconfigure, and bring them back up.hadoop,     * This time, modify the dfs.datanode properties and make sure that theyhadoop,     * are used to configure sockets by MiniDFSCluster.startDataNodes().hadoop,     *------------------------------------------------------------------------*/#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeImpl.java#transition(RMNodeImpl,RMNodeEvent)#ffd2e01604be814fa3db1dded7cd7cff26a79b1e#2012-08-25 02:18:49#27c8a87a54322bb231782e2a668ad2331997b422#2013-02-28 21:02:06#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// HeartBeat processing from our end is done, as node pulls the following // lists before sending status-updates. Clear data-structures // TODO: These lists could go to the NM multiple times, or never.#ffd2e01604be814fa3db1dded7cd7cff26a79b1e#YARN-39. RM-NM secret-keys should be randomly generated and rolled every so often. (Contributed by Vinod Kumar Vavilapalli and Siddharth Seth)#83d80658673b286efc534d96463e4c93fb818858#YARN-376. Fixes a bug which would prevent the NM knowing about completed containers and applications. Contributed by Jason Lowe.
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/NotificationTestCase.java#testMR()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7dcef364a99d0b276db98610270d53a8a73e62c4#2011-10-26 02:12:50#-1#1.0#1.0#13.0#13.0#29.0#29.0#2.0#2.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#common/src/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java#compress(byte[],int,int)#7e1e4bf50fa83083e762fc267b5215d606a64c3e#2011-06-20 16:32:27#7e1e4bf50fa83083e762fc267b5215d606a64c3e#2011-06-20 16:32:27#-1#7.0#7.0#9.0#9.0#56.0#56.0#9.0#9.0#2.0#2.0#// Only need todo this once#7e1e4bf50fa83083e762fc267b5215d606a64c3e#HADOOP-7206. Integrate Snappy compression. Contributed by T Jake Luciani.#75de23c0d383aa829ae25f19fbfc4fab51959ec4#Revert commit 1137690 (HADOOP-7206)
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Copy.java#processOptions(LinkedList<String>)#4de502c7c050373efe8620b320ab4413bd54cfa2#2011-05-06 20:55:30#4de502c7c050373efe8620b320ab4413bd54cfa2#2011-05-06 20:55:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this really should be a -nl option#4de502c7c050373efe8620b320ab4413bd54cfa2#HADOOP-7251. Refactor the getmerge command to conform to new FsCommand class.  Contributed by Daryn Sharp#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.
hadoop#DESIGN#mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingAsDifferentUser.java#testStreamingWithDistCache()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#3.0#3.0#19.0#19.0#87.0#87.0#2.0#2.0#0.0#0.0#// put the file(that should go into public dist cache) in dfs and set // read and exe permissions for others#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#1c15670d531945e3cae856af35bc0e52567c2ea5#MAPREDUCE-2948. Hadoop streaming test failure, post MR-2767 (mahadev)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java#purgeLogsOlderThan(long)#7be4e5bd222c6f1c40f88ee8b24b1587e157a87e#2012-03-02 01:32:49#2151716832ad14932dd65b1a4e47e64d8d6cd767#2016-02-29 15:34:43#-1#5.0#4.0#1.0#2.0#14.0#23.0#2.0#4.0#1.0#1.0#// This could be improved to not need synchronization. But currently, // journalSet is not threadsafe, so we need to synchronize this method.#7be4e5bd222c6f1c40f88ee8b24b1587e157a87e#HDFS-3039. Address findbugs and javadoc warnings on branch. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLog.java#recoverUnclosedStreams()#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#2151716832ad14932dd65b1a4e47e64d8d6cd767#2016-02-29 15:34:43#-1#7.0#8.0#2.0#2.0#11.0#11.0#2.0#2.0#1.0#1.0#// All journals have failed, it is handled in logSync. // TODO: are we sure this is OK?#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java#loadEditRecords(int,EditLogInputStream,boolean,long)#71071b904d0c9aec7b3713d41740f24182e81c36#2011-12-16 04:18:58#cf611255d6fcd7016e0ce2a3f80ccd0d4e051d9f#2012-02-01 05:16:49#-1#99.0#90.0#54.0#37.0#304.0#251.0#45.0#37.0#7.0#4.0#// TODO: We should do away with this add-then-replace dance.#71071b904d0c9aec7b3713d41740f24182e81c36#HDFS-2602. NN should log newly-allocated blocks without losing BlockInfo. Contributed by Aaron T. Myers#191db6a9073e8660440c85d2c1a65e2a48b4b45c#HDFS-2718. Optimize OP_ADD in edits loading. Contributed by Konstantin Shvachko.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java#loadEditRecords(int,EditLogInputStream,boolean,long)#71071b904d0c9aec7b3713d41740f24182e81c36#2011-12-16 04:18:58#cf611255d6fcd7016e0ce2a3f80ccd0d4e051d9f#2012-02-01 05:16:49#-1#99.0#90.0#54.0#37.0#304.0#251.0#45.0#37.0#7.0#4.0#// TODO: we could use removeLease(holder, path) here, but OP_CLOSE // doesn't seem to serialize the holder... unclear why!#71071b904d0c9aec7b3713d41740f24182e81c36#HDFS-2602. NN should log newly-allocated blocks without losing BlockInfo. Contributed by Aaron T. Myers#191db6a9073e8660440c85d2c1a65e2a48b4b45c#HDFS-2718. Optimize OP_ADD in edits loading. Contributed by Konstantin Shvachko.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java#updateBlocks(FSDirectory,BlockListUpdatingOp,INodeFile)#30cffeb388f9065f0c5ce5fa53e127940a8917b6#2012-03-01 00:37:09#ec25c7f9c7e60c077d8c4143253c20445fcdaecf#2016-01-27 16:34:40#-1#5.0#-1#20.0#-1#81.0#-1#11.0#-1#3.0#-1#// TODO: shouldn't this only be true for the last block? // what about an old-version fsync() where fsync isn't called // until several blocks in?#30cffeb388f9065f0c5ce5fa53e127940a8917b6#HDFS-3023. Optimize entries in edits log for persistBlocks call. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInotifyEventInputStream.java#updateBlocks(FSDirectory,BlockListUpdatingOp,INodeFile)#faa4455be512e070fa420084be8d1be5c72f3b08#2014-09-02 14:02:29#a4d9acc51d1a977bc333da17780c00c72e8546f1#2015-08-25 14:09:13#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: shouldn't this only be true for the last block? // what about an old-version fsync() where fsync isn't called // until several blocks in?#faa4455be512e070fa420084be8d1be5c72f3b08#HDFS-6634. inotify in HDFS. Contributed by James Thomas.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java#writeFields(DataOutputStream)#438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea#2011-07-26 20:46:58#8ae98a9d1ca4725e28783370517cb3a3ecda7324#2011-09-04 19:30:12#-1#1.0#1.0#0.0#0.0#1.0#1.0#1.0#1.0#0.0#0.0#// mtime // atime, unused at this time#438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea#HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.#dafa8f7a77e8e569f5e5b2dc0887f8fd95ca7ef6#HDFS-362.  FSEditLog should not writes long and short as UTF8, and should not use ArrayWritable for writing non-array items.  Contributed by Uma Maheswara Rao G
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java#writeFields(DataOutputStream)#dafa8f7a77e8e569f5e5b2dc0887f8fd95ca7ef6#2011-09-17 10:53:44#2151716832ad14932dd65b1a4e47e64d8d6cd767#2016-02-29 15:34:43#-1#1.0#1.0#0.0#0.0#1.0#1.0#1.0#1.0#0.0#0.0#// mtime // atime, unused at this#dafa8f7a77e8e569f5e5b2dc0887f8fd95ca7ef6#HDFS-362.  FSEditLog should not writes long and short as UTF8, and should not use ArrayWritable for writing non-array items.  Contributed by Uma Maheswara Rao G##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java#readOp(boolean)#95710c15b7a724897bcde826e112df6d4b4fe56b#2012-05-15 00:41:37#2151716832ad14932dd65b1a4e47e64d8d6cd767#2016-02-29 15:34:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// FSEditLogOpdecodeOp is not supposed to throw RuntimeException. // However, we handle it here for recovery mode, just to be more // robust.#95710c15b7a724897bcde826e112df6d4b4fe56b#HDFS-3335. check for edit log corruption at the end of the log. Contributed by Colin Patrick McCabe.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInputStream.java#writeFields(DataOutputStream)#e89fc53a1d264fde407dd2c36defab5241cd0b52#2015-04-30 19:09:57#3aac4758b007a56e3d66998d457b2156effca528#2015-08-19 11:28:05#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// mtime // atime, unused at this#e89fc53a1d264fde407dd2c36defab5241cd0b52#HDFS-5574. Remove buffer copy in BlockReader.skip. Contributed by Binglin Chang.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInputStream.java#readOp(boolean)#e89fc53a1d264fde407dd2c36defab5241cd0b52#2015-04-30 19:09:57#3aac4758b007a56e3d66998d457b2156effca528#2015-08-19 11:28:05#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// FSEditLogOpdecodeOp is not supposed to throw RuntimeException. // However, we handle it here for recovery mode, just to be more // robust.#e89fc53a1d264fde407dd2c36defab5241cd0b52#HDFS-5574. Remove buffer copy in BlockReader.skip. Contributed by Binglin Chang.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java#writeFields(DataOutputStream)#7e9358feb326d48b8c4f00249e7af5023cebd2e2#2015-01-12 21:53:52#ec25c7f9c7e60c077d8c4143253c20445fcdaecf#2016-01-27 16:34:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// mtime // atime, unused at this#7e9358feb326d48b8c4f00249e7af5023cebd2e2#HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java#readOp(boolean)#7e9358feb326d48b8c4f00249e7af5023cebd2e2#2015-01-12 21:53:52#ec25c7f9c7e60c077d8c4143253c20445fcdaecf#2016-01-27 16:34:40#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// FSEditLogOpdecodeOp is not supposed to throw RuntimeException. // However, we handle it here for recovery mode, just to be more // robust.#7e9358feb326d48b8c4f00249e7af5023cebd2e2#HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/ExponentiallySmoothedTaskRuntimeEstimator.java#incorporateReading(TaskAttemptId,float,long)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#11b9dd4e844c762f8c53e5fafa25f29eece1bc87#2011-10-11 04:45:28#-1#5.0#5.0#5.0#5.0#28.0#28.0#5.0#5.0#2.0#2.0#//TODO: Refactor this method, it seems more complicated than necessary.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/HarFileSystem.java#seekToNewSource(long)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#e381af1e1ecce489a28f7d63363908ec2dd8b551#2010-03-24 17:51:38#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//do not need to implement this // hdfs in itself does seektonewsource  // while reading.#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#980f819047e3bbcb5d792f3be829f4fed3eff8c7#HADOOP-6646. Move HarfileSystem out of Hadoop Common. (mahadev)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java#loadEdits(Iterable<EditLogInputStream>,FSNamesystem)#f87a4b40bc99e76602a75906df31747cfdbff78a#2011-11-30 21:46:22#41e56dfecee0db1975c9859017c0de1226afb4b5#2012-02-18 07:12:27#-1#8.0#9.0#11.0#12.0#29.0#37.0#2.0#3.0#2.0#3.0#// update the counts // TODO(HA): this may be very slow -- we probably want to // update them as we go for HA.#f87a4b40bc99e76602a75906df31747cfdbff78a#HDFS-1975. Support for sharing the namenode state from active to standby. Contributed by Jitendra Nath Pandey, Aaron T Myers, and Todd Lipcon.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/security/TokenCache.java#obtainTokensForNamenodesInternal(FileSystem,Credentials,Configuration)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#b03023110805a3479ef6b42f7c095de3f1a883e2#2012-02-03 23:48:48#-1#8.0#10.0#17.0#16.0#43.0#53.0#7.0#11.0#4.0#4.0#//TODO: Need to come up with a better place to put //this block of code to do with reading the file#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#cfc4ad76a325381119351092ac9e40544141b74a#MAPREDUCE-3849. Change TokenCache's reading of the binary token file  (Daryn Sharp via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AppSchedulingInfo.java#allocate(Container)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#7f46636495e23693d588b0915f464fa7afd9102e#2016-01-27 15:38:32#-1#6.0#-1#4.0#-1#13.0#-1#1.0#-1#0.0#-1#// Update consumption and track allocations //TODO: fixme sharad#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestContinuousScheduling.java#allocate(Container)#7e42088abf230dce9c63497d0937fee4f9a1e4a5#2015-02-08 22:48:10#f84af8bd588763c4e99305742d8c86ed596e8359#2016-03-17 05:54:06#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Update consumption and track allocations //TODO: fixme sharad#7e42088abf230dce9c63497d0937fee4f9a1e4a5#YARN-2990. FairScheduler's delay-scheduling always waits for node-local and rack-local delays, even for off-rack-only requests. (kasha)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java#load(File)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#646e855f6ef058b636a5fc85637a3f8e17fddaba#2011-10-27 22:11:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#/*hadoop,         * TODO we need to change format of the image filehadoop,         * it should not contain version and namespace fieldshadoop,         */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#64641c28b5ea8538033060452b0c45b7f2eeb60c#HDFS-3137. Bump LAST_UPGRADABLE_LAYOUT_VERSION to -16. Contributed by Eli Collins
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java#save(File,FSNamesystem,FSImageCompression)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#8ae98a9d1ca4725e28783370517cb3a3ecda7324#2011-09-04 19:30:12#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO bad dependency#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#06e84a1bca19bd01568a3095e33944d4d6387fd3#HDFS-2223. Untangle depencencies between NN components. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.java#load(File)#0fa9c7a825f444d50c89b986bacea7a547e4ab8b#2012-12-28 08:26:33#1096917649fd951be633e5619518764f23cca645#2013-04-01 23:24:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// reset INodeId. TODO: remove this after inodeId is persisted in fsimage#0fa9c7a825f444d50c89b986bacea7a547e4ab8b#HDFS-4334. Add a unique id to INode.  Contributed by Brandon Li#19201622be1db8e166d1cc0dd7e62af4702d2784#HDFS-4339. Persist inode id in fsimage and editlog. Contributed by Brandon Li.
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java#getPathForConf(Path,Path)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#d0f89303e97428ed494ee28038cc3abf502b57d9#2012-01-11 22:53:36#-1#4.0#4.0#3.0#3.0#7.0#7.0#1.0#1.0#0.0#0.0#//TODO this is a hack :( // jobtracker-hostname_jobtracker-identifier_#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java#handle(ContainersMonitorEvent)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#79c41b1d83e981ae74cb8b58ffcf7907b7612ad4#2015-12-16 13:18:19#-1#5.0#10.0#8.0#18.0#27.0#51.0#4.0#7.0#1.0#2.0#// TODO: Wrong event.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java#writeINodeFile(INodeFile,DataOutputStream,boolean)#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#2013-02-08 02:18:55#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#2013-02-08 02:18:55#-1#6.0#6.0#18.0#18.0#34.0#34.0#4.0#4.0#2.0#2.0#//  TODO: fix snapshot fsimage#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#HDFS-4446. Support file snapshots with diff lists.#02e6b72ae148fc8c2ba02ef624536b9e48997b31#HDFS-4481. Change fsimage to support snapshot file diffs.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java#testSaveLoadImage()#1096917649fd951be633e5619518764f23cca645#2013-04-01 23:24:42#0b101bd7e875ee5597ddb8f0d887159076310ffa#2013-04-20 16:57:44#-1#-1#5.0#-1#11.0#-1#43.0#-1#1.0#-1#0.0#// TODO: fix case hdfs.rename(sub1file1, sub1file2);#1096917649fd951be633e5619518764f23cca645#HDFS-4611. Update FSImage for INodeReference.#65752c09ab4c070fbb7013c785d0db1dccd55d8f#HDFS-4735. DisallowSnapshot throws IllegalStateException for nested snapshottable directories.  Contributed by Jing Zhao
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestChainMapReduce.java#getFlagDir(boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#4.0#4.0#4.0#4.0#11.0#11.0#2.0#2.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/exceptions/SwiftJsonMarshallingException.java#getFlagDir(boolean)#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#5ec7fcd9dd6bb86858c6e2583321bb9a615bd392#2014-09-10 16:14:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Hack for local FS that does not have the concept of a 'mounting point'#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#HADOOP-8545. Filesystem Implementation for OpenStack Swift##
hadoop#DESIGN#hadoop-tools/hadoop-openstack/src/test/java/org/apache/hadoop/fs/swift/http/TestRestClientBindings.java#getFlagDir(boolean)#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Hack for local FS that does not have the concept of a 'mounting point'#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#HADOOP-8545. Filesystem Implementation for OpenStack Swift##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestDelegatingInputFormat.java#testSplitting()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#0050fa5f1c20087009bd76a0bb2183a479f787f0#2016-03-29 18:17:52#-1#0.0#1.0#12.0#15.0#61.0#62.0#6.0#6.0#3.0#3.0#// Each bin is a unique combination of a Mapper and InputFormat, and // DelegatingInputFormat should split each bin into numSplits splits, // regardless of the number of paths that use that Mapper/InputFormat#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/exceptions/SwiftJsonMarshallingException.java#testSplitting()#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#5ec7fcd9dd6bb86858c6e2583321bb9a615bd392#2014-09-10 16:14:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Each bin is a unique combination of a Mapper and InputFormat, and // DelegatingInputFormat should split each bin into numSplits splits, // regardless of the number of paths that use that Mapper/InputFormat#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#HADOOP-8545. Filesystem Implementation for OpenStack Swift##
hadoop#DESIGN#hadoop-tools/hadoop-openstack/src/test/java/org/apache/hadoop/fs/swift/http/TestSwiftRestClient.java#testSplitting()#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#2013-09-27 11:32:53#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Each bin is a unique combination of a Mapper and InputFormat, and // DelegatingInputFormat should split each bin into numSplits splits, // regardless of the number of paths that use that Mapper/InputFormat#3caca924bc72fe4a0e5b1ea89adb098cc1eb7874#HADOOP-8545. Filesystem Implementation for OpenStack Swift##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#registerDatanodeInternal(DatanodeRegistration)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#08928d067bb9e1d38b5e7db9e23fcf20fe161435#2011-07-20 23:35:50#-1#9.0#8.0#38.0#40.0#121.0#121.0#10.0#10.0#3.0#3.0#// The same datanode has been just restarted to serve the same data  // storage. We do not need to remove old data blocks, the delta will // be calculated on the next block report from the datanode#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#233a7aa34f37350bf7bcdd9c84b97d613e7344c9#HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#close()#f87a4b40bc99e76602a75906df31747cfdbff78a#2011-11-30 21:46:22#c14912785d22734d735b5c4f8638b57dff009a97#2012-02-22 20:31:52#-1#15.0#15.0#8.0#8.0#20.0#20.0#4.0#4.0#2.0#2.0#// TODO: these lines spew lots of warnings about "already stopped" logs, etc#f87a4b40bc99e76602a75906df31747cfdbff78a#HDFS-1975. Support for sharing the namenode state from active to standby. Contributed by Jitendra Nath Pandey, Aaron T Myers, and Todd Lipcon.#b57260f848da5cfc6b03c871987ed34d8bfda9c7#HDFS-2978. The NameNode should expose name dir statuses via JMX. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#allowSnapshot(String)#4fde5c01901b6acb4363747d01603664a0283fc4#2012-10-23 20:26:08#98c0f13b19277a3397102cefceee984d5760ae30#2012-11-02 02:26:58#-1#1.0#3.0#0.0#5.0#4.0#9.0#1.0#2.0#0.0#1.0#// TODO: implement#4fde5c01901b6acb4363747d01603664a0283fc4#HDFS-4084. Provide CLI support to allow and disallow snapshot on a directory. Contributed by Brondon Li.#77fe43ac1440356f77c6207276463f16df75e3b5#HDFS-4095. Add some snapshot related metrics. Contributed by Jing Zhao.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#allowSnapshot(String)#f60a844e7af0fd95cb10f6faa427a73314753dbd#2012-10-28 20:02:54#cbbaa93ae09bf5cf643263faf78f99315c4f3a8d#2012-12-17 03:40:27#-1#5.0#6.0#10.0#15.0#19.0#25.0#2.0#3.0#2.0#2.0#//TODO: do not hardcode snapshot quota value#f60a844e7af0fd95cb10f6faa427a73314753dbd#HDFS-4119. Complete the allowSnapshot code and add a test for it.#b9f965de120b5278ac84a7e98aecb32aafde4c16#HDFS-4103. Support O(1) snapshot creation.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#disallowSnapshot(String)#77fe43ac1440356f77c6207276463f16df75e3b5#2012-11-02 05:01:10#77fe43ac1440356f77c6207276463f16df75e3b5#2012-11-02 05:01:10#-1#3.0#3.0#5.0#5.0#10.0#10.0#2.0#2.0#1.0#1.0#// TODO: implement, also need to update metrics in corresponding // SnapshotManager method #77fe43ac1440356f77c6207276463f16df75e3b5#HDFS-4095. Add some snapshot related metrics. Contributed by Jing Zhao.#d174f574bafcfefc635c64a47f258b1ce5d5c84e#HDFS-4143. Change blocks to private in INodeFile and renames isLink() to isSymlink() in INode.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#allowSnapshot(String)#f84000900afa8b6274eb227992134f24dbf5c2b4#2012-11-05 00:40:54#92e0416ced279a910616985bf11fa3f8b1b1de9b#2013-04-23 00:00:47#-1#6.0#6.0#15.0#14.0#25.0#24.0#3.0#3.0#2.0#2.0#//TODO: need to update metrics in corresponding SnapshotManager method #f84000900afa8b6274eb227992134f24dbf5c2b4#HDFS-4149. Implement the disallowSnapshot(..) in FSNamesystem and add resetSnapshottable(..) to SnapshotManager.#65752c09ab4c070fbb7013c785d0db1dccd55d8f#HDFS-4735. DisallowSnapshot throws IllegalStateException for nested snapshottable directories.  Contributed by Jing Zhao
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java#renameSnapshot(String,String,String)#9bed64a6fc84f640c7bfded6228b4d7fee9ea45f#2012-11-18 20:44:10#1096917649fd951be633e5619518764f23cca645#2013-04-01 23:24:42#-1#9.0#-1#16.0#-1#30.0#-1#3.0#-1#2.0#-1#// TODO: check if the new name is valid. May also need this for // creationSnapshot#9bed64a6fc84f640c7bfded6228b4d7fee9ea45f#HDFS-4196. Support renaming of snapshots. Contributed by Jing Zhao#c5bb615317f1aa8d3cba4cf331f732126655b68e#HDFS-4525. Provide an API for knowing that whether file is closed or not. Contributed by SreeHari.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/webapp/AMWebServices.java#getJobFromJobIdString(String,AppContext)#7a082ec2bd29d04abe0dc86349d163d6e03250eb#2012-02-25 02:03:59#e7583d816a69677bbaa4280deb58ea73dbc42cef#2012-04-25 21:13:06#-1#24.0#9.0#4.0#4.0#25.0#30.0#5.0#6.0#1.0#1.0#// TODO: after MAPREDUCE-2793 YarnException is probably not expected here // anymore but keeping it for now just in case other stuff starts failing. // Also, the webservice should ideally return BadRequest (HTTP:400) when // the id is malformed instead of NotFound (HTTP:404). The webserver on // top of which AMWebServices is built seems to automatically do that for // unhandled exceptions#7a082ec2bd29d04abe0dc86349d163d6e03250eb#MAPREDUCE-2793. Corrected AppIDs, JobIDs, TaskAttemptIDs to be of correct format on the web pages. Contributed by Bikas Saha.#a83fb61ac07c0468cbc7a38526e92683883dd932#YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth. MAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/webapp/AMWebServices.java#getJobFromJobIdString(String,AppContext)#a83fb61ac07c0468cbc7a38526e92683883dd932#2013-06-04 04:05:50#d18f10ad1b3e497fa1aaaeb85ba055f87d9849f7#2015-05-08 15:54:14#-1#24.0#11.0#4.0#4.0#25.0#30.0#5.0#6.0#1.0#1.0#// TODO: after MAPREDUCE-2793 YarnRuntimeException is probably not expected here // anymore but keeping it for now just in case other stuff starts failing. // Also, the webservice should ideally return BadRequest (HTTP:400) when // the id is malformed instead of NotFound (HTTP:404). The webserver on // top of which AMWebServices is built seems to automatically do that for // unhandled exceptions#a83fb61ac07c0468cbc7a38526e92683883dd932#YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth. MAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth##
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapreduce/split/SplitMetaInfoReader.java#readSplitMetaInfo(JobID,FileSystem,Configuration,Path)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#892846dc0495aa4d0247e3a75cefecc6c191fd97#2013-02-28 19:55:10#-1#10.0#11.0#16.0#16.0#38.0#39.0#5.0#5.0#1.0#1.0#//TODO: check for insane values#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java#getDir(Path)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#5.0#5.0#5.0#5.0#9.0#9.0#2.0#2.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/dfs/DFSFolder.java#upload(IProgressMonitor,File)#cab0a4bf543f58600ae8499f5b219a452f89c827#2009-05-19 04:45:07#cab0a4bf543f58600ae8499f5b219a452f89c827#2009-05-19 04:45:07#-1#4.0#4.0#10.0#10.0#22.0#22.0#5.0#5.0#3.0#3.0#// XXX don't know what the file is?#cab0a4bf543f58600ae8499f5b219a452f89c827#HADOOP-4687 split the contrib dirs#aa471150ea99d81102939e17fdbc251bd1218b44#Move eclipse-plugin from common to mapreduce
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultithreadedMapRunner.java#run(boolean,boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#6.0#6.0#33.0#33.0#69.0#69.0#7.0#7.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java#newINode(long,PermissionStatus,BlockInfo[],String,short,long,long,long,long,long,int,boolean,long,boolean,boolean,boolean,String,String)#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#2013-02-08 02:18:55#afe77ce53d3cf203690aa419e377f26cbd45a96e#2013-02-08 23:19:32#-1#15.0#14.0#9.0#9.0#34.0#34.0#7.0#7.0#2.0#2.0#//    TODO: fix image for file diff.#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#HDFS-4446. Support file snapshots with diff lists.#02e6b72ae148fc8c2ba02ef624536b9e48997b31#HDFS-4481. Change fsimage to support snapshot file diffs.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java#testInodeReplacement()#06fb184d4d0278cfb57df70ec3c264ec3e8886eb#2013-04-26 00:50:09#34ab50ea92370cc7440a8f7649286b148c2fde65#2016-02-01 11:23:44#-1#0.0#0.0#15.0#16.0#29.0#34.0#1.0#2.0#0.0#1.0#// the inode in inodeMap should also be replaced#06fb184d4d0278cfb57df70ec3c264ec3e8886eb#HDFS-4757. Update FSDirectoryinodeMap when replacing an INodeDirectory while setting quota.  Contributed by Jing Zhao##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/client/ShortCircuitCache.java#testInodeReplacement()#beb0d25d2a7ba5004c6aabd105546ba9a9fec9be#2014-02-12 19:08:52#7136e8c5582dc4061b566cb9f11a0d6a6d08bb93#2015-10-03 11:06:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// the inode in inodeMap should also be replaced#beb0d25d2a7ba5004c6aabd105546ba9a9fec9be#HDFS-5810. Unify mmap cache and short-circuit file descriptor cache (cmccabe)##
hadoop#DESIGN#src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/launch/HadoopApplicationLaunchShortcut.java#findLaunchConfiguration(IType,ILaunchConfigurationType)#cab0a4bf543f58600ae8499f5b219a452f89c827#2009-05-19 04:45:07#cab0a4bf543f58600ae8499f5b219a452f89c827#2009-05-19 04:45:07#-1#4.0#4.0#18.0#18.0#63.0#63.0#5.0#5.0#1.0#1.0#// FIXME Error dialog#cab0a4bf543f58600ae8499f5b219a452f89c827#HADOOP-4687 split the contrib dirs#aa471150ea99d81102939e17fdbc251bd1218b44#Move eclipse-plugin from common to mapreduce
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/rawcoder/TestJRSRawCoder.java#findLaunchConfiguration(IType,ILaunchConfigurationType)#dae27f6dd14ac3ed0b9821a3c5239569b13f6adf#2015-02-12 21:12:44#efdc0070d880c7e1b778e0029a1b827ca962ce70#2016-02-24 14:29:03#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// FIXME Error dialog#dae27f6dd14ac3ed0b9821a3c5239569b13f6adf#HADOOP-11542. Raw Reed-Solomon coder in pure Java. Contributed by Kai Zheng##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java#getExistingPathINodes(byte[][],int,boolean)#9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#2013-04-13 02:48:34#6bda1f20ad396918edde211f709f5819a361b51e#2013-04-16 22:03:58#-1#14.0#14.0#36.0#36.0#113.0#113.0#21.0#21.0#5.0#5.0#// no snapshot in dst tree of rename // the above scenario #9c6a7bebe23ffb85d7fd95607f3b7bb4fe82dbe4#HDFS-4675. Fix rename across snapshottable directories.  Contributed by Jing Zhao#9280468b1acfa346250d0212b5cb7486dc83705c#HDFS-4550. Refactor INodeDirectory.INodesInPath to a standalone class.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.java#destroyAndCollectBlocks(BlocksMapUpdateInfo)#43bdc22e9207a74678665de5f109dd7e56fe979a#2013-04-22 22:13:58#43bdc22e9207a74678665de5f109dd7e56fe979a#2013-04-22 22:13:58#-1#3.0#3.0#3.0#3.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO: Need to update the cleanSubtree/destroy methods to clean inode map#43bdc22e9207a74678665de5f109dd7e56fe979a#HDFS-4726. Fix test failures after merging the INodeId-INode mapping from trunk.  Contributed by Jing Zhao#92e0416ced279a910616985bf11fa3f8b1b1de9b#HDFS-4727. Update inodeMap after deleting files/directories/snapshots.  Contributed by Jing Zhao
hadoop#DESIGN#mapreduce/src/java/org/apache/hadoop/mapred/TaskLog.java#buildCommandLine(List<String>,List<String>,File,File,long,boolean)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#2440671a117f165dcda5056404bc898df3c50803#2016-02-18 14:15:08#-1#11.0#10.0#6.0#6.0#53.0#53.0#6.0#6.0#1.0#1.0#// Export the pid of taskJvm to env variable JVM_PID. // Currently pid is not used on Windows#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java#recordModification(Snapshot)#bb80f2fb29d6f58d9c35f4a1fd88c99517f43e16#2013-01-24 21:33:34#e7db60fbfcc222b32d610ffd912683494674ad2f#2013-02-02 01:53:17#-1#3.0#4.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#//TODO: change it to use diff list#bb80f2fb29d6f58d9c35f4a1fd88c99517f43e16#HDFS-4436. Change INode.recordModification(..) to return only the current inode and remove the updateCircularList parameter from some methods in INodeDirectoryWithSnapshot.Diff.#4f7d921324c7fa9623c34688e3f2aa57fbfcb8b3#HDFS-4446. Support file snapshots with diff lists.
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRWithDFS.java#checkTaskDirectories(MiniMRCluster,String,String[],String[])#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#12.0#12.0#15.0#15.0#57.0#57.0#6.0#6.0#4.0#4.0#// All taskDirs should be present in the observed list. Other files like // job.xml etc may be present too, we are not checking them here.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java#resolve(INodeDirectory,byte[][],int,boolean)#9280468b1acfa346250d0212b5cb7486dc83705c#2013-04-17 02:41:38#9f4bf3bdf9e74800643477cfb18361e01cf6859c#2016-01-11 11:31:59#-1#12.0#-1#36.0#-1#112.0#-1#20.0#-1#5.0#-1#// no snapshot in dst tree of rename // the above scenario #9280468b1acfa346250d0212b5cb7486dc83705c#HDFS-4550. Refactor INodeDirectory.INodesInPath to a standalone class.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/util/CgroupsLCEResourcesHandler.java#setupLimits(ContainerId,Resource)#5032a694ed250f65ade8c2b62c97b89ab45f53ea#2012-12-18 22:58:32#27d4592771ddbeb793bf148c0efb951e640b7b19#2013-04-29 23:09:28#-1#4.0#4.0#5.0#5.0#10.0#10.0#2.0#2.0#1.0#1.0#/*hadoop,   * TODO: After YARN-2 is committed, we should call containerResource.getCpus()hadoop,   * (or equivalent) to multiply the weight by the number of requested cpus.hadoop,   */#5032a694ed250f65ade8c2b62c97b89ab45f53ea#YARN-3. Add support for CPU isolation/monitoring of containers. (adferguson via tucu)#80eb92aff02cc9f899a6897e9cbc2bc69bd56136#YARN-600. Hook up cgroups CPU settings to the number of virtual cores allocated. (sandyr via tucu)
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/util/CgroupsLCEResourcesHandler.java#clearLimits(ContainerId)#5032a694ed250f65ade8c2b62c97b89ab45f53ea#2012-12-18 22:58:32#2085e60a9655b59aa2ba8917acdc511ab71ff6e4#2016-01-25 16:19:03#-1#3.0#3.0#5.0#4.0#18.0#5.0#4.0#2.0#2.0#1.0#// Based on testing, ApplicationMaster executables don't terminate until // a little after the container appears to have finished. Therefore, we // wait a short bit for the cgroup to become empty before deleting it.#5032a694ed250f65ade8c2b62c97b89ab45f53ea#YARN-3. Add support for CPU isolation/monitoring of containers. (adferguson via tucu)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java#addApplication(ApplicationAttemptId,String,String)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#fa7a43529d529f0006c8033c2003f15b9b93f103#2016-03-16 17:02:10#-1#9.0#-1#12.0#-1#45.0#-1#4.0#-1#1.0#-1#// TODO: Fix store#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#src/test/core/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsByteArrays.java#setUp()#8246aa28ff72e3ae81eb6ce59852abd5828fadc6#2009-06-24 05:48:25#85623a2d75c5f8855228f1c3cc46b4d5087f5833#2013-05-30 22:43:16#-1#2.0#2.0#6.0#6.0#12.0#11.0#3.0#3.0#1.0#1.0#// TODO: sample the generated key/value records, and put the numbers below#8246aa28ff72e3ae81eb6ce59852abd5828fadc6#HADOOP-3315. Add a new, binary file foramt, TFile. Contributed by Hong Tang.##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/JobBuilder.java#process(Properties)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#4efdf3a979c361348612f817a3253be6d0de58f7#2016-01-26 18:17:12#-1#9.0#9.0#9.0#9.0#21.0#25.0#2.0#3.0#1.0#1.0#//TODO remove this once the deprecate APIs in LoggedJob are removed#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/JobBuilder.java#processReduceAttemptFinishedEvent(ReduceAttemptFinishedEvent)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#4efdf3a979c361348612f817a3253be6d0de58f7#2016-01-26 18:17:12#-1#2.0#2.0#19.0#27.0#19.0#27.0#2.0#3.0#1.0#1.0#// XXX There may be redundant location info available in the event. // We might consider extracting it from this event. Currently this // is redundant, but making this will add future-proofing.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ipc/RPCUtil.java#unwrapAndThrowException(ServiceException)#2638bc67a48f923404d57ed2026c4997df6bd06e#2013-05-10 21:49:28#2638bc67a48f923404d57ed2026c4997df6bd06e#2013-05-10 21:49:28#-1#44.0#44.0#11.0#11.0#34.0#34.0#7.0#7.0#3.0#3.0#// TODO Fix in YARN-628.#2638bc67a48f923404d57ed2026c4997df6bd06e#YARN-634. Modified YarnRemoteException to be not backed by PB and introduced a separate SerializedException record. Contributed by Siddharth Seth. MAPREDUCE-5239. Updated MR App to reflect YarnRemoteException changes after YARN-634. Contributed by Siddharth Seth.#065747efabd1cbea9b14e93e905e304b9973d355#YARN-628. Fix the way YarnRemoteException is being unrolled to extract out the underlying exception. Contributed by Siddharth Seth.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogDeletionService.java#logIOException(String,IOException)#7fc6ad661d4723cc2ea1df1ff0c4611d5f534f9e#2012-08-17 20:29:38#cb81bac0029fce3a9726df3523f0b692cd3375b8#2014-10-10 00:10:39#-1#6.0#6.0#4.0#4.0#10.0#10.0#2.0#2.0#1.0#1.0#//TODO fix this after HADOOP-8661#7fc6ad661d4723cc2ea1df1ff0c4611d5f534f9e#YARN-25. remove old aggregated logs  (Robert Evans via tgraves)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/records/impl/pb/ContainerFinishDataPBImpl.java#logIOException(String,IOException)#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#8314674947ec087899d2515ae6b668c6c39cabbd#2014-03-17 21:36:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//TODO fix this after HADOOP-8661#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java#getApplicationAcls()#670fa24b48acb407c22fbfdde87ae3123dcbf449#2011-10-28 06:45:04#688617d6d7e6377a37682b5676b805cc6e8cf3f0#2015-07-04 21:51:58#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Seek directly to the key once a comparator is specified.#670fa24b48acb407c22fbfdde87ae3123dcbf449#MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/records/impl/pb/ContainerStartDataPBImpl.java#getApplicationAcls()#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#cbee889711eddc5c67a61df4a6531b4ab3cd205a#2014-01-26 04:51:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO Seek directly to the key once a comparator is specified.#cbee889711eddc5c67a61df4a6531b4ab3cd205a#YARN-321. Merging YARN-321 branch to trunk. svn merge ../branches/YARN-321##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/LogAggregationUtils.java#getRemoteLogSuffixedDir(Path,String,String)#c27601fefebd0af887a12d684bfc6f90d9fc0321#2011-11-03 08:02:19#e90718fa5a0e7c18592af61534668acebb9db51b#2014-10-20 13:38:59#-1#5.0#5.0#4.0#4.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO Maybe support suffix to be more than a single file.#c27601fefebd0af887a12d684bfc6f90d9fc0321#MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java#createContainer(SchedulerApp,SchedulerNode,Resource,Priority)#126dd6adefeb00e4ba81ea137d63a8a76b75c3bd#2012-06-21 18:14:22#126dd6adefeb00e4ba81ea137d63a8a76b75c3bd#2012-06-21 18:14:22#-1#8.0#8.0#15.0#15.0#31.0#31.0#3.0#3.0#2.0#2.0#// this could be because DNS is down - in which case we just want // to retry and not bring RM down#126dd6adefeb00e4ba81ea137d63a8a76b75c3bd#MAPREDUCE-4295. RM crashes due to DNS issue (tgraves)#3bfb26ad3b5ac46f992a632541c97ca2bc897638#MAPREDUCE-3940. ContainerTokens should have an expiry interval. Contributed by Siddharth Seth and Vinod Kumar Vavilapalli.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java#setDelegationToken(Textends,Token<T>)#32cad9affe159ff7c6e4c7e31f57174967ef210a#2011-10-31 20:37:16#6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8#2011-11-03 22:34:47#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// no need to change service because we aren't exactly sure what it // should be.  we can guess, but it might be wrong if the local conf // value is incorrect.  the service is a client side field, so the remote // end does not care about the value#32cad9affe159ff7c6e4c7e31f57174967ef210a#HDFS-2385. Support renew and cancel delegation tokens in webhdfs.#a590b498acf1a424ffbb3a9d8849c0abb409366d#HDFS-2528. Webhdfs: set delegation kind to WEBHDFS and add a HDFS token when http requests are redirected to datanode.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Shuffle.java#run()#895029b2f2535f1ba8275be29fda16d0f80be790#2012-10-25 01:26:30#0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4#2013-08-06 06:36:21#-1#20.0#20.0#19.0#20.0#70.0#78.0#7.0#9.0#2.0#2.0#// Scale the maximum events we fetch per RPC call to mitigate OOM issues // on the ApplicationMaster when a thundering herd of reducers fetch events // TODO: This should not be necessary after HADOOP-8942#895029b2f2535f1ba8275be29fda16d0f80be790#MAPREDUCE-4730. Fix Reducer's EventFetcher to scale the map-completion requests slowly to avoid HADOOP-8942. Contributed by Jason Lowe.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/SimpleEntityWriterV1.java#run()#58590fef49bf45fc97c81277560e08da6b753f95#2015-10-16 16:53:20#58590fef49bf45fc97c81277560e08da6b753f95#2015-10-16 16:53:20#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Scale the maximum events we fetch per RPC call to mitigate OOM issues // on the ApplicationMaster when a thundering herd of reducers fetch events // TODO: This should not be necessary after HADOOP-8942#58590fef49bf45fc97c81277560e08da6b753f95#YARN-2556. Tool to measure the performance of the timeline server (Chang Li via sjlee)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java#verifyLeafQueueGeneric(String,LeafQueueInfo)#0086014703db5f1299143103e92093c4e8cf92d7#2012-01-12 00:15:35#ca8106d2dd03458944303d93679daa03b1d82ad5#2016-03-17 09:04:41#-1#15.0#13.0#5.0#4.0#31.0#27.0#1.0#1.0#0.0#0.0#// TODO: would like to use integer comparisons here but can't due to //       roundoff errors in absolute capacity calculations#0086014703db5f1299143103e92093c4e8cf92d7#MAPREDUCE-3625. CapacityScheduler web-ui display of queue's used capacity is broken. (Jason Lowe via mahadev)##
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDistributedFileSystem.java#testDFSClient()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd8b6889a74a949e37f4b2eb664cdf3b59bfb93b#2016-03-19 14:02:04#-1#3.0#4.0#27.0#30.0#150.0#159.0#8.0#8.0#3.0#3.0#// This is the proper exception to catch; move on.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRespectsBindHostKeys.java#testDFSClient()#730e0675da80642c05c79c52ba345555f2cfba43#2014-04-24 18:04:45#bf8e45298218f70e38838152f69c7705d8606bd6#2015-10-27 23:07:14#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// This is the proper exception to catch; move on.#730e0675da80642c05c79c52ba345555f2cfba43#HDFS-6273. Add file missed in previous checkin.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/oauth2/AccessTokenProvider.java#testDFSClient()#837fb75e8e03b2f016bcea2f4605106a5022491c#2015-08-29 18:37:05#7136e8c5582dc4061b566cb9f11a0d6a6d08bb93#2015-10-03 11:06:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// This is the proper exception to catch; move on.#837fb75e8e03b2f016bcea2f4605106a5022491c#HDFS-8155. Support OAuth2 in WebHDFS.##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java#fsck()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#e01c6ea688e62f25c4310e771a0cd85b53a5fb87#2016-03-10 19:03:55#-1#15.0#23.0#17.0#32.0#52.0#109.0#5.0#15.0#3.0#4.0#// DFSck client scans for the string HEALTHY/CORRUPT to check the status // of file system and return appropriate code. Changing the output // string might break testcases. Also note this must be the last line  // of the report.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java#lostFoundMove(String,HdfsFileStatus,LocatedBlocks)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#f2f4e9341387199e04679ebc8de5e05c0fdbd437#2011-12-13 18:07:29#-1#12.0#12.0#19.0#20.0#66.0#67.0#12.0#12.0#5.0#5.0#// perhaps we should bail out here... // return;#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#4feef863721ba88c9cbf4557502e2082dfca7c40#HDFS-3044. fsck move should be non-destructive by default. Contributed by Colin Patrick McCabe
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java#copyBlock(DFSClient,LocatedBlock,OutputStream)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#e01c6ea688e62f25c4310e771a0cd85b53a5fb87#2016-03-10 19:03:55#-1#11.0#11.0#24.0#40.0#76.0#95.0#14.0#10.0#4.0#2.0#/*hadoop,   * XXX (ab) Bulk of this method is copied verbatim from {@link DFSClient}, which ishadoop,   * bad. Both places should be refactored to provide a method to copy blockshadoop,   * around.hadoop,   */#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/webapp/ContainerLogsPage.java#render(Block)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#397c261433fdc3748050905f748d4fc7f5474b46#2012-11-14 19:22:11#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: Use secure IO Utils to avoid symlink attacks. //TODO Fix findBugs close warning along with IOUtils change#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#5420f287ccc83df69b6725942754c82b89e46b3e#YARN-578. Fixed NM to use SecureIOUtils for reading and aggregating logs. Contributed by Omkar Vinit Joshi.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/contrib/bkjournal/src/main/java/org/apache/hadoop/contrib/bkjournal/BookKeeperJournalManager.java#selectInputStreams(Collection<EditLogInputStream>,long,boolean)#74dfa8f1f22d58df64a78c660af111e17ab7053e#2012-05-23 20:42:48#8a2de213158ee3b673d7201bd797e38063027b7e#2012-11-15 18:25:55#-1#6.0#6.0#4.0#4.0#21.0#21.0#5.0#5.0#2.0#2.0#// NOTE: could probably be rewritten more efficiently#74dfa8f1f22d58df64a78c660af111e17ab7053e#HDFS-2982. Startup performance suffers when there are many edit log segments. Contributed by Colin Patrick McCabe.#103eff1fad9dc947c5c078f829044cff2da6139b#HDFS-4130. BKJM: The reading for editlog at NN starting using bkjm is not efficient. Contributed by Han Xiao.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/contrib/bkjournal/src/main/java/org/apache/hadoop/contrib/bkjournal/BookKeeperJournalManager.java#format(NamespaceInfo)#9d0f8792a9a1d3d2b24adfc2c213247a099e7ad1#2012-08-09 22:13:54#6fd7df77a5d935192048855fc5c7a1173e34e3d2#2012-09-06 18:03:16#-1#1.0#1.0#1.0#1.0#8.0#8.0#1.0#1.0#0.0#0.0#// Currently, BKJM automatically formats itself when first accessed. // TODO: change over to explicit formatting so that the admin can // clear out the BK storage when reformatting a cluster.#9d0f8792a9a1d3d2b24adfc2c213247a099e7ad1#HDFS-3695. Genericize format() to non-file JournalManagers. Contributed by Todd Lipcon.#f1fe91ec9519535153f05acd3e6402bdb8e12c56#HDFS-3810. Implement format() for BKJM. Contributed by Ivan Kelly.
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/webapp/NavBlock.java#render(Block)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#bad070fe15a642cc6f3a165612fbd272187e03cb#2015-04-02 17:23:20#-1#1.0#3.0#7.0#13.0#17.0#39.0#1.0#4.0#0.0#2.0#// TODO: Problem if no header like this#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeResourcePolicy.java#areResourcesAvailable(Collection<?extendsCheckableNameNodeResource>,int)#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#74d4573a23db5586c6e47ff2277aa7c35237da34#2012-07-20 00:25:50#-1#6.0#6.0#4.0#4.0#39.0#39.0#7.0#7.0#3.0#3.0#// TODO: workaround: // - during startup, if there are no edits dirs on disk, then there is // a call to areResourcesAvailable() with no dirs at all, which was // previously causing the NN to enter safemode#74d4573a23db5586c6e47ff2277aa7c35237da34#HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingZones.java#areResourcesAvailable(Collection<?extendsCheckableNameNodeResource>,int)#1af8c148626effe1b41fc536019fd3349f485d59#2015-04-02 22:38:29#7600e3c48ff2043654dbe9f415a186a336b5ea6c#2016-03-08 22:30:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: workaround: // - during startup, if there are no edits dirs on disk, then there is // a call to areResourcesAvailable() with no dirs at all, which was // previously causing the NN to enter safemode#1af8c148626effe1b41fc536019fd3349f485d59#HDFS-7839. Erasure coding: implement facilities in NameNode to create and manage EC zones. Contributed by Zhe Zhang##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNestedEncryptionZones.java#areResourcesAvailable(Collection<?extendsCheckableNameNodeResource>,int)#dbe49c1bd6f62f04cf4290795b81a66fbd41d44c#2016-02-08 16:30:51#dbe49c1bd6f62f04cf4290795b81a66fbd41d44c#2016-02-08 16:30:51#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: workaround: // - during startup, if there are no edits dirs on disk, then there is // a call to areResourcesAvailable() with no dirs at all, which was // previously causing the NN to enter safemode#dbe49c1bd6f62f04cf4290795b81a66fbd41d44c#HDFS-9244. Support nested encryption zones.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/oauth2/OAuth2Constants.java#areResourcesAvailable(Collection<?extendsCheckableNameNodeResource>,int)#837fb75e8e03b2f016bcea2f4605106a5022491c#2015-08-29 18:37:05#7136e8c5582dc4061b566cb9f11a0d6a6d08bb93#2015-10-03 11:06:21#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: workaround: // - during startup, if there are no edits dirs on disk, then there is // a call to areResourcesAvailable() with no dirs at all, which was // previously causing the NN to enter safemode#837fb75e8e03b2f016bcea2f4605106a5022491c#HDFS-8155. Support OAuth2 in WebHDFS.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/webapp/NMController.java#index()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#6329bd00fa1f17cc9555efa496ea7607ad93e0ce#2015-05-20 17:20:21#-1#1.0#1.0#3.0#3.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: What use of this with info() in?#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/allocator/ContainerAllocator.java#index()#ba2313d6145a1234777938a747187373f4cd58d9#2015-08-05 13:45:17#fa7a43529d529f0006c8033c2003f15b9b93f103#2016-03-16 17:02:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: What use of this with info() in?#ba2313d6145a1234777938a747187373f4cd58d9#YARN-3983. Refactored CapacityScheduleriFiCaSchedulerApp to easier extend container allocation logic. Contributed by Wangda Tan##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java#errorReport(NamenodeRegistration,int,String)#36d1c49486587c2dbb193e8538b1d4510c462fa6#2011-12-21 03:03:23#7933dc583838fa7273cf55c03400a591a41d23db#2012-02-17 07:37:43#-1#6.0#6.0#3.0#3.0#11.0#11.0#2.0#2.0#1.0#1.0#// nn.checkOperation(OperationCategory.WRITE); // TODO: I dont think this should be checked - it's just for logging // and dropping backups#36d1c49486587c2dbb193e8538b1d4510c462fa6#HDFS-2693. Fix synchronization issues around state transition. Contributed by Todd Lipcon.#475db83b874f5808811d6f2d5be425a6bd14bca5#HDFS-2985. Improve logging when replicas are marked as corrupt. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java#setSafeMode(SafeModeAction)#a63e12c4c8b6d637eb6ab04f84de183e8d34bb00#2012-02-09 22:33:20#8af96c7b22f92ab84c142c37252f85df7b9b98aa#2012-02-10 00:46:17#-1#2.0#2.0#2.0#2.0#4.0#5.0#1.0#1.0#0.0#0.0#// NB: not checking OperationCategory so this works on a standby#a63e12c4c8b6d637eb6ab04f84de183e8d34bb00#HDFS-2922. HA: close out operation categories. Contributed by Eli Collins#a626fa04f983623b1e2c00189df6f0b83b806b5f#Revert HDFS-2922 via svn merge -c -1242572
hadoop#DESIGN#hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapreduce/TestTaskContext.java#testContextStatus()#5f7e9916590012f3102d2bfe3012115a9f5b1c3c#2011-11-01 00:57:22#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#4.0#3.0#16.0#16.0#50.0#50.0#1.0#1.0#0.0#0.0#// check map task reports // TODO fix testcase  // Disabling checks for now to get builds to run#5f7e9916590012f3102d2bfe3012115a9f5b1c3c#MAPREDUCE-3321. Disabled a few MR tests for 0.23. Contributed by Hitesh Shah.##
hadoop#DESIGN#hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java#testContextStatus()#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#2014-06-10 22:26:45#3369a4f6916f12e9d6b97072badd1b176be443bd#2016-02-23 21:37:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// check map task reports // TODO fix testcase  // Disabling checks for now to get builds to run#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.##
hadoop#DESIGN#hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestSaveNamespace.java#saveNamespaceWithInjectedFault(Fault)#28e6a4e44a3e920dcaf858f9a74a6358226b3a63#2011-07-29 16:28:45#ec25c7f9c7e60c077d8c4143253c20445fcdaecf#2016-01-27 16:34:40#-1#18.0#16.0#26.0#25.0#93.0#99.0#10.0#10.0#3.0#3.0#// TODO: unfortunately this fails -- should be improved. // See HDFS-2173.#28e6a4e44a3e920dcaf858f9a74a6358226b3a63#HDFS-1073. Redesign the NameNode's storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java#write(DataOutput)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#f2b91a8367a762091482074505618b570a520b19#2011-08-25 06:35:58#-1#5.0#5.0#7.0#9.0#8.0#9.0#1.0#1.0#0.0#0.0#// TODO: more resources.#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1#MAPREDUCE-2896. Simplify all apis to in org.apache.hadoop.yarn.api.records.* to be get/set only. Added javadocs to all public records.
hadoop#DESIGN#hdfs/src/java/org/apache/hadoop/hdfs/DFSUtil.java#createClientDatanodeProtocolProxy(DatanodeID,Configuration,int,LocatedBlock)#710e5a960e8af1d4c73e386041096aacfee8b828#2011-07-19 14:23:50#180646dea33785f8b4cc71482d099595b8c7da9d#2011-10-27 23:15:07#-1#10.0#11.0#16.0#16.0#28.0#28.0#2.0#2.0#1.0#1.0#// Since we're creating a new UserGroupInformation here, we know that no // future RPC proxies will be able to re-use the same connection. And // usages of this proxy tend to be one-off calls. // // This is a temporary fix: callers should really achieve this by using // RPC.stopProxy() on the resulting object, but this is currently not // working in trunk. See the discussion on HDFS-1965.#710e5a960e8af1d4c73e386041096aacfee8b828#HDFS-2161. Move createNamenode(..), createClientDatanodeProtocolProxy(..) and Random object creation to DFSUtil; move DFSClient.stringifyToken(..) to DelegationTokenIdentifier.#32cad9affe159ff7c6e4c7e31f57174967ef210a#HDFS-2385. Support renew and cancel delegation tokens in webhdfs.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java#getFailoverProxyProviderClass(T,Configuration,URI,Class<T>)#212678f036f4f96493bc14a584e758f97cf65573#2012-01-17 03:10:25#481f84597bf842df45b068cc24c328112e8bcf40#2012-02-25 00:03:26#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// If we found a proxy provider, then this URI should be a logical NN. // Given that, it shouldn't have a non-default port number.#212678f036f4f96493bc14a584e758f97cf65573#HDFS-2767. ConfiguredFailoverProxyProvider should support NameNodeProtocol. Contributed by Uma Maheswara Rao G.#c69dfdd5e14af490790dff8227b11962ec816577#HDFS-2958. Sweep for remaining proxy construction which doesn't go through failover path.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java#getFailoverProxyProviderClass(T,Configuration,URI,Class<T>)#c69dfdd5e14af490790dff8227b11962ec816577#2012-02-28 20:09:18#63d9f1596c92206cce3b72e3214d2fb5f6242b90#2015-09-22 20:52:37#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// If we found a proxy provider, then this URI should be a logical NN. // Given that, it shouldn't have a non-default port number.#c69dfdd5e14af490790dff8227b11962ec816577#HDFS-2958. Sweep for remaining proxy construction which doesn't go through failover path.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SerialNumberMap.java#getFailoverProxyProviderClass(T,Configuration,URI,Class<T>)#eee0d4563c62647cfaaed6605ee713aaf69add78#2015-08-25 16:16:09#eee0d4563c62647cfaaed6605ee713aaf69add78#2015-08-25 16:16:09#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// If we found a proxy provider, then this URI should be a logical NN. // Given that, it shouldn't have a non-default port number.#eee0d4563c62647cfaaed6605ee713aaf69add78#HDFS-8900. Compact XAttrs to optimize memory footprint. (yliu)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/MRApp.java#submit(Configuration)#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#d40859fab1ad977636457a6cc96b6a4f9b903afc#2016-01-18 10:58:14#-1#27.0#72.0#14.0#2.0#17.0#5.0#1.0#1.0#0.0#0.0#//TODO: fix the bug where the speculator gets events with  //not-fully-constructed objects. For now, disable speculative exec#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#src/test/org/apache/hadoop/fs/TestTruncatedInputBug.java#testTruncatedInputBug()#abe7be913432053f6d419ea4ca4f9cd2be938bc7#2009-05-19 04:35:56#abe7be913432053f6d419ea4ca4f9cd2be938bc7#2009-05-19 04:35:56#-1#1.0#1.0#16.0#16.0#57.0#57.0#6.0#6.0#3.0#3.0#// Now set mark() to trigger the bug // NOTE: in the fixed code, mark() does nothing (not supported) and //   hence won't trigger this bug.#abe7be913432053f6d419ea4ca4f9cd2be938bc7#HADOOP-4687 Moving directories around#7e7fd2ce5b754c6398f8a326e5172d1e1b57c8e6#fixed test test-core and test-contrib targets
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/db/TestTextSplitter.java#testCommonPrefix()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#0050fa5f1c20087009bd76a0bb2183a479f787f0#2016-03-29 18:17:52#-1#0.0#0.0#4.0#4.0#11.0#11.0#1.0#1.0#0.0#0.0#// Don't check for exact values in the middle, because the splitter generates some // ugly Unicode-isms. But do check that we get multiple splits and that it starts // and ends on the correct points.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-mapreduce/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestLinuxContainerExecutor.java#testCommandFilePreparation()#dbecbe5dfe50f834fc3b8401709079e9470cc517#2011-08-18 11:07:10#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#0.0#0.0#0.0#0.0#12.0#12.0#1.0#1.0#0.0#0.0#//    LinuxContainerExecutor executor = new LinuxContainerExecutor(new String[] { //        "/bin/echo", "hello" }, null, null, "nobody"); // TODO: fix user name //    executor.prepareCommandFile(workSpace.getAbsolutePath()); // //    // Now verify the contents of the commandFile //    File commandFile = new File(workSpace, LinuxContainerExecutor.COMMAND_FILE); //    BufferedReader reader = new BufferedReader(new FileReader(commandFile)); //    Assert.assertEquals("/bin/echo hello", reader.readLine()); //    Assert.assertEquals(null, reader.readLine()); //    Assert.assertTrue(commandFile.canExecute());#dbecbe5dfe50f834fc3b8401709079e9470cc517#MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.#a8190ce5c520fcb69399485231ef7c0b7fdc3df7#MAPREDUCE-2988. Reenabled TestLinuxContainerExecutor reflecting the current NodeManager code. Contributed by Robert Joseph Evans.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.java#setConf(Configuration)#9146ad23f3f1af7c5547fba08e2a867cee49e015#2011-11-29 02:27:45#212678f036f4f96493bc14a584e758f97cf65573#2012-01-17 03:10:25#-1#3.0#10.0#8.0#11.0#19.0#32.0#3.0#3.0#2.0#2.0#// TODO(HA): currently hardcoding the nameservice used by MiniDFSCluster. // We need to somehow communicate this into the proxy provider.#9146ad23f3f1af7c5547fba08e2a867cee49e015#HDFS-2582. Scope dfs.ha.namenodes config by nameservice. Contributed by Todd Lipcon.#02919e61f6935813bc3dbe23cc89e00e0cb02918#HDFS-2367. Enable the configuration of multiple HA cluster addresses. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestSaslRPC.java#testSecureClientSecureServer()#22ef03bc7677d6718902a7587bbd26ab750f8d78#2012-10-12 16:27:26#8303175db8e5b78ddb09005654cf1bc1a2d82037#2012-11-05 18:26:49#-1#1.0#1.0#4.0#4.0#16.0#16.0#2.0#2.0#1.0#1.0#/* Should be this when multiple secure auths are supported and we canhadoop,     * dummy one out:hadoop,     *     assertEquals(AuthenticationMethod.SECURE_AUTH_METHOD,hadoop,     *                  getAuthMethod(true, true, false));hadoop,     */#22ef03bc7677d6718902a7587bbd26ab750f8d78#HADOOP-8784. Improve IPC.Client's token use (daryn)#5605b54010b67785085192629d9a191e0c79bd90#HADOOP-9012. IPC Client sends wrong connection context (daryn via bobby)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/EditLogTailer.java#run()#f87a4b40bc99e76602a75906df31747cfdbff78a#2011-11-30 21:46:22#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#2012-01-05 00:22:54#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO(HA): What should we do in this case? Shutdown the standby NN?#f87a4b40bc99e76602a75906df31747cfdbff78a#HDFS-1975. Support for sharing the namenode state from active to standby. Contributed by Jitendra Nath Pandey, Aaron T Myers, and Todd Lipcon.#9a07ba8945407cd8f63169faf9e0faa4311d38c7#HDFS-2709. Appropriately handle error conditions in EditLogTailer. Contributed by Aaron T. Myers.
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeManagerResync.java#run()#635f96e74e7b988b320770c71022f38f55806090#2013-04-26 04:42:34#a83fb61ac07c0468cbc7a38526e92683883dd932#2013-06-04 04:05:50#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TO DO: This should be replaced to explicitly check exception // class name after YARN-142#635f96e74e7b988b320770c71022f38f55806090#YARN-562. Missed files from previous commit.#c6c41abf683be17c3917a7f94953b55347aaa69f#YARN-737. Throw some specific exceptions directly instead of wrapping them in YarnException. Contributed by Jian He.
hadoop#DESIGN#mapreduce/src/test/unit/org/apache/hadoop/mapred/TestLostTaskTracker.java#testLostTaskTrackerCalledAfterExpiryTime()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#2.0#3.0#13.0#13.0#37.0#37.0#1.0#1.0#0.0#0.0#// Wait long enough for tracker1 to be considered lost // We could have used a Mockito stub here, except we don't know how many  // times JobTracker calls getTime() on the clock, so a static mock // is appropriate.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)#ca1c683b4755958b30af7b6d8dc8c5b9fa55c60b#MAPREDUCE-4266. remove Ant remnants from MR (tgraves via bobby)
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestRecovery.java#testCrashed()#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#2011-10-19 05:21:18#d40859fab1ad977636457a6cc96b6a4f9b903afc#2016-01-18 10:58:14#-1#14.0#20.0#43.0#46.0#156.0#191.0#4.0#5.0#1.0#1.0#// TODO Add verification of additional data from jobHistory - whatever was // available in the failed attempt should be available here#13e4562924a6cb3d16c262e0f595b2ffbf9e0546#MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/MiniYARNCluster.java#stop()#638801cce16fc1dc3259c541dc30a599faaddda1#2013-03-06 19:15:18#55ae1439233e8585d624b2872e1e4753ef63eebb#2016-03-27 20:22:12#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// On Windows, clean up the short temporary symlink that was created to // work around path length limitation.#638801cce16fc1dc3259c541dc30a599faaddda1#HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.##
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLease.java#testLeaseAfterRename()#88eea2157275d4c7e1bf70cac98fe52c326f3585#2012-12-01 22:29:54#692b1a45ce46a76586c9c375854940454eeca306#2015-09-24 20:19:16#-1#3.0#3.0#23.0#24.0#88.0#89.0#1.0#1.0#1.0#1.0#// rename with opts to existing dir // NOTE: rename with options will not move paths into the existing dir#88eea2157275d4c7e1bf70cac98fe52c326f3585#HDFS-4248. Renaming directories may incorrectly remove the paths in leases under the tree.  Contributed by daryn##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/TestNodeStatusUpdater.java#registerNodeManager(RegisterNodeManagerRequest)#48414b08277b86cdbc34ae36d7c4d204fd838294#2012-05-03 18:35:21#d284e187b8db43056236032ebc2114ee462c27f6#2016-02-23 20:49:09#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// NOTE: this really should be checking against the config value#48414b08277b86cdbc34ae36d7c4d204fd838294#MAPREDUCE-4163. consistently set the bind address (Daryn Sharp via bobby)##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSQueueSchedulable.java#getQueueInfo(boolean,boolean)#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#2012-07-13 00:43:01#933a6d2c1ec8d3b373674e3e74eb472863fc464d#2012-11-09 12:38:10#-1#5.0#5.0#11.0#11.0#14.0#14.0#1.0#1.0#0.0#0.0#// TODO: we might change these queue metrics around a little bit // to match the semantics of the fair scheduler.#1ef64e64c05ae5318cd4cb47d03a0494d742fb7c#MAPREDUCE-3451. Port Fair Scheduler to MR2 (pwendell via tucu)#ae6f1123f57c09a9cf5eed3e8c4659481417dc21#YARN-187. Add hierarchical queues to the fair scheduler. Contributed by Sandy Ryza.
hadoop#DESIGN#mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/input/TestMultipleInputs.java#getDir(Path)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#247a7906092065289ea81139e71badcac6abef1e#2016-03-11 22:51:20#-1#3.0#3.0#5.0#5.0#9.0#9.0#2.0#2.0#1.0#1.0#// Hack for local FS that does not have the concept of a 'mounting point'#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/NativeAzureFileSystemBaseTest.java#getDir(Path)#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#2014-06-10 22:26:45#91a96eaa534dbb27e81b6c24bbb8138200a80a83#2016-02-12 15:50:10#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Hack for local FS that does not have the concept of a 'mounting point'#81bc395deb3ba00567dc067d6ca71bacf9e3bc82#HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.##
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java#submitAndRegisterApplication(ResourceManager,YarnRPC,ApplicationId)#7f4dc277572df6ba25fa961073b99a5bdb086c00#2011-10-29 09:35:36#40062e1aaa09628c6f45d20298fd66d799fd1f3f#2012-09-27 03:43:57#-1#15.0#13.0#51.0#50.0#95.0#93.0#6.0#6.0#0.0#0.0#// TODO: Use a resource to work around bugs. Today NM doesn't create local // app-dirs if there are no file to download!!#7f4dc277572df6ba25fa961073b99a5bdb086c00#MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.#9385dd50c7f21dae40f0c341e2ca89246604e41a#YARN-253. Fixed container-launch to not fail when there are no local resources to localize. Contributed by Tom White.
hadoop#DESIGN#hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestContainerManagerSecurity.java#submitAndRegisterApplication(ResourceManager,YarnRPC,ApplicationId)#7f4dc277572df6ba25fa961073b99a5bdb086c00#2011-10-29 09:35:36#db3e592df0cd022d15a6acdeac3517c54d510ad2#2012-03-29 02:02:17#-1#15.0#15.0#51.0#51.0#95.0#95.0#6.0#6.0#0.0#0.0#// TODO: FIX. Be in Sync with // ResourceManager.java#7f4dc277572df6ba25fa961073b99a5bdb086c00#MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.#fe7711df98b9dd16259f6534e8461a29f24caadc#MAPREDUCE-3942. Randomize master key generation for ApplicationTokenSecretManager and roll it every so often. (Contributed by Vinod Kumar Vavilapalli)
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java#cancelAndPreventCheckpoints()#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#2012-01-05 00:22:54#5e26de982b1ab68fffeb897fef4c97458ad46708#2012-02-09 18:22:02#-1#4.0#4.0#4.0#4.0#12.0#12.0#2.0#2.0#1.0#1.0#// TODO: there is a really narrow race here if we are just // about to start a checkpoint - this won't cancel it!#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.#978a8050e28b2afb193a3e00d82a8475fa4d2428#HDFS-2920. fix remaining TODO items. Contributed by Aaron T. Myers and Todd Lipcon.
hadoop#DESIGN#hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/StandbyCheckpointer.java#run()#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#2012-01-05 00:22:54#32c313d51cd2483ea510afe044c55eeaed7c2b2d#2012-02-02 22:21:57#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// We have to make sure we're logged in as far as JAAS // is concerned, in order to use kerberized SSL properly. // This code copied from SecondaryNameNode - TODO: refactor // to a utility function.#5b8dcb20a2fad2e7e9dee56c451f68f9d865b5ae#HDFS-2291. Allow the StandbyNode to make checkpoints in an HA setup. Contributed by Todd Lipcon.#5e26de982b1ab68fffeb897fef4c97458ad46708#HDFS-2924. Standby checkpointing fails to authenticate in secure cluster. Contributed by Todd Lipcon.
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java#getJobConf()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7b3a98cfcd0eb729b1971b3e5607a1d7755fdb07#2012-03-21 09:42:23#-1#5.0#6.0#19.0#20.0#24.0#24.0#3.0#3.0#2.0#2.0#//TODO Eliminate parameters that are already copied from the job's  // configuration file.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java#getInputSplits()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7b3a98cfcd0eb729b1971b3e5607a1d7755fdb07#2012-03-21 09:42:23#-1#6.0#6.0#20.0#21.0#79.0#79.0#16.0#16.0#5.0#5.0#// TODO set size of a split to 0 now.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java#buildMaps()#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7b3a98cfcd0eb729b1971b3e5607a1d7755fdb07#2012-03-21 09:42:23#-1#6.0#6.0#13.0#11.0#39.0#37.0#10.0#10.0#5.0#5.0#// TODO: do not care about "other" tasks, "setup" or "clean"#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/tools/rumen/ZombieJob.java#getTaskAttemptInfo(TaskType,int,int)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7b3a98cfcd0eb729b1971b3e5607a1d7755fdb07#2012-03-21 09:42:23#-1#4.0#4.0#8.0#8.0#31.0#31.0#4.0#4.0#2.0#2.0#// TODO should we handle killed attempts later?#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSQueue.java#getQueueInfo(boolean,boolean)#ae6f1123f57c09a9cf5eed3e8c4659481417dc21#2012-11-30 12:03:25#fb238d7e5dcd96466c8938b13ca7f13cedecb08a#2016-01-27 11:47:29#-1#7.0#7.0#13.0#16.0#21.0#30.0#3.0#5.0#2.0#2.0#// TODO: we might change these queue metrics around a little bit // to match the semantics of the fair scheduler.#ae6f1123f57c09a9cf5eed3e8c4659481417dc21#YARN-187. Add hierarchical queues to the fair scheduler. Contributed by Sandy Ryza.##
hadoop#DESIGN#hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-tests/src/test/java/org/apache/hadoop/yarn/server/TestMiniYarnCluster.java#getQueueInfo(boolean,boolean)#265ed1fe804743601a8b62cabc1e4dc2ec8e502f#2015-04-08 14:13:10#27414dac66f278b61fc23762204b01a1c508178a#2015-10-28 10:32:16#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: we might change these queue metrics around a little bit // to match the semantics of the fair scheduler.#265ed1fe804743601a8b62cabc1e4dc2ec8e502f#YARN-2890. MiniYarnCluster should turn on timeline service if configured to do so. Contributed by Mit Desai.##
hadoop#DESIGN#src/java/org/apache/hadoop/conf/Configuration.java#iterator()#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#ea6b183a1a649ad2874050ade8856286728c654c#2015-10-27 10:57:45#-1#0.0#5.0#6.0#6.0#14.0#14.0#3.0#3.0#2.0#2.0#// Get a copy of just the string to string pairs. After the old object // methods that allow non-strings to be put into configurations are removed, // we could replace properties with a Map<String,String> and get rid of this // code.#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FileContext.java#fixRelativePart(Path)#0294c49df60150bd9b363af5cfbc312222c12c69#2009-09-17 22:27:15#a90d3205d2a23945eaab8b756cfbeeb4377c3c04#2010-01-16 00:44:40#-1#19.0#20.0#3.0#3.0#7.0#7.0#2.0#2.0#1.0#1.0#/* hadoop,   * Remove relative part - return "absolute":hadoop,   * If input is relative path ("foo/bar") add wd: ie "/<workingDir>/foo/bar"hadoop,   * A fully qualified uri ("hdfs://nn:p/foo/bar") or a slash-relative pathhadoop,   * ("/foo/bar") are returned unchanged.hadoop,   * hadoop,   * Applications that use FileContext should use makeQualified() sincehadoop,   * they really want a fully qualified URI.hadoop,   * Hence this method os not called makeAbsolute() and hadoop,   * has been deliberately declared private.hadoop,   */#0294c49df60150bd9b363af5cfbc312222c12c69#HADOOP-4952. Add new improved file system interface FileContext for the application writer. Contributed by Sanjay Radia.#ea605b8cd79163444feead75d7b55dbd4ab537a0#    HADOOP-6421 Adds Symbolic links to FileContext, AbstractFileSystem.     It also adds a limited implementation for the local file system      (RawLocalFs) that allows local symlinks. (Eli Collins via Sanjay Radia)
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FileContext.java#getFSofPath(Path)#0294c49df60150bd9b363af5cfbc312222c12c69#2009-09-17 22:27:15#64f537da0a216055d5b6eae49a2a9129189cacbf#2009-10-07 17:07:37#-1#19.0#20.0#7.0#7.0#17.0#17.0#3.0#3.0#1.0#1.0#// TBD cleanup this impl once we create a new FileSystem to replace current // one - see HADOOP-6223.#0294c49df60150bd9b363af5cfbc312222c12c69#HADOOP-4952. Add new improved file system interface FileContext for the application writer. Contributed by Sanjay Radia.#3f371a0a644181b204111ee4e12c995fc7b5e5f5#Hadoop-6223. Add new file system interface AbstractFileSystem with implementation of some file systems that delegate to old FileSystem. Contributed by Sanjay Radia.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FileContext.java#checkDest(String,Path,boolean)#0294c49df60150bd9b363af5cfbc312222c12c69#2009-09-17 22:27:15#9ad633f011700997c2f571e990ed9a3745955ac4#2010-04-27 16:53:40#-1#4.0#4.0#4.0#4.0#14.0#14.0#5.0#5.0#3.0#3.0#// TBD not very clear#0294c49df60150bd9b363af5cfbc312222c12c69#HADOOP-4952. Add new improved file system interface FileContext for the application writer. Contributed by Sanjay Radia.#8991eb7959947735449d300a60aaadb897c11ba2#HADOOP-6678. Remove FileContextisFile, isDirectory and exists. Contributed by Eli Collins.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FileContext.java#fixRelativePart(Path)#ea605b8cd79163444feead75d7b55dbd4ab537a0#2010-02-16 21:43:30#736eb17a796a1c1ad5f4db2c6a64f6752db7bec3#2016-01-25 13:47:29#-1#24.0#47.0#3.0#4.0#7.0#8.0#2.0#2.0#1.0#1.0#/* hadoop,   * Remove relative part - return "absolute":hadoop,   * If input is relative path ("foo/bar") add wd: ie "/<workingDir>/foo/bar"hadoop,   * A fully qualified uri ("hdfs://nn:p/foo/bar") or a slash-relative pathhadoop,   * ("/foo/bar") are returned unchanged.hadoop,   * hadoop,   * Applications that use FileContext should use makeQualified() sincehadoop,   * they really want a fully qualified URI.hadoop,   * Hence this method is not called makeAbsolute() and hadoop,   * has been deliberately declared private.hadoop,   */#ea605b8cd79163444feead75d7b55dbd4ab537a0#    HADOOP-6421 Adds Symbolic links to FileContext, AbstractFileSystem.     It also adds a limited implementation for the local file system      (RawLocalFs) that allows local symlinks. (Eli Collins via Sanjay Radia)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java#fixRelativePart(Path)#799e3c344ebc6e1f64072ae211d62fe541625310#2013-03-27 23:43:45#799e3c344ebc6e1f64072ae211d62fe541625310#2013-03-27 23:43:45#-1#27.0#27.0#9.0#9.0#16.0#16.0#4.0#4.0#2.0#2.0#/* hadoop,   * Resolve a relative path passed from the user.hadoop,   * hadoop,   * Relative paths are resolved against the current working directoryhadoop,   * (e.g. "foo/bar" becomes "/<workingDir>/foo/bar").hadoop,   * Fully-qualified URIs (e.g. "hdfs://nn:p/foo/bar") and slash-relative pathshadoop,   * ("/foo/bar") are returned unchanged.hadoop,   * hadoop,   * Additionally, we fix malformed URIs that specify a scheme but not an hadoop,   * authority (e.g. "hdfs:///foo/bar"). Per RFC 2395, we remove the schemehadoop,   * if it matches the default FS, and let the default FS add in the defaulthadoop,   * scheme and authority later (see {@link AbstractFileSystemcheckPath}).hadoop,   * hadoop,   * Applications that use FileContext should use makeQualified() sincehadoop,   * they really want a fully-qualified URI.hadoop,   * Hence this method is not called makeAbsolute() and hadoop,   * has been deliberately declared private.hadoop,   */#799e3c344ebc6e1f64072ae211d62fe541625310#HADOOP-9357. Fallback to default authority if not specified in FileContext. Contributed by Andrew Wang#0e9f61addc67e598cfcde0e9c537954ef00f311e#Revert initial HADOOP-9357 patch.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileEncryptionInfo.java#fixRelativePart(Path)#2efea952139b30dd1c881eed0b443ffa72be6dce#2014-06-27 20:43:41#6ac10516e7fa28384b6d3c2670f6621e2666ffdb#2014-10-02 13:51:08#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#/* hadoop,   * Remove relative part - return "absolute":hadoop,   * If input is relative path ("foo/bar") add wd: ie "/<workingDir>/foo/bar"hadoop,   * A fully qualified uri ("hdfs://nn:p/foo/bar") or a slash-relative pathhadoop,   * ("/foo/bar") are returned unchanged.hadoop,   * hadoop,   * Applications that use FileContext should use makeQualified() sincehadoop,   * they really want a fully qualified URI.hadoop,   * Hence this method is not called makeAbsolute() and hadoop,   * has been deliberately declared private.hadoop,   */#2efea952139b30dd1c881eed0b443ffa72be6dce#HDFS-6391. Get the Key/IV from the NameNode for encrypted files in DFSClient. Contributed by Charles Lamb and Andrew Wang.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java#makeQualified(Path)#da00476fca356514b0720b64c40b632a445a8907#2012-02-03 22:55:52#27941a1811831e0f2144a2f463d807755cd850b2#2016-03-02 18:35:28#-1#5.0#13.0#5.0#5.0#15.0#15.0#3.0#3.0#2.0#2.0#// NOTE: should deal with authority, but too much other stuff is broken #da00476fca356514b0720b64c40b632a445a8907#HADOOP-8013 ViewFileSystem does not honor setVerifyChecksum (Dayrn Sharp via bobby)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#copyToLocal(FileSystem,FileStatus,File,boolean)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#b04fb035ece4aafef525ec65cbd0ffe9bf70e5cc#2011-05-17 00:53:51#-1#6.0#6.0#19.0#19.0#52.0#54.0#9.0#10.0#3.0#3.0#/* Keep the structure similar to ChecksumFileSystem.copyToLocal(). hadoop,     * Ideal these two should just invoke FileUtil.copy() and not repeathadoop,     * recursion here. Of course, copy() should support two more options :hadoop,     * copyCrc and useTmpFile (may be useTmpFile need not be an option).hadoop,     */#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#touchz(String)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#4aa51ca6f9ba0b096568bfb5aa4249fd41d99899#2011-05-11 18:32:18#-1#2.0#2.0#9.0#9.0#15.0#15.0#4.0#4.0#2.0#2.0#// TODO: handle this#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#cd2079f0e4aa292492b5d6c0d0af5bfa41a39043#HADOOP-7237. Refactor the touchz commands to conform to new FsCommand class.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#run(Stringargv)#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#2011-03-28 23:45:02#7568e9c88cf470f63c2ab78c17d02865661d13fa#2011-04-08 23:07:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: next two lines are a temporary crutch until this entire // block is overhauled#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp#d358eb75b79b17f85ae9fd831a0bd065b87bf924#HADOOP-7224. Add CommandFactory to shell.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#run(Stringargv)#a65753ddac34a114c51cb0010ee39a9af48b4f9e#2011-04-07 21:59:37#7568e9c88cf470f63c2ab78c17d02865661d13fa#2011-04-08 23:07:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: will change with factory#a65753ddac34a114c51cb0010ee39a9af48b4f9e#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp#d358eb75b79b17f85ae9fd831a0bd065b87bf924#HADOOP-7224. Add CommandFactory to shell.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#run(Stringargv)#d358eb75b79b17f85ae9fd831a0bd065b87bf924#2011-04-13 20:23:51#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#2011-05-25 17:29:20#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: This isn't the best place, but this class is being abused with // subclasses which of course override this method.  There really needs // to be a better base class for all commands#d358eb75b79b17f85ae9fd831a0bd065b87bf924#HADOOP-7224. Add CommandFactory to shell.  Contributed by Daryn Sharp#44a35b5d9accc4ecf7b1bbf762e593540bafe6a3#HADOOP-7353. Cleanup FsShell and prevent masking of RTE stack traces. Contributed by Daryn Sharp.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#test(Stringargv,int)#a5290c9eca69027cff2448d05fee6983cbb54cd7#2011-05-10 21:29:34#7f77fad79af0010cd22ca773d9af27110429d3a2#2011-05-11 21:12:23#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: it's backwards compat, but why is this throwing an exception? // it's not like the shell test cmd#a5290c9eca69027cff2448d05fee6983cbb54cd7#HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp#a8a336b1b5082dcab29c5fed45fed4b01312426d#HADOOP-7285. Refactor the test command to conform to new FsCommand class. Contributed by Daryn Sharp.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#registerCommands(CommandFactory)#44a35b5d9accc4ecf7b1bbf762e593540bafe6a3#2011-06-06 20:53:37#cbc7b6bf97a80c39d4bbb3005e42dacae6726baf#2015-12-04 10:39:45#-1#3.0#3.0#3.0#3.0#8.0#8.0#2.0#2.0#1.0#1.0#// TODO: DFSAdmin subclasses FsShell so need to protect the command // registration.  This class should morph into a base class for // commands, and then this method can be abstract#44a35b5d9accc4ecf7b1bbf762e593540bafe6a3#HADOOP-7353. Cleanup FsShell and prevent masking of RTE stack traces. Contributed by Daryn Sharp.##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShell.java#newShellInstance()#44a35b5d9accc4ecf7b1bbf762e593540bafe6a3#2011-06-06 20:53:37#cbc7b6bf97a80c39d4bbb3005e42dacae6726baf#2015-12-04 10:39:45#-1#1.0#1.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: this should be abstract in a base class#44a35b5d9accc4ecf7b1bbf762e593540bafe6a3#HADOOP-7353. Cleanup FsShell and prevent masking of RTE stack traces. Contributed by Daryn Sharp.##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/FsShellPermissions.java#processOptions(LinkedList<String>)#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#2011-05-06 20:14:15#be3fdd1c40140e24df1a5414cf91537862b66e82#2014-06-13 06:39:57#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: remove "chmod : " so it's not doubled up in output, but it's // here for backwards compatibility...#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#HADOOP-7249. Refactor the chmod/chown/chgrp command to conform to new FsCommand class.  Contributed by Daryn Sharp##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/HardLink.java#linkCount(File)#527bac7e2265548d8611723109f7f91b629079ed#2011-03-10 23:33:52#13422461f3a96aca663bc8464535cce19804148d#2012-10-23 15:32:25#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//The linkCount command is actually a Cygwin shell command, //not a Windows shell command, so we should use "makeShellPath()" //instead of "getCanonicalPath()".  However, that causes another //shell exec to "cygpath.exe", and "stat.exe" actually can handle //DOS-style paths (it just prints a couple hundred bytes of warning //to stderr), so we use the more efficient "getCanonicalPath()".#527bac7e2265548d8611723109f7f91b629079ed#HADOOP-7133. Batch the calls in DataStorage to FileUtil.createHardLink().  Contributed by Matt Foley.#638801cce16fc1dc3259c541dc30a599faaddda1#HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.
hadoop#DESIGN#mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java#seekToNewSource(long)#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#7d2d16f4ee87ae56dc20016a91c109dd5130f7d4#2015-10-29 11:28:17#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//do not need to implement this // hdfs in itself does seektonewsource  // while reading.#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFs.java#seekToNewSource(long)#7a655d563398d539e5aca8a42061926e5d35c3ae#2014-04-03 22:20:47#f343f8657e2b01773a32c2c7d960dc368954b42e#2015-05-01 15:44:36#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//do not need to implement this // hdfs in itself does seektonewsource  // while reading.#7a655d563398d539e5aca8a42061926e5d35c3ae#HADOOP-10454. Provide FileContext version of har file system. (Kihwal Lee via jeagles)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HasEnhancedByteBufferAccess.java#seekToNewSource(long)#9a361c5821508435b6aabd6640940341902719a1#2013-09-24 21:40:53#173c1159519b6a1885c604b9891a31011b0bcc85#2014-03-07 01:18:32#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//do not need to implement this // hdfs in itself does seektonewsource  // while reading.#9a361c5821508435b6aabd6640940341902719a1#HDFS-5191. Revisit zero-copy API in FSDataInputStream to make it more intuitive (Contributed by Colin Patrick McCabe)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#expandArguments(LinkedList<String>)#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#2011-03-28 23:45:02#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#3.0#3.0#4.0#4.0#12.0#12.0#3.0#3.0#2.0#2.0#// other exceptions are probably nasty#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#processPaths(PathData,PathData...)#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#2011-03-28 23:45:02#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this really should be iterative#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#displayError(Exception)#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#2011-03-28 23:45:02#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#3.0#3.0#6.0#6.0#16.0#20.0#2.0#3.0#1.0#1.0#// this is an unexpected condition, so dump the whole exception since // it's probably a nasty internal error where the backtrace would be // useful#50b1f9fc73bedd7b5bd5d7c7ec1a43b17dd117ac#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#processNonexistentPathArgument(PathData)#a65753ddac34a114c51cb0010ee39a9af48b4f9e#2011-04-07 21:59:37#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#2011-05-06 20:14:15#-1#2.0#3.0#1.0#1.0#5.0#4.0#1.0#1.0#0.0#0.0#// TODO: this should be more posix-like: ex. "No such file or directory"#a65753ddac34a114c51cb0010ee39a9af48b4f9e#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp#a5290c9eca69027cff2448d05fee6983cbb54cd7#HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#expandGlob(String)#a65753ddac34a114c51cb0010ee39a9af48b4f9e#2011-04-07 21:59:37#7ebfabc65a1c4a5b7dfb3d197385bbe95859278c#2011-04-27 04:13:23#-1#3.0#3.0#8.0#9.0#21.0#21.0#4.0#4.0#2.0#2.0#// glob failed to match // TODO: this should be more posix-like: ex. "No such file or directory"#a65753ddac34a114c51cb0010ee39a9af48b4f9e#HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp#369a20391555f9c0ca9bd5384435be12770942aa#HADOOP-7236. Refactor the mkdir command to conform to new FsCommand class.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Command.java#run(String...)#99ebad8e757e90f6e036fc213d99f82dec7b80d7#2011-04-21 16:05:30#369a20391555f9c0ca9bd5384435be12770942aa#2011-05-04 21:34:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: -1 should be reserved for syntax error, 1 should be failure#99ebad8e757e90f6e036fc213d99f82dec7b80d7#HADOOP-7233. Refactor ls to conform to new FsCommand class.  Contributed by Daryn Sharp#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#HADOOP-7249. Refactor the chmod/chown/chgrp command to conform to new FsCommand class.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/CommandWithDestination.java#setOverwrite(boolean)#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#2011-05-25 17:29:20#a196766ea07775f18ded69bd9e8d239f8cfd3ccc#2011-06-12 22:00:51#-1#1.0#1.0#1.0#1.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: commands should implement a -f to enable this#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.#e8eed98feb5aa482abf9cec156e5b87022769604#HADOOP-7361. Provide an option, -overwrite/-f, in put and copyFromLocal shell commands.  Contributed by Uma Maheswara Rao G
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java#processPath(PathData,PathData)#8f9661da4823bfbb243e430252ec1bb5780ecbfc#2011-11-01 01:50:56#8bfaa80037365c0790083313a905d1e7d88b0682#2016-03-28 14:13:48#-1#4.0#5.0#8.0#8.0#11.0#11.0#4.0#4.0#1.0#1.0#// TODO: remove when FileContext is supported, this needs to either // copy the symlink or deref the symlink#8f9661da4823bfbb243e430252ec1bb5780ecbfc#HADOOP-7771. FsShell -copyToLocal, -get, etc. commands throw NPE if the destination directory does not exist.  Contributed by John George and Daryn Sharp##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/CopyCommands.java#processOptions(LinkedList<String>)#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#2011-05-25 17:29:20#8f9661da4823bfbb243e430252ec1bb5780ecbfc#2011-11-01 01:50:56#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this really should be a -nl option#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.#1e0c51c66e107a79b43c16dc1808168636626a3b#HADOOP-7348. Change 'addnl' in getmerge util to be a flag '-nl' instead (XieXianshan via harsh)
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/CopyCommands.java#processPath(PathData,PathData)#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#2011-05-25 17:29:20#659ea4c540e440004d9f1a7dedefa91c0bec8b04#2011-10-28 01:13:49#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// we have no idea what the error is...  FileUtils masks it and in // some cases won't even report an error#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.#8f9661da4823bfbb243e430252ec1bb5780ecbfc#HADOOP-7771. FsShell -copyToLocal, -get, etc. commands throw NPE if the destination directory does not exist.  Contributed by John George and Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/CopyCommands.java#processArguments(LinkedList<PathData>)#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#2011-05-25 17:29:20#061c05cc05ff6257b14c5c4f25cbcec2d184cda7#2015-12-18 13:58:28#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// NOTE: this logic should be better, mimics previous implementation#77b4fd6572d6f928ea5bd86c8b00caeba7bb3b99#HADOOP-7320. Refactor the copy and move commands to conform to new FsCommand class. Contributed by Daryn Sharp.##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Count.java#getFnfText(Path)#99ebad8e757e90f6e036fc213d99f82dec7b80d7#2011-04-21 16:05:30#99ebad8e757e90f6e036fc213d99f82dec7b80d7#2011-04-21 16:05:30#-1#1.0#1.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: remove when the error is commonized...#99ebad8e757e90f6e036fc213d99f82dec7b80d7#HADOOP-7233. Refactor ls to conform to new FsCommand class.  Contributed by Daryn Sharp#a5290c9eca69027cff2448d05fee6983cbb54cd7#HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Delete.java#processOptions(LinkedList<String>)#7f77fad79af0010cd22ca773d9af27110429d3a2#2011-05-11 21:12:23#ea6b183a1a649ad2874050ade8856286728c654c#2015-10-27 10:57:45#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: should probably allow path arguments for the filesystems#7f77fad79af0010cd22ca773d9af27110429d3a2#HADOOP-7267. Refactor the rm/rmr/expunge commands to conform to new FsCommand class.  Contributed by Daryn Sharp##
hadoop#DESIGN#src/test/empty-file#processOptions(LinkedList<String>)#a02641cfa5c5d31268978aa142c61cf3257fdfd6#2011-03-12 00:24:30#a02641cfa5c5d31268978aa142c61cf3257fdfd6#2011-03-12 00:24:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: should probably allow path arguments for the filesystems#a02641cfa5c5d31268978aa142c61cf3257fdfd6#HADOOP-7167. Amend previous commit under this JIRA to fix issue on cygwin. Contributed by Todd Lipcon#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#HADOOP-7249. Refactor the chmod/chown/chgrp command to conform to new FsCommand class.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Display.java#getFnfText(Path)#3337cdb3121d926301a3cca17abef029abdb2ff3#2011-05-09 20:08:51#3337cdb3121d926301a3cca17abef029abdb2ff3#2011-05-09 20:08:51#-1#1.0#1.0#8.0#8.0#12.0#12.0#2.0#2.0#1.0#1.0#// TODO: this is a pretty inconsistent way to output the path...!! //       but, it's backwards compatible#3337cdb3121d926301a3cca17abef029abdb2ff3#HADOOP-7238. Refactor the cat and text commands to conform to new FsCommand class.  Contributed by Daryn Sharp#a5290c9eca69027cff2448d05fee6983cbb54cd7#HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Ls.java#getFnfText(Path)#99ebad8e757e90f6e036fc213d99f82dec7b80d7#2011-04-21 16:05:30#38ac23159dd0eea5a58928fbcff501cbd9ffdd5b#2011-05-06 20:14:15#-1#1.0#1.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: remove when the error is commonized...#99ebad8e757e90f6e036fc213d99f82dec7b80d7#HADOOP-7233. Refactor ls to conform to new FsCommand class.  Contributed by Daryn Sharp#a5290c9eca69027cff2448d05fee6983cbb54cd7#HADOOP-7271. Standardize shell command error messages.  Contributed by Daryn Sharp
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Mkdir.java#processNonexistentPath(PathData)#889a863da13bdc493036671f8db14095a5ca484e#2012-03-15 23:42:38#4c51dacd521b774a1f7c9220d755933c50639225#2012-07-19 21:15:42#-1#3.0#3.0#3.0#3.0#6.0#6.0#2.0#2.0#1.0#1.0#// TODO: should use createParents to control intermediate dir creation #889a863da13bdc493036671f8db14095a5ca484e#HADOOP-8175. FsShell: Add -p option to mkdir.  Contributed by Daryn Sharp#0bfa7d79d0fc5f127fd785e8ba3bc83dab8df991#HADOOP-8551. fs -mkdir creates parent directories without the -p option (John George via bobby)
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/PathData.java#expandAsGlob(String,Configuration)#369a20391555f9c0ca9bd5384435be12770942aa#2011-05-04 21:34:15#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#4.0#5.0#9.0#9.0#32.0#32.0#4.0#4.0#2.0#2.0#// this is very ugly, but needed to avoid breaking hdfs tests... // if a path has no authority, then the FileStatus from globStatus // will add the "-fs" authority into the path, so we need to sub // it back out to satisfy the tests#369a20391555f9c0ca9bd5384435be12770942aa#HADOOP-7236. Refactor the mkdir command to conform to new FsCommand class.  Contributed by Daryn Sharp#659ea4c540e440004d9f1a7dedefa91c0bec8b04#HADOOP-7360. Preserve relative paths that do not contain globs in FsShell.  Contributed by Daryn Sharp and Kihwal Lee
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/PathData.java#lookupStat(FileSystem,String,boolean)#659ea4c540e440004d9f1a7dedefa91c0bec8b04#2011-10-28 01:13:49#e54a3e1f4f3ea4dbba14f3fab0c395a235763c54#2015-04-22 13:48:16#-1#5.0#5.0#4.0#4.0#11.0#11.0#3.0#3.0#2.0#2.0#// TODO: should consider wrapping other exceptions into Path*Exceptions#659ea4c540e440004d9f1a7dedefa91c0bec8b04#HADOOP-7360. Preserve relative paths that do not contain globs in FsShell.  Contributed by Daryn Sharp and Kihwal Lee##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/SnapshotCommands.java#processOptions(LinkedList<String>)#2d5334931ed569e11b293a49fb7f475a09da2616#2012-10-25 04:08:36#59e968a114dfe1b513f31424211116f23525def8#2013-02-25 23:14:58#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: name length check  #2d5334931ed569e11b293a49fb7f475a09da2616#HDFS-4097. Provide CLI support for createSnapshot. Contributed by Brandon Li.#0f78c50ea7f25515f43a7570fe67a6604e8772ad#HDFS-4692. Use timestamp as default snapshot names.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/SnapshotCommands.java#processOptions(LinkedList<String>)#59e968a114dfe1b513f31424211116f23525def8#2013-02-25 23:14:58#59e968a114dfe1b513f31424211116f23525def8#2013-02-25 23:14:58#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: new name length check#59e968a114dfe1b513f31424211116f23525def8#HDFS-4514. Add CLI for supporting snapshot rename, diff report, and snapshottable directory listing.  Contributed by Jing Zhao#0f78c50ea7f25515f43a7570fe67a6604e8772ad#HDFS-4692. Use timestamp as default snapshot names.
hadoop#DESIGN#src/java/org/apache/hadoop/fs/shell/Touchz.java#processPath(PathData)#cd2079f0e4aa292492b5d6c0d0af5bfa41a39043#2011-05-11 20:20:18#8bfaa80037365c0790083313a905d1e7d88b0682#2016-03-28 14:13:48#-1#2.0#-1#5.0#-1#10.0#-1#3.0#-1#1.0#-1#// TODO: handle this#cd2079f0e4aa292492b5d6c0d0af5bfa41a39043#HADOOP-7237. Refactor the touchz commands to conform to new FsCommand class.  Contributed by Daryn Sharp##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Truncate.java#processPath(PathData)#a0521bc83a168a06f21314a9aff78630a576fc75#2015-01-21 15:58:58#a0521bc83a168a06f21314a9aff78630a576fc75#2015-01-21 15:58:58#-1#8.0#8.0#7.0#7.0#22.0#22.0#5.0#5.0#1.0#1.0#// TODO: handle this#a0521bc83a168a06f21314a9aff78630a576fc75#HADOOP-11490. Expose truncate API via FileSystem and shell command. Contributed by Milan Desai.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/XAttrCommands.java#processPath(PathData)#ac23a55547716df29b3e25c98a113399e184d9d1#2014-05-21 13:57:33#d1c6accb6f87b08975175580e15f1ff1fe29ab04#2015-03-03 14:12:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ac23a55547716df29b3e25c98a113399e184d9d1#Merge HDFS-2006 HDFS XAttrs branch to Trunk##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/And.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/BaseExpression.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/Expression.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/ExpressionFactory.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/FilterExpression.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/Find.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ad8ed3e802782a7a3fb3d21c5862673a8f695372#2015-02-25 16:25:04#-1#1.0#1.0#3.0#3.0#7.0#7.0#2.0#2.0#1.0#1.0#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/FindOptions.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/Name.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#d1c6accb6f87b08975175580e15f1ff1fe29ab04#2015-03-03 14:12:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/Print.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/find/Result.java#processPath(PathData)#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#ba879a5dadbb0f33bba7e05ebc329a9942f34276#2014-11-13 08:20:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: handle this#ba879a5dadbb0f33bba7e05ebc329a9942f34276#HADOOP-8989. hadoop fs -find feature (Jonathan Allen via aw)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/viewfs/ChRootedFileSystem.java#rename(Path,Path)#f1c74df922058e88791ed6971bbb96b53f6770f1#2011-05-06 02:11:31#2fd19b9674420e025af54a5bed12eb96478f8c48#2016-01-21 12:04:14#-1#3.0#2.0#3.0#3.0#5.0#5.0#1.0#1.0#0.0#0.0#// note fullPath will check that paths are relative to this FileSystem. // Hence both are in same file system and a rename is valid#f1c74df922058e88791ed6971bbb96b53f6770f1#HADOOP-7257 Client side mount tables (sanjay)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/viewfs/ChRootedFs.java#renameInternal(Path,Path)#f1c74df922058e88791ed6971bbb96b53f6770f1#2011-05-06 02:11:31#adfa34ff9992295a6d2496b259d8c483ed90b566#2015-07-23 10:13:04#-1#3.0#3.0#2.0#2.0#6.0#6.0#1.0#1.0#0.0#0.0#// note fullPath will check that paths are relative to this FileSystem. // Hence both are in same file system and a rename is valid#f1c74df922058e88791ed6971bbb96b53f6770f1#HADOOP-7257 Client side mount tables (sanjay)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java#getFileStatus(Path)#f1c74df922058e88791ed6971bbb96b53f6770f1#2011-05-06 02:11:31#2fd19b9674420e025af54a5bed12eb96478f8c48#2016-01-21 12:04:14#-1#4.0#4.0#6.0#6.0#18.0#7.0#1.0#1.0#0.0#0.0#// The implementors of RawLocalFileSystem were trying to be very smart. // They implement FileStatusgetOwener lazily -- the object // returned is really a RawLocalFileSystem that expect the // FileStatusgetPath to be unchanged so that it can get owner when needed. // Hence we need to interpose a new ViewFileSystemFileStatus that  // works around.#f1c74df922058e88791ed6971bbb96b53f6770f1#HADOOP-7257 Client side mount tables (sanjay)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java#mkdirs(Path,FsPermission)#f1c74df922058e88791ed6971bbb96b53f6770f1#2011-05-06 02:11:31#2fd19b9674420e025af54a5bed12eb96478f8c48#2016-01-21 12:04:14#-1#5.0#5.0#4.0#4.0#6.0#6.0#1.0#1.0#0.0#0.0#// this is the stupid semantics of FileSystem#f1c74df922058e88791ed6971bbb96b53f6770f1#HADOOP-7257 Client side mount tables (sanjay)##
hadoop#DESIGN#src/java/org/apache/hadoop/fs/viewfs/ViewFs.java#getFileStatus(Path)#f1c74df922058e88791ed6971bbb96b53f6770f1#2011-05-06 02:11:31#adfa34ff9992295a6d2496b259d8c483ed90b566#2015-07-23 10:13:04#-1#4.0#4.0#6.0#6.0#19.0#19.0#1.0#1.0#0.0#0.0#// The implementors of RawLocalFileSystem were trying to be very smart. // They implement FileStatusgetOwener lazily -- the object // returned is really a RawLocalFileSystem that expect the // FileStatusgetPath to be unchanged so that it can get owner when needed. // Hence we need to interpose a new ViewFsFileStatus that works around.#f1c74df922058e88791ed6971bbb96b53f6770f1#HADOOP-7257 Client side mount tables (sanjay)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ActiveStandbyElector.java#tryDeleteOwnBreadCrumbNode()#805c1280ce2773bc61ea718723b42b09d795688f#2012-03-24 00:05:33#0fce5f9a496925f0d53ea6c14318c9b513de9882#2015-10-22 13:41:09#-1#8.0#8.0#8.0#8.0#25.0#25.0#3.0#3.0#2.0#2.0#// Sanity check the data. This shouldn't be strictly necessary, // but better to play it safe.#805c1280ce2773bc61ea718723b42b09d795688f#HADOOP-8163. Improve ActiveStandbyElector to provide hooks for fencing old active. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/SshFenceByTcpPort.java#checkArgs(String)#5c156519dfc1be193a9b7fc2aa450ed1f774b60f#2012-01-30 22:27:42#7be4e5bd222c6f1c40f88ee8b24b1587e157a87e#2012-03-02 01:32:49#-1#1.0#1.0#1.0#1.0#7.0#7.0#2.0#2.0#1.0#1.0#// Use a dummy service when checking the arguments defined // in the configuration are parseable.#5c156519dfc1be193a9b7fc2aa450ed1f774b60f#HADOOP-7983. HA: failover should be able to pass args to fencers. Contributed by Eli Collins#8fd473cf4c04f4a28a2e7f76951ab0db5d206542#HADOOP-8191. SshFenceByTcpPort uses netcat incorrectly. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java#run(String[])#578f413778a6f005a35d18d7f015df128aeded5b#2012-03-26 23:37:33#84ff2d6d066ee7d854dfcb93bb85df7b98a3d761#2012-04-03 20:41:26#-1#1.0#1.0#3.0#3.0#18.0#18.0#2.0#2.0#1.0#1.0#// TODO: need to hook DFS here to find the NN keytab info, etc, // similar to what DFSHAAdmin does. Annoying that this is in common.#578f413778a6f005a35d18d7f015df128aeded5b#HADOOP-8206. Common portion of a ZK-based failover controller. Contributed by Todd Lipcon.#30e1b3bba856b2379a0dc1e7450512427d39c5d7#HADOOP-8215. Security support for ZK Failover controller. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java#initZK()#578f413778a6f005a35d18d7f015df128aeded5b#2012-03-26 23:37:33#84ff2d6d066ee7d854dfcb93bb85df7b98a3d761#2012-04-03 20:41:26#-1#8.0#8.0#7.0#7.0#19.0#19.0#1.0#1.0#0.0#0.0#// TODO: need ZK ACL support in config, also maybe auth!#578f413778a6f005a35d18d7f015df128aeded5b#HADOOP-8206. Common portion of a ZK-based failover controller. Contributed by Todd Lipcon.#30e1b3bba856b2379a0dc1e7450512427d39c5d7#HADOOP-8215. Security support for ZK Failover controller. Contributed by Todd Lipcon.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java#becomeActive()#578f413778a6f005a35d18d7f015df128aeded5b#2012-03-26 23:37:33#49dfad942970459297f72632ed8dfd353e0c86de#2015-06-23 17:26:11#-1#5.0#6.0#5.0#11.0#20.0#36.0#2.0#3.0#1.0#2.0#/*hadoop,* TODO:hadoop,* we need to make sure that if we get fenced and then quickly restarted,hadoop,* none of these calls will retry across the restart boundaryhadoop,* perhaps the solution is that, whenever the nn starts, it gets a uniquehadoop,* ID, and when we start becoming active, we record it, and then any futurehadoop,* calls use the same IDhadoop,*/#578f413778a6f005a35d18d7f015df128aeded5b#HADOOP-8206. Common portion of a ZK-based failover controller. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java#fenceOldActive(byte[])#578f413778a6f005a35d18d7f015df128aeded5b#2012-03-26 23:37:33#49dfad942970459297f72632ed8dfd353e0c86de#2015-06-23 17:26:11#-1#-1#6.0#-1#9.0#-1#24.0#-1#4.0#-1#1.0#// It's possible that it's in standby but just about to go into active, // no? Is there some race here?#578f413778a6f005a35d18d7f015df128aeded5b#HADOOP-8206. Common portion of a ZK-based failover controller. Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java#fenceOldActive(byte[])#578f413778a6f005a35d18d7f015df128aeded5b#2012-03-26 23:37:33#c6e132124591362657e6f1722acca376747ea254#2012-04-24 19:34:51#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO: this will end up in some kind of tight loop, // won't it? We need some kind of backoff#578f413778a6f005a35d18d7f015df128aeded5b#HADOOP-8206. Common portion of a ZK-based failover controller. Contributed by Todd Lipcon.#9d5799553fea81920edfab611e5d485a97841848#HADOOP-8279. Allow manual failover to be invoked when auto-failover is enabled. Contributed by Todd Lipcon.
hadoop#DESIGN#src/java/org/apache/hadoop/http/HttpServer.java#start()#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#e29ede3f729784f0eb770f0a1570bea199ff6902#2012-04-25 03:20:53#-1#9.0#32.0#10.0#15.0#71.0#94.0#15.0#20.0#7.0#8.0#//Workaround to handle the problem reported in HADOOP-4744#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#097a001b3fd355558c971cd82a633177ace77b39#HADOOP-8334. HttpServer sometimes returns incorrect port (Daryn Sharp via bobby)
hadoop#DESIGN#src/java/org/apache/hadoop/http/HttpServer.java#start()#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#e29ede3f729784f0eb770f0a1570bea199ff6902#2012-04-25 03:20:53#-1#9.0#32.0#10.0#15.0#71.0#94.0#15.0#20.0#7.0#8.0#//Workaround end#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#097a001b3fd355558c971cd82a633177ace77b39#HADOOP-8334. HttpServer sometimes returns incorrect port (Daryn Sharp via bobby)
hadoop#DESIGN#src/java/org/apache/hadoop/http/HttpServer.java#start()#929e91a08c5387c692ed3257361190b83d72f2e9#2009-12-08 20:50:47#f6acb32e068a3f1611767c92f728f1c92b9a9fad#2010-04-29 21:32:54#-1#14.0#18.0#12.0#13.0#98.0#101.0#21.0#21.0#7.0#7.0#// Workaround for HADOOP-6386#929e91a08c5387c692ed3257361190b83d72f2e9#HADOOP-6386. NameNode's HttpServer can't instantiate InetSocketAddress: IllegalArgumentException is thrown. Contributed by Konstantin Boudnik.#4e5bdc46bc717d365cce95dd7be0685ef8443dd7#HADOOP-6760. WebServer shouldn't increase port number in case of negative port setting caused by Jetty's race. Contributed by Konstantin Boudnik.
hadoop#DESIGN#src/java/org/apache/hadoop/http/HttpServer.java#start()#929e91a08c5387c692ed3257361190b83d72f2e9#2009-12-08 20:50:47#f6acb32e068a3f1611767c92f728f1c92b9a9fad#2010-04-29 21:32:54#-1#14.0#18.0#12.0#13.0#98.0#101.0#21.0#21.0#7.0#7.0#// End of HADOOP-6386 workaround#929e91a08c5387c692ed3257361190b83d72f2e9#HADOOP-6386. NameNode's HttpServer can't instantiate InetSocketAddress: IllegalArgumentException is thrown. Contributed by Konstantin Boudnik.#4e5bdc46bc717d365cce95dd7be0685ef8443dd7#HADOOP-6760. WebServer shouldn't increase port number in case of negative port setting caused by Jetty's race. Contributed by Konstantin Boudnik.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/ReadaheadPool.java#cancel()#78336e717be194683f863ca15a12cde90b9e936d#2011-10-27 22:19:13#21d10ccc6e463cf250414264c78acb4a6e7c83e3#2015-07-31 14:55:14#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// We could attempt to remove it from the work queue, but that would // add complexity. In practice, the work queues remain very short, // so removing canceled requests has no gain.#78336e717be194683f863ca15a12cde90b9e936d#HADOOP-7753. Support fadvise and sync_file_range in NativeIO. Add ReadaheadPool infrastructure for use in HDFS and MR. Contributed by Todd Lipcon.##
hadoop#DESIGN#src/java/org/apache/hadoop/io/SecureIOUtils.java#openForRead(File,String,String)#dbd07f9e8c2824cdb04d44d07d27c2b56f68c1d5#2010-12-01 08:03:58#dbd07f9e8c2824cdb04d44d07d27c2b56f68c1d5#2010-12-01 08:03:58#-1#8.0#8.0#11.0#11.0#25.0#25.0#3.0#3.0#1.0#1.0#// Subject to race conditions but this is the best we can do#dbd07f9e8c2824cdb04d44d07d27c2b56f68c1d5#HADOOP-6978. Adds support for NativeIO using JNI. Contributed by Todd Lipcon, Devaraj Das & Owen O'Malley.#dc16490ad3f8ff42849647fa6150fa53d771809c#HADOOP-7172. SecureIO should not check owner on non-secure clusters that have no native support. Contributed by Todd Lipcon
hadoop#DESIGN#src/java/org/apache/hadoop/io/SequenceFile.java#init(boolean)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#039a1f9e968690cb66af224858e6e64b4f0b2926#2015-10-23 06:43:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Initialize... *not* if this we are constructing a temporary Reader#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch##
hadoop#DESIGN#src/java/org/apache/hadoop/io/WritableUtils.java#readCompressedString(DataInput)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#7fbf69bf47bb733f95b4afd733f9b65e1e7f2b46#2015-10-08 06:08:28#-1#2.0#3.0#2.0#2.0#5.0#5.0#2.0#2.0#1.0#1.0#/* Ugly utility, maybe someone else can do this better  */#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch##
hadoop#DESIGN#src/java/org/apache/hadoop/io/compress/bzip2/CBZip2OutputStream.java#mainSimpleSort(Data,int,int,int)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#deead78e35b0cb81af875b5a8032cbd06c9a2dae#2012-08-25 01:03:22#-1#13.0#13.0#2.0#2.0#183.0#183.0#41.0#41.0#20.0#20.0#// HAMMER // end inline mainGTU#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch##
hadoop#DESIGN#common/src/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java#compress(byte[],int,int)#7e1e4bf50fa83083e762fc267b5215d606a64c3e#2011-06-20 16:32:27#75de23c0d383aa829ae25f19fbfc4fab51959ec4#2011-06-24 17:40:15#-1#7.0#-1#9.0#-1#56.0#-1#9.0#-1#2.0#-1#// Only need todo this once#7e1e4bf50fa83083e762fc267b5215d606a64c3e#HADOOP-7206. Integrate Snappy compression. Contributed by T Jake Luciani.#8014dfa1dba66ae11a055e1e12099d0f6df94448#HADOOP-7206. Support Snappy compression. Contributed by Issei Yoshida and Alejandro Abdelnur
hadoop#DESIGN#common/src/java/org/apache/hadoop/io/compress/snappy/SnappyCompressor.java#compress(byte[],int,int)#7e1e4bf50fa83083e762fc267b5215d606a64c3e#2011-06-20 16:32:27#75de23c0d383aa829ae25f19fbfc4fab51959ec4#2011-06-24 17:40:15#-1#7.0#-1#9.0#-1#56.0#-1#9.0#-1#2.0#-1#// Only need todo this once#7e1e4bf50fa83083e762fc267b5215d606a64c3e#HADOOP-7206. Integrate Snappy compression. Contributed by T Jake Luciani.#8014dfa1dba66ae11a055e1e12099d0f6df94448#HADOOP-7206. Support Snappy compression. Contributed by Issei Yoshida and Alejandro Abdelnur
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/retry/RetryInvocationHandler.java#invoke(Object,Method,Object[])#14569ab482c2bb79cae31bf12a1e6c8d5f0d6064#2011-10-06 01:01:19#d8f390d015510950ccf78174af8891cd613d4438#2016-02-29 16:24:05#-1#12.0#16.0#19.0#29.0#62.0#104.0#9.0#16.0#4.0#5.0#// The number of times this invocation handler has ever been failed over, // before this method invocation attempt. Used to prevent concurrent // failed method invocations from triggering multiple failover attempts.#14569ab482c2bb79cae31bf12a1e6c8d5f0d6064#HADOOP-7717. Move handling of concurrent client fail-overs to RetryInvocationHandler (atm)##
hadoop#DESIGN#src/java/org/apache/hadoop/ipc/Client.java#run()#2786e80436de5e27d4edc648bc882b77c922091a#2010-05-24 18:24:16#1898810cda83e6d273a2963b56ed499c0fb91118#2016-03-14 15:48:01#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// This truly is unexpected, since we catch IOException in receiveResponse // -- this is only to be really sure that we don't leave a client hanging // forever.#2786e80436de5e27d4edc648bc882b77c922091a#HADOOP-6723.  Unchecked exceptions thrown in IPC Connection should not orphan clients.  Contributed by Todd Lipcon.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java#constructRpcRequest(Method,Object[])#65200998c01b17e017d1814e8b1f4d82ac334a23#2011-12-04 20:44:36#892ade689f9bcce76daae8f66fc00a49bee8548e#2015-09-26 22:05:51#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// For protobuf, {@code protocol} used when creating client side proxy is // the interface extending BlockingInterface, which has the annotations  // such as ProtocolName etc. // // Using Method.getDeclaringClass(), as in WritableEngine to get at // the protocol interface will return BlockingInterface, from where  // the annotation ProtocolName and Version cannot be // obtained. // // Hence we simply use the protocol class used to create the proxy. // For PB this may limit the use of mixins on client side.#65200998c01b17e017d1814e8b1f4d82ac334a23#HADOOP-7862  Move the support for multiple protocols to lower layer so that Writable, PB and Avro can all use it (includes HDFS and MR changes to match) (Sanjay)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java#readAndProcess()#5319818487d5c139de06155834deecb18c10b7a1#2013-03-26 23:29:09#2e040d31c7bba021576e6baf267d937da7ff814a#2016-03-08 23:29:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO we should add handler for service class later#5319818487d5c139de06155834deecb18c10b7a1#HADOOP-9194. RPC Support for QoS. (Junping Du via llu)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java#initializeAuthContext(int)#5f9b4c14a175873b4f82654513e289c657c694eb#2013-06-21 20:09:31#5f9b4c14a175873b4f82654513e289c657c694eb#2013-06-21 20:09:31#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// switch to simple hack#5f9b4c14a175873b4f82654513e289c657c694eb#HADOOP-9421. [RPC v9] Convert SASL to use ProtoBuf and provide negotiation capabilities (daryn)#b3a8d99817dcceb4d1125dec0c3ecbb0f15f6c76#YARN-874. Making common RPC to switch to not switch to simple when other mechanisms are enabled and thus fix YARN/MR test failures after HADOOP-9421. Contributed by Daryn Sharp and Vinod Kumar Vavilapalli.
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java#initializeAuthContext(int)#b3a8d99817dcceb4d1125dec0c3ecbb0f15f6c76#2013-06-26 00:42:26#2e040d31c7bba021576e6baf267d937da7ff814a#2016-03-08 23:29:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// switch to simple hack, but don't switch if other auths are // supported, ex. tokens#b3a8d99817dcceb4d1125dec0c3ecbb0f15f6c76#YARN-874. Making common RPC to switch to not switch to simple when other mechanisms are enabled and thus fix YARN/MR test failures after HADOOP-9421. Contributed by Daryn Sharp and Vinod Kumar Vavilapalli.##
hadoop#DESIGN#src/java/org/apache/hadoop/ipc/metrics/RpcMetrics.java#doUpdates(MetricsContext)#5128a9a453d64bfe1ed978cf9ffed27985eeef36#2009-05-19 04:20:40#5c5c163aa3315e063041cefc55a4b1a753494ada#2010-07-28 00:56:50#-1#5.0#6.0#6.0#6.0#13.0#13.0#2.0#2.0#1.0#1.0#// ToFix - fix server to use the following two metrics directly so // the metrics do not have be copied here.#5128a9a453d64bfe1ed978cf9ffed27985eeef36#HADOOP-4687 Moving src directories on branch#8a2b40d0726215e48b53ab22382dd49379c36249#HADOOP-6920. Metrics instrumentation to move new metrics2 framework. Contributed by Luke Lu.
hadoop#DESIGN#src/java/org/apache/hadoop/log/metrics/EventCounter.java#append(LoggingEvent)#8a2b40d0726215e48b53ab22382dd49379c36249#2011-05-10 23:56:54#cd7157784e5e5ddc4e77144d042e54dd0d04bac1#2011-08-25 00:14:24#-1#6.0#6.0#3.0#3.0#17.0#17.0#5.0#5.0#1.0#1.0#// depends on the api, == might not work // see HADOOP-7055 for details#8a2b40d0726215e48b53ab22382dd49379c36249#HADOOP-6920. Metrics instrumentation to move new metrics2 framework. Contributed by Luke Lu.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetworkTopologyWithNodeGroup.java#pseudoSortByDistance(Node,Node[])#19ac5c4e8bc392b778e770e623ec8ff36f207199#2012-06-17 21:12:25#49e176c29f95c179c0f6b07d4d582e6a771a96bd#2016-02-05 15:46:25#-1#4.0#-1#8.0#-1#71.0#-1#18.0#-1#5.0#-1#// if reader is not a datanode (not in NetworkTopology tree), we will  // replace this reader with a sibling leaf node in tree.#19ac5c4e8bc392b778e770e623ec8ff36f207199#HADOOP-8468. Add NetworkTopologyWithNodeGroup, a 4-layer implementation of NetworkTopology.  Contributed by Junping Du##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java#saslConnect(InputStream,OutputStream)#5f9b4c14a175873b4f82654513e289c657c694eb#2013-06-21 20:09:31#ff2b2bea9143c6299cad4bb7d1d049e415d2d7f3#2015-10-28 10:25:22#-1#15.0#14.0#35.0#31.0#105.0#98.0#19.0#16.0#4.0#4.0#// TODO: should instantiate sasl client based on advertisement // but just blindly use the pre-instantiated sasl client for now#5f9b4c14a175873b4f82654513e289c657c694eb#HADOOP-9421. [RPC v9] Convert SASL to use ProtoBuf and provide negotiation capabilities (daryn)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java#setLoginUser(UserGroupInformation)#86ce5f6c917131e79174f8c7ac55d6cb1abad09d#2012-11-15 21:14:37#ccff6035f50769eb69701128ae61efc69e82609d#2016-02-25 09:24:32#-1#3.0#23.0#1.0#1.0#5.0#5.0#1.0#1.0#0.0#0.0#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#86ce5f6c917131e79174f8c7ac55d6cb1abad09d#HADOOP-9035. Generalize setup of LoginContext (daryn via bobby)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/WhitelistBasedResolver.java#setLoginUser(UserGroupInformation)#b47ad1ccbaf6a75eecfbeddb17e539480a01aab3#2014-08-17 17:43:20#d1c6accb6f87b08975175580e15f1ff1fe29ab04#2015-03-03 14:12:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#b47ad1ccbaf6a75eecfbeddb17e539480a01aab3#HADOOP-10335. An ip whilelist based implementation to resolve Sasl properties per connection. (Contributed by Benoy Antony)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/JavaKeyStoreProvider.java#setLoginUser(UserGroupInformation)#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#fbf55dcaf45285e1795cb107e7846799e4042b0b#2015-06-16 14:44:03#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#c79728478caadd8374bce2bc3f466db1da1e3ad1#HADOOP-10607. Create API to separate credential/password storage from applications. (Larry McCay via omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/CredentialProvider.java#setLoginUser(UserGroupInformation)#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#65b0cfc96b118f0f2b55805d98076dd5229f1bc3#2014-07-15 18:15:46#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#c79728478caadd8374bce2bc3f466db1da1e3ad1#HADOOP-10607. Create API to separate credential/password storage from applications. (Larry McCay via omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProviderFactory.java#setLoginUser(UserGroupInformation)#77306291643838ed7b57b99d6497553314a525f2#2013-12-20 00:25:42#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#77306291643838ed7b57b99d6497553314a525f2#HADOOP-10141. Create KeyProvider API to separate encryption key storage from the applications. (omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/CredentialShell.java#setLoginUser(UserGroupInformation)#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#6e891a921e00b122390a976dfd13838472a7fcc6#2015-03-24 20:57:39#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#c79728478caadd8374bce2bc3f466db1da1e3ad1#HADOOP-10607. Create API to separate credential/password storage from applications. (Larry McCay via omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/JavaKeyStoreProvider.java#setLoginUser(UserGroupInformation)#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#860b8373c3a851386b8cd2d4265dd35e5aabc941#2015-05-28 15:01:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#c79728478caadd8374bce2bc3f466db1da1e3ad1#HADOOP-10607. Create API to separate credential/password storage from applications. (Larry McCay via omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/LocalJavaKeyStoreProvider.java#setLoginUser(UserGroupInformation)#860b8373c3a851386b8cd2d4265dd35e5aabc941#2015-05-28 15:01:42#2dbc40e6086026ef02747223982aa68f2d328ade#2015-06-05 13:11:01#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#860b8373c3a851386b8cd2d4265dd35e5aabc941#HADOOP-11934. Use of JavaKeyStoreProvider in LdapGroupsMapping causes infinite loop. Contributed by Larry McCay.##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/alias/UserProvider.java#setLoginUser(UserGroupInformation)#c79728478caadd8374bce2bc3f466db1da1e3ad1#2014-06-18 15:45:20#5b9fcedb4d116d91d70aaad6cbf59093eeee36df#2014-12-11 16:41:30#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// if this is to become stable, should probably logout the currently // logged in ugi if it's different#c79728478caadd8374bce2bc3f466db1da1e3ad1#HADOOP-10607. Create API to separate credential/password storage from applications. (Larry McCay via omalley)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ssl/SSLHostnameVerifier.java#getDNSSubjectAlts(X509Certificate)#9d16c9354b0c05edb30d23003dcdec4cc44ed925#2012-07-26 13:23:05#d1c6accb6f87b08975175580e15f1ff1fe29ab04#2015-03-03 14:12:34#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Should probably log.debug() this?#9d16c9354b0c05edb30d23003dcdec4cc44ed925#MAPREDUCE-4417. add support for encrypted shuffle (tucu)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ssl/SslSocketConnectorSecure.java#getDNSSubjectAlts(X509Certificate)#dbf30e3c0e1522e6588aecac71c990c0b01fd8fb#2014-11-04 16:18:24#dbf30e3c0e1522e6588aecac71c990c0b01fd8fb#2014-11-04 16:18:24#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// Should probably log.debug() this?#dbf30e3c0e1522e6588aecac71c990c0b01fd8fb#HADOOP-11260. Patch up Jetty to disable SSLv3. (Mike Yoder via kasha)##
hadoop#DESIGN#hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Shell.java#runCommand()#638801cce16fc1dc3259c541dc30a599faaddda1#2013-03-06 19:15:18#5a725f0ab8ef9e2a8b08f088ba4e87531ae4530d#2016-03-16 14:31:19#-1#14.0#16.0#28.0#30.0#107.0#127.0#14.0#14.0#2.0#2.0#// To workaround the race condition issue with child processes // inheriting unintended handles during process launch that can // lead to hangs on reading output and error streams, we // serialize process creation. More info available at: // http://support.microsoft.com/kb/315939#638801cce16fc1dc3259c541dc30a599faaddda1#HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.##
log4j#DESIGN#src/java/org/apache/log4j/helpers/Loader.java#getResource(String)#caa8e432af35512216b58492e3d8499f7262e109#2001-10-11 15:10:21#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#4.0#8.0#8.0#10.0#39.0#51.0#6.0#10.0#4.0#4.0#// We could not find resource. Ler us now try with the // classloader that loaded this class.#caa8e432af35512216b58492e3d8499f7262e109#Search for "resource" using the thread context class loader under Java2. If that fails, search for "resource" using the class loader that loaded this class (Loader). Under JDK 1.1, only the the class loader that loaded this class (Loader) is used.##
log4j#DESIGN#src/java/org/apache/log4j/helpers/OptionConverter.java#getLogger()#d192ca52485990a035b7ef84cea67a6743ad3d47#2005-01-08 13:14:03#719d93cd529c1f406668242393ff188d7ae77025#2007-07-18 05:06:07#-1#7.0#7.0#2.0#2.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: this method should be removed if OptionConverter becomes a static#d192ca52485990a035b7ef84cea67a6743ad3d47#- log4j.jar now confoms to the UGLI model. - Minor changes.#7c8d2d6732c10a519ac231edb406c97a38abc182#Bug 44157: InterruptedIOException ignored by log4j
log4j#DESIGN#src/java/org/apache/log4j/helpers/OptionConverter.java#setLoggerRepository(LoggerRepository)#1f62d9a039c3ee68f66c6c5cb41760438777dfd8#2005-01-08 14:05:29#719d93cd529c1f406668242393ff188d7ae77025#2007-07-18 05:06:07#-1#0.0#0.0#0.0#0.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO: this method should be removed if OptionConverter becomes totally static#1f62d9a039c3ee68f66c6c5cb41760438777dfd8#- OptionConverter once again all static. - Fixed a bug in ConsoleAppender preventing it from displaying any output.#7c8d2d6732c10a519ac231edb406c97a38abc182#Bug 44157: InterruptedIOException ignored by log4j
log4j#DESIGN#src/java/org/apache/log4j/helpers/Transform.java#escapeTags(String)#7bd0c413a7902328b3e48de73486b7076ae0efbb#2002-04-26 12:31:42#cb2d874d82a5ffb5435778d2869d827e7fca9b7c#2007-08-10 22:05:16#-1#4.0#4.0#5.0#6.0#27.0#38.0#5.0#8.0#2.0#2.0#//Use a StringBuffer in lieu of String concatenation -- it is //much more efficient this way.#7bd0c413a7902328b3e48de73486b7076ae0efbb#Missing file.##
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/dnd/FileDnDTarget.java#decorateComponent()#d8530a7ba0a823db98022edabcc018e5864ab2a5#2004-09-02 00:30:19#c12e49983b082a4286e39d639fb3324cde6315ce#2004-09-17 10:23:32#-1#2.0#2.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#//        TODO work out a better way of decorating a component#d8530a7ba0a823db98022edabcc018e5864ab2a5#* Added Drag & Drop (rudimentary) support to Chainsaw.   You can drag any File to Chainsaw's   Tabbed Pane area and it will try to load it.  If there are no events in the file, not a lot happens...#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/help/HelpManager.java#showHelpForClass(Class)#bc50e850e3193f556c6c22631eb0fc54a64a9cbf#2003-12-19 06:50:35#bc50e850e3193f556c6c22631eb0fc54a64a9cbf#2003-12-19 06:50:35#-1#1.0#1.0#1.0#1.0#5.0#5.0#1.0#1.0#0.0#0.0#// TODO This needs to convert the FQN class name into a valid help URL. //		 TODO Be also nice to be able to set a BaseHelpURL or something instead of hitting the Apache server.#bc50e850e3193f556c6c22631eb0fc54a64a9cbf#Added a singleton HelpManager so that the Help system is a little more decoupled from the implementation of the help viewer.#0d1bc03ceaf04880c70dfe06ede90da7603f683c#The HelpManager now uses the HelpLocator to find help resources for particular classes.
log4j#DESIGN#src/java/org/apache/log4j/net/SocketAppender.java#isActive()#ad3450477a77a963b46c8c563e7c857e85a994ce#2003-06-24 08:24:57#ad3450477a77a963b46c8c563e7c857e85a994ce#2003-06-24 08:24:57#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO handle active/inactive#ad3450477a77a963b46c8c563e7c857e85a994ce#moving to jakarta-log4j from jakarta-log4j-sandbox.#9d8ddc07310be17aba019c96a80de3784753f578#Reverting to previous version as the version from the sandbox does not pass unit tests
log4j#DESIGN#src/java/org/apache/log4j/net/SocketHubAppender.java#append(LoggingEvent)#1a29e3ec91205f488d5ad379ecf61282a520bb2c#2002-03-25 22:05:36#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#3.0#6.0#8.0#17.0#45.0#64.0#7.0#11.0#2.0#3.0#// catch this, but just don't assign a value // this should not really occur as this method is // the only one that can remove oos's (besides cleanUp).#1a29e3ec91205f488d5ad379ecf61282a520bb2c#Added SocketHubAppender as supplied by Mark Womack. Renamed the package of JDBCAppender##
log4j#DESIGN#src/java/org/apache/log4j/net/SocketHubAppender.java#append(LoggingEvent)#1a29e3ec91205f488d5ad379ecf61282a520bb2c#2002-03-25 22:05:36#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#3.0#6.0#8.0#17.0#45.0#64.0#7.0#11.0#2.0#3.0#// Failing to reset the object output stream every now and // then creates a serious memory leak. // right now we always reset. TODO - set up frequency counter per oos?#1a29e3ec91205f488d5ad379ecf61282a520bb2c#Added SocketHubAppender as supplied by Mark Womack. Renamed the package of JDBCAppender##
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/receivers/PluginPropertyEditorPanel.java#initComponents()#52991087d7eb4a160d14f7d7193ae877777ff51a#2003-12-18 21:41:45#52991087d7eb4a160d14f7d7193ae877777ff51a#2003-12-18 21:41:45#-1#3.0#3.0#6.0#6.0#12.0#12.0#1.0#1.0#0.0#0.0#//        TODO when all the correct CellEditors are in place, remove this line#52991087d7eb4a160d14f7d7193ae877777ff51a#Moved 3 classes into the new package and added a Plugin property editor.#2cd6937d8ca2245d854a4121ddcbab9c4cbb3db4#Plugin Property editor now getting close to being pretty usable.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/receivers/PluginPropertyEditorPanel.java#setupListeners(PropertyChangeEvent)#52991087d7eb4a160d14f7d7193ae877777ff51a#2003-12-18 21:41:45#52991087d7eb4a160d14f7d7193ae877777ff51a#2003-12-18 21:41:45#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO handle else condition#52991087d7eb4a160d14f7d7193ae877777ff51a#Moved 3 classes into the new package and added a Plugin property editor.#2cd6937d8ca2245d854a4121ddcbab9c4cbb3db4#Plugin Property editor now getting close to being pretty usable.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/receivers/PluginPropertyEditorPanel.java#main(String[])#52991087d7eb4a160d14f7d7193ae877777ff51a#2003-12-18 21:41:45#5b2d19618aa31d0e1299397ef946bb1003f95282#2004-11-21 07:01:27#-1#0.0#0.0#10.0#10.0#31.0#31.0#2.0#2.0#1.0#1.0#// TODO: handle exception#52991087d7eb4a160d14f7d7193ae877777ff51a#Moved 3 classes into the new package and added a Plugin property editor.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/DirectoryListTableModel.java#formatFileSize(double)#654f33b2f16afa399586d0c69e0d0fd1665656db#2004-05-20 03:58:08#698014826a4549b23726f0069aa754e7485ffbce#2004-11-29 01:33:27#-1#3.0#3.0#2.0#2.0#10.0#10.0#3.0#3.0#1.0#1.0#// TODO format should come from a preference model#654f33b2f16afa399586d0c69e0d0fd1665656db#This model can now be poplutated and cleared of FileObjects, and can render the details of the correctly.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/DirectoryListTableModel.java#isSortable(int)#131bc4d7010ed8aef9af2aa03839f8852f3d704d#2004-05-21 04:23:23#698014826a4549b23726f0069aa754e7485ffbce#2004-11-29 01:33:27#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#//        TODO should all columns be sorted?  I think so...#131bc4d7010ed8aef9af2aa03839f8852f3d704d#Implemented SortTableModel for extra sort goodness.  Hmmm... Sortable...#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/VFSNode.java#toString()#e95b32c28f38b2b41972ae0eb1cbb23cbdccdba4#2004-05-19 00:11:08#e95b32c28f38b2b41972ae0eb1cbb23cbdccdba4#2004-05-19 00:11:08#-1#0.0#0.0#2.0#2.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO display name, but with Schema too#e95b32c28f38b2b41972ae0eb1cbb23cbdccdba4#VFSPlugin now looking a bit better, although still no actual functionality yet#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing the Class would be nicer, except that serialized // classed can not be read back by JDK 1.1.x. We have to resort // to this hack instead.#b702f7145d3f660ac350ec862df9e8e913c1fffa#Changed LoggingEvent fields to be either private or public final instead of all public.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#2001-01-22 10:57:29#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing directly the Class object would be nicer, except that // serialized a Class object can not be read back by JDK // 1.1.x. We have to resort to this hack instead.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.##
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#readLevel(ObjectInputStream)#21c50bd181a2b62ade54f2ab926b2da30bc23311#2002-05-09 15:43:44#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#7.0#7.0#11.0#11.0#29.0#29.0#4.0#4.0#3.0#3.0#// Note that we use Class.getDeclaredMethod instead of // Class.getMethod. This assumes that the Level subclass // implements the toLevel(int) method which is a // requirement. Actually, it does not make sense for Level // subclasses NOT to implement this method. Also note that // only Level can be subclassed and not Priority.#21c50bd181a2b62ade54f2ab926b2da30bc23311#Added support for resursive variable substitution in OptionConverter.java.##
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#getMDC(String)#abbd9d3d8b7b16aa02f45679753c1e20886bc49f#2006-01-24 03:50:12#719d93cd529c1f406668242393ff188d7ae77025#2007-07-18 05:06:07#-1#2.0#3.0#3.0#3.0#13.0#13.0#3.0#3.0#2.0#2.0#// //  could potentially return a LoggerRepository property value //     when there is not an MDC property value //     but the negative consequences should be minimal.#abbd9d3d8b7b16aa02f45679753c1e20886bc49f#Bug 35452: Restored o.a.l.spi.LoggingEvent.getMDC and getMDCCopy#612f6287fda8178626ba6625b257c790f65de5f8#Bug 42108: Add event.getLogger to allow cloning events
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/VFSPlugin.java#determineSupportedFileSystems()#e7a45e09af8c6312a340f607b1425453e5284d7d#2004-05-15 06:31:48#b15088714356b450ae81f8faf51975f10b5eebb8#2004-05-19 06:12:46#-1#4.0#4.0#5.0#5.0#17.0#17.0#4.0#4.0#3.0#3.0#//    TODO This seems really lame to have to do this, but there you go...#e7a45e09af8c6312a340f607b1425453e5284d7d#Shell classes for the portion of the VFS GUI plugni that could be started.#82f3ef43d7678ac66d6218bbebe1f613b8f75f9a#Thanks to Mario of the VFS team, no longer have to manually work out what VFS schemes are available on the class path.  Much cleaner!  Thanks Mario.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/VFSPlugin.java#loadLocalFileSystem()#ae5a19796d81ba878d522fa09787980f9924636e#2004-05-20 23:13:50#ae5a19796d81ba878d522fa09787980f9924636e#2004-05-20 23:13:50#-1#4.0#4.0#5.0#5.0#15.0#15.0#2.0#2.0#1.0#1.0#// TODO replace this with an explicit call to pre-select the firs node in the tree, which // would then trigger the look for children //VFSUtils.lookForChildren(this.fileSystemTree.getTree(), node);#ae5a19796d81ba878d522fa09787980f9924636e#child directories are now located 'lazily', that is, only when you explicitly select the folder in the tree.  This defers the cost of finding out the children until you need it, making the gui much snappier.#e158902f9ab222b4ef4afc1fac5269d7f24fb1bd#If the user has elected to auto load all the local file systems, we should honour that.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/VFSPlugin.java#valueChanged(TreeSelectionEvent)#ae5a19796d81ba878d522fa09787980f9924636e#2004-05-20 23:13:50#698014826a4549b23726f0069aa754e7485ffbce#2004-11-29 01:33:27#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO this method will NEVER remove the children and repopulates if the node already has // children, be nice to find out // whether VFS can help determine whether it should 'relook' for changes or something.#ae5a19796d81ba878d522fa09787980f9924636e#child directories are now located 'lazily', that is, only when you explicitly select the folder in the tree.  This defers the cost of finding out the children until you need it, making the gui much snappier.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/vfs/VFSPlugin.java#initMenus()#a06357e45797002cb00c6c23590b20f68665c149#2004-05-22 08:06:35#698014826a4549b23726f0069aa754e7485ffbce#2004-11-29 01:33:27#-1#5.0#5.0#5.0#5.0#14.0#14.0#1.0#1.0#0.0#0.0#//        TODO Work out WTF is going on with this PopupListener not being // picked up.... //        TODO Work out WTF is going on with the split pane and the setVisible // like it used to do in LogPanel#a06357e45797002cb00c6c23590b20f68665c149#Note: Eclipse M9 did more formatting to this file than I would have liked...#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/db/DBAppender2.java#fillEventIDArray(Connection,Statement)#ce1a5b525e7b67ab216b383b66e3f32372cc0f69#2004-05-26 15:36:18#b57664eedb4fcb798910b31cf7986e185f0c1cc9#2005-01-04 12:51:20#-1#5.0#5.0#14.0#13.0#32.0#32.0#4.0#4.0#2.0#2.0#// TODO CG better errorHandling code here // no point in continuing#ce1a5b525e7b67ab216b383b66e3f32372cc0f69#- Added db2 sql script for table creation. - Improved docs. - DBAppender2 uses batched updates using the getGeneratedKeys method. However, this does not work correctly on PostgreSQL nor MySQL.#d0edd1a0f5acc79749f07445528b5366c380cfcc#Removing unused DBAppender2
log4j#DESIGN#src/java/org/apache/log4j/rolling/SlidingWindowRollingPolicy.java#rollover(File)#2046d0782fcec9b8c00f96f8bb6f4364239cf42e#2003-05-14 18:20:28#abb0a73e829f759efc325177b534aa6b5e746b1d#2003-05-19 12:19:37#-1#4.0#4.0#4.0#4.0#29.0#29.0#5.0#5.0#2.0#2.0#//move active file name to min // TODO: compress the currently active file into minIndex#2046d0782fcec9b8c00f96f8bb6f4364239cf42e#Work in progress#579d6f525526f317fa3cccd4bf8cbf11e8023361#Added compression capatiblity while rolling over files
log4j#DESIGN#src/java/org/apache/log4j/rolling/SlidingWindowRollingPolicy.java#rollover(File)#2046d0782fcec9b8c00f96f8bb6f4364239cf42e#2003-05-14 18:20:28#12333c9f2eeddb0dbd34c24a21fee4e70b60d514#2003-05-17 14:30:03#-1#4.0#4.0#4.0#4.0#29.0#29.0#5.0#5.0#2.0#2.0#// TODO: compress the currently active file (minIndex) into minIndex+1#2046d0782fcec9b8c00f96f8bb6f4364239cf42e#Work in progress#abb0a73e829f759efc325177b534aa6b5e746b1d#Adding compression code and more tests
log4j#DESIGN#src/java/org/apache/log4j/rolling/SlidingWindowRollingPolicy.java#rollover()#abb0a73e829f759efc325177b534aa6b5e746b1d#2003-05-19 12:19:37#abb0a73e829f759efc325177b534aa6b5e746b1d#2003-05-19 12:19:37#-1#4.0#4.0#4.0#4.0#29.0#29.0#5.0#5.0#2.0#2.0#// TODO: compress the currently active file (minIndex) into minIndex+1 //Util.rename( //fileNamePattern.convert(minIndex), //fileNamePattern.convert(minIndex + 1));#abb0a73e829f759efc325177b534aa6b5e746b1d#Adding compression code and more tests#579d6f525526f317fa3cccd4bf8cbf11e8023361#Added compression capatiblity while rolling over files
log4j#DESIGN#src/java/org/apache/log4j/rolling/SlidingWindowRollingPolicy.java#getActiveFileName()#559f0829327009ee2d5172011d18056827ff8f62#2004-11-23 16:30:14#8a1825f5b7d01f2d4ebc198a342ac78b267fa2ff#2004-11-25 19:06:27#-1#2.0#2.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO This is clearly bogus.#559f0829327009ee2d5172011d18056827ff8f62#- Refactoring and simplifications of various rolling policies - Slightly better docs#e6d0c5a232e2d63de06f5b588cf7c1837141b78a#- Renamed SlidingWindowRollingPolicy as FixedWindowRollingPolicy. - Improved documentation for FixedWindowRollingPolicy.
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing the Class would be nicer, except that serialized // classed can not be read back by JDK 1.1.x. We have to resort // to this hack instead.#b702f7145d3f660ac350ec862df9e8e913c1fffa#Changed LoggingEvent fields to be either private or public final instead of all public.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#2001-01-22 10:57:29#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing directly the Class object would be nicer, except that // serialized a Class object can not be read back by JDK // 1.1.x. We have to resort to this hack instead.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.##
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#readLevel(ObjectInputStream)#21c50bd181a2b62ade54f2ab926b2da30bc23311#2002-05-09 15:43:44#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#7.0#9.0#11.0#13.0#29.0#41.0#4.0#8.0#3.0#3.0#// Note that we use Class.getDeclaredMethod instead of // Class.getMethod. This assumes that the Level subclass // implements the toLevel(int) method which is a // requirement. Actually, it does not make sense for Level // subclasses NOT to implement this method. Also note that // only Level can be subclassed and not Priority.#21c50bd181a2b62ade54f2ab926b2da30bc23311#Added support for resursive variable substitution in OptionConverter.java.##
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#getMDC(String)#abbd9d3d8b7b16aa02f45679753c1e20886bc49f#2006-01-24 03:50:12#719d93cd529c1f406668242393ff188d7ae77025#2007-07-18 05:06:07#-1#2.0#3.0#3.0#3.0#13.0#13.0#3.0#3.0#2.0#2.0#// //  could potentially return a LoggerRepository property value //     when there is not an MDC property value //     but the negative consequences should be minimal.#abbd9d3d8b7b16aa02f45679753c1e20886bc49f#Bug 35452: Restored o.a.l.spi.LoggingEvent.getMDC and getMDCCopy#612f6287fda8178626ba6625b257c790f65de5f8#Bug 42108: Add event.getLogger to allow cloning events
log4j#DESIGN#src/java/org/apache/log4j/lf5/viewer/LogTable.java#setDetailedView()#092e79cd773f99af3a934f93d4c1841889e3f168#2002-04-26 15:48:44#092e79cd773f99af3a934f93d4c1841889e3f168#2002-04-26 15:48:44#-1#4.0#4.0#4.0#4.0#14.0#14.0#3.0#3.0#1.0#1.0#//TODO: Defineable Views.#092e79cd773f99af3a934f93d4c1841889e3f168#The paperwork for the donation of LogFactor5 is now complete and we are ready to add LogFactor5 source code to our CVS repository.#eddf09c6b65dc0f075da20eaac99e8416caeb646#Removed lf5.
log4j#DESIGN#src/java/org/apache/log4j/xml/DOMConfigurator.java#findAppenderByReference(Element)#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#2000-12-19 13:14:10#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#5.0#4.0#14.0#12.0#35.0#35.0#5.0#6.0#3.0#3.0#// Endre's hack:#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#Removed the dependence on DOM Level 2 due to a patch submited by Endre St�lsvik <Endre@Stolsvik.com>.##
log4j#DESIGN#src/java/org/apache/log4j/xml/DOMConfigurator.java#findAppenderByReference(Element)#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#2000-12-19 13:14:10#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#5.0#4.0#14.0#12.0#35.0#35.0#5.0#6.0#3.0#3.0#// Hack finished.#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#Removed the dependence on DOM Level 2 due to a patch submited by Endre St�lsvik <Endre@Stolsvik.com>.##
log4j#DESIGN#src/java/org/apache/log4j/xml/DOMConfigurator.java#findAppenderByName(Document,String)#75b7ee81d5490aeb1104707c39e4d4d89491cd78#2003-06-03 18:44:18#8128cd4763152944b6c4a2e8e0a1859aa969b79b#2005-01-06 17:03:12#-1#4.0#4.0#12.0#12.0#38.0#38.0#5.0#5.0#3.0#3.0#// Doesn't work on DOM Level 1 : // Element element = doc.getElementById(appenderName); // Endre's hack:#75b7ee81d5490aeb1104707c39e4d4d89491cd78#Reformatted with Jalopy. No other changes.#2816a0b6f858c8bd56a6f0556c0d3573e7bf7262#Removed all members fields of type Logger in accordance with the internal logging guidelines.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ColorFilter.java#getColor(List,LoggingEvent)#1672b02eb269209e396ac6db0d5f8cb5454397b7#2003-09-03 05:47:27#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#-1#1.0#1.0#1.0#1.0#26.0#26.0#1.0#1.0#0.0#0.0#//    TODO this is broken while the change from Vectors -> LoggingEvents occurs //    Iterator iter = filters.iterator(); //#1672b02eb269209e396ac6db0d5f8cb5454397b7#Forced to comment out some code here while we refactor the model.#ac9e0003d5766df2f9f5b4052e3dd968911bd4fc#* Re-implemented support for 'refine focus on' text field on the log panel * Added support for multiple-word operands in expression rules (enclose operand in single quotes * New colorpanel layout with drop down color list and browse button - much smaller layout * Added mouse support for setting and adding event fields to the refine focus rule.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/XMLFileHandler.java#endElement(String,String,String)#587e14ed6c4ffd37b73773e1abfdce5a2c75fe7e#2002-03-23 07:51:26#2150b43b6b6dc27cdeae47c7a0022eac889f7e5b#2002-05-02 11:25:49#-1#3.0#3.0#4.0#4.0#11.0#11.0#3.0#3.0#1.0#1.0#// hack - but only thing I care about#587e14ed6c4ffd37b73773e1abfdce5a2c75fe7e#First version of Chainsaw based on version 1.1. The changes made were: - Change the package name - Change the license to Apache - Remove the startup sound - Remove the test generator class - Change the email address for the author.#3b8592f75e673c39e84fd96ed991976a76234740#PR: 9268 Fixed the bug in the code that loads events from an XML file. The code now correctly handles multiple calls to characters(). Tested with Crimson and Xerces under JDK1.3.1 and JDK1.4. Also fixed Checkstyle errors.
log4j#DESIGN#src/java/org/apache/log4j/test/Shallow.java#test()#4e7121c85b7353a8dff17f7669c270ad963763a6#2000-12-14 09:16:58#be2ce23479bb3da85a14482d81443217f1bf3d6e#2001-01-18 17:25:35#-1#3.0#3.0#9.0#8.0#43.0#40.0#1.0#1.0#0.0#0.0#// It is always a good idea to call this method when exiting an // application.#4e7121c85b7353a8dff17f7669c270ad963763a6#initial log4j commit on Apache#09bc0dcbccc3225cfadc2ca0024b4015ed8f684e#Corrected path to match the new src/java source dir.
log4j#DESIGN#src/java/org/apache/log4j/test/Shallow.java#test()#4e7121c85b7353a8dff17f7669c270ad963763a6#2000-12-14 09:16:58#5effc7da57ace6080eb78f33d5c22ed7af09ae02#2001-09-25 10:06:36#-1#3.0#2.0#9.0#7.0#43.0#15.0#1.0#1.0#0.0#0.0#// It is always a good idea to call this method when exiting an // application.#4e7121c85b7353a8dff17f7669c270ad963763a6#initial log4j commit on Apache#c5619e90f1e3147c57566713b8f9b0ae02d05e74#Removing some custom logger tests. They will be added later under the tests/ directory.
log4j#DESIGN#src/java/org/apache/log4j/gui/TextPaneAppender.java#append(LoggingEvent)#947517357402f5ff3800d18c8106c52533c91e09#2000-12-14 09:35:59#3b3a3c2e3d12185cc35039a758a4940b91a74ee0#2001-03-19 12:38:22#-1#12.0#12.0#15.0#15.0#28.0#28.0#6.0#6.0#3.0#3.0#// Print Stacktrace // Quick Hack maybe there is a better/faster way?#947517357402f5ff3800d18c8106c52533c91e09#initial log4j commit on Apache#1bd2457e52fc19f621a7d577fe896bfb98561004#Removed unused gui stuff.
log4j#DESIGN#tests/src/java/org/apache/log4j/pattern/CachedDateFormatTest.java#test17()#17fa629e45d0dcd55b81edb34286e8c675a0bfd4#2004-12-24 09:08:51#9de98b292a27632b5ca9908c933101ef7ea4a1ec#2010-03-27 06:10:02#-1#1.0#1.0#7.0#7.0#19.0#19.0#1.0#1.0#0.0#0.0#// //  TODO: why is this returning ,120 ... , 120 // //assertEquals("00:00:00,120 00:00:00,000", s) ;#17fa629e45d0dcd55b81edb34286e8c675a0bfd4#Bug 32064: Added pattern check and incomplete test for multiple SSS patterns##
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/XMLFileHandler.java#endElement(String,String,String)#587e14ed6c4ffd37b73773e1abfdce5a2c75fe7e#2002-03-23 07:51:26#2150b43b6b6dc27cdeae47c7a0022eac889f7e5b#2002-05-02 11:25:49#-1#3.0#3.0#4.0#4.0#11.0#11.0#3.0#3.0#1.0#1.0#// hack - but only thing I care about#587e14ed6c4ffd37b73773e1abfdce5a2c75fe7e#First version of Chainsaw based on version 1.1. The changes made were: - Change the package name - Change the license to Apache - Remove the startup sound - Remove the test generator class - Change the email address for the author.#3b8592f75e673c39e84fd96ed991976a76234740#PR: 9268 Fixed the bug in the code that loads events from an XML file. The code now correctly handles multiple calls to characters(). Tested with Crimson and Xerces under JDK1.3.1 and JDK1.4. Also fixed Checkstyle errors.
log4j#DESIGN#src/java/org/apache/log4j/lf5/viewer/LogTable.java#setDetailedView()#092e79cd773f99af3a934f93d4c1841889e3f168#2002-04-26 15:48:44#eb94ecb378be47166e3ef8cb4ca9e134600af442#2009-10-11 20:58:26#-1#4.0#4.0#4.0#4.0#14.0#14.0#3.0#3.0#1.0#1.0#//TODO: Defineable Views.#092e79cd773f99af3a934f93d4c1841889e3f168#The paperwork for the donation of LogFactor5 is now complete and we are ready to add LogFactor5 source code to our CVS repository.#697be9a5b21445cf658e8a39c1178474c467a175#removed obsolete packages lf5 and chainsaw 1
log4j#DESIGN#contribs/JamesHouse/TextPanelAppender.java#append(LoggingEvent)#5095ca00abeb4c0dc66967f3baa1563734ea4d94#2001-02-14 17:47:01#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#7.0#7.0#10.0#10.0#21.0#21.0#5.0#5.0#3.0#3.0#// Print Stacktrace // Quick Hack maybe there is a better/faster way?#5095ca00abeb4c0dc66967f3baa1563734ea4d94#Contribs by various authors.##
log4j#DESIGN#contribs/KitchingSimon/DatagramStringWriter.java#write(String)#5095ca00abeb4c0dc66967f3baa1563734ea4d94#2001-02-14 17:47:01#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#7.0#7.0#3.0#3.0#37.0#37.0#4.0#4.0#1.0#1.0#// convert to specified encoding - which may be sequence of // 8-bit chars, or multi-byte encodings like UTF-8 or UTF-16. // The receiving end had better be expecting whatever encoding // is used here on the sending end!#5095ca00abeb4c0dc66967f3baa1563734ea4d94#Contribs by various authors.##
log4j#DESIGN#contribs/LeosLiterak/TempFileAppender.java#subAppend(LoggingEvent)#dc0124d2cb6e285149532d4e9a57c157f5032270#2001-04-20 17:38:32#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#8.0#8.0#4.0#4.0#11.0#11.0#2.0#2.0#1.0#1.0#/* this Appender is not supposed to be used for logging of Exceptions */#dc0124d2cb6e285149532d4e9a57c157f5032270#Added LeosLiterak's TempFileAppender.java##
log4j#DESIGN#contribs/SvenReimers/gui/TextPaneAppender.java#append(LoggingEvent)#947517357402f5ff3800d18c8106c52533c91e09#2000-12-14 09:35:59#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#12.0#12.0#15.0#15.0#28.0#28.0#6.0#6.0#3.0#3.0#// Print Stacktrace // Quick Hack maybe there is a better/faster way?#947517357402f5ff3800d18c8106c52533c91e09#initial log4j commit on Apache##
log4j#DESIGN#src/java/org/apache/log4j/concurrent/ConcurrentAppender.java#doAppend(LoggingEvent)#3d30346f59a79ced396bbcaf6acb3624a7cb27ad#2006-07-27 13:37:06#94eff9a041300970516ea866f8f0420d1cc75355#2007-01-26 05:44:59#-1#7.0#8.0#11.0#14.0#43.0#45.0#6.0#7.0#3.0#3.0#// Prevent concurrent re-entry by this thread // (There might be a cheaper way to do this) // (Or maybe this lock is not necessary)#3d30346f59a79ced396bbcaf6acb3624a7cb27ad#Bug 24159: Migrate concurrent package from sandbox to trunk#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/helpers/IntializationUtil.java#log4jInternalConfiguration(LoggerRepository)#3605f1464cd0ddde0bca8aa270fbe6e6e63edaaa#2004-11-16 20:29:44#c23b6c602d21d74d9b03a9cf97a2385e78e9a027#2006-01-02 05:10:42#-1#3.0#2.0#0.0#0.0#10.0#10.0#1.0#1.0#0.0#0.0#// This method does not do anoything currently. It might become useful // when sub-domains are added to log4j.#3605f1464cd0ddde0bca8aa270fbe6e6e63edaaa#Self-logigng in log4j.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/joran/JoranConfigurator.java#detachListAppender(LoggerRepository)#3605f1464cd0ddde0bca8aa270fbe6e6e63edaaa#2004-11-16 20:29:44#3605f1464cd0ddde0bca8aa270fbe6e6e63edaaa#2004-11-16 20:29:44#-1#5.0#5.0#19.0#19.0#30.0#30.0#4.0#4.0#2.0#2.0#// FIXME: What happens if the users wanted to set the additivity flag // to false in the config file? We are now potentially overriding her  // wishes but I don't see any other way.#3605f1464cd0ddde0bca8aa270fbe6e6e63edaaa#Self-logigng in log4j.#5ce8c4d34da5f4ff1dff4092589833e8fa6c56a9#LogLog to Logger
log4j#DESIGN#src/java/org/apache/log4j/net/MulticastAppender.java#isActive()#ad3450477a77a963b46c8c563e7c857e85a994ce#2003-06-24 08:24:57#696ca5278150b8ca6ae726c36e477e3e819280e5#2007-04-11 06:04:46#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO handle active/inactive#ad3450477a77a963b46c8c563e7c857e85a994ce#moving to jakarta-log4j from jakarta-log4j-sandbox.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/net/UDPAppender.java#isActive()#ad3450477a77a963b46c8c563e7c857e85a994ce#2003-06-24 08:24:57#e7ec8973dc4c7618cd9dab379e2a5426a1292e40#2004-05-27 12:16:58#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO handle active/inactive#ad3450477a77a963b46c8c563e7c857e85a994ce#moving to jakarta-log4j from jakarta-log4j-sandbox.#a18b74108260ddfa7ca6e13ce8400dcbfe29b68a#In UDPAppedner, removed code related to the connector thread. Also removed the needless padding/trimming.
log4j#DESIGN#src/java/org/apache/log4j/FileAppender.java#closeFile()#4649eee6fc9a5efa1253be942d21a239b2a71227#2001-02-20 08:05:12#db451258c9d7f8724d6543c8c02b786b6abdee79#2001-08-13 15:12:10#-1#5.0#8.0#2.0#2.0#13.0#13.0#3.0#3.0#2.0#2.0#// FIXME (remove qwIsOurs)#4649eee6fc9a5efa1253be942d21a239b2a71227#FileAppender remains backward compatible.#ebc274ee0733441ed2acb2a401c059020e7fe1b3#Added MDC support in AsyncAppender.
log4j#DESIGN#src/java/org/apache/log4j/db/DBAppender.java#close()#db66be54dea271c9ecfd6f6426f7229fe9f2aeba#2004-05-04 09:36:03#130b3181d10b8f89ee785ff0a0e608b9c3001ca3#2004-05-21 18:45:07#-1#0.0#0.0#0.0#0.0#3.0#3.0#1.0#1.0#0.0#0.0#// TODO Auto-generated method st  #db66be54dea271c9ecfd6f6426f7229fe9f2aeba#An initial draft of DBAppender. It seems to work on MySQL and PostgreSQL using the URLConnectionSource#1cd511911f8ee040913c26e6b130791eb635a65f#- Added support for the JDBC 3.0 getGeneratedKeys function which if supported by the JDC driver obsoletes the need for a RDBMS specific SQLDialect.
log4j#DESIGN#src/java/org/apache/log4j/spi/location/StackTraceElementExtractor.java#setClassName(LocationInfo,Object)#31836fb3952ef3022b72bf346adea8164473c5e3#2004-09-07 18:58:42#31836fb3952ef3022b72bf346adea8164473c5e3#2004-09-07 18:58:42#-1#4.0#4.0#2.0#2.0#6.0#6.0#2.0#2.0#1.0#1.0#// this should work, shouldn't it?#31836fb3952ef3022b72bf346adea8164473c5e3#Added a new location info extraction mechanism based on Martin Shutlz' code. See http://marc.theaimsgroup.com/?t=108473346700001&r=1&w=2 for details.#ff26b789d2f1613c5180772dd9fa3efc420a7547#- Ensuring that test cases run correctly. - Fixed problem with null return values in LocationInfo and StackElementExtractor. - Fixed problem deferred logging in o.a.l.varia.ListAppender
log4j#DESIGN#src/java/org/apache/log4j/db/DBReceiver.java#execute()#42f1290ae7de2687560d1f850fd8dc21eb09d7f2#2004-05-10 19:38:58#d3e24380fcf1c3da74989bda23aa8a0afa0092a3#2004-05-21 16:13:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// TODO CG The conversion of levelStr should be more general#42f1290ae7de2687560d1f850fd8dc21eb09d7f2#Added support for receiving events from a db.#130b3181d10b8f89ee785ff0a0e608b9c3001ca3#- In order to avoid having DBReceiver depend on vhainsaw, moved the LOG4J_ID_KEY from ChainsawConstants to o.a.l.helpers.Constants interface.
log4j#DESIGN#src/java/org/apache/log4j/db/DBReceiverJob.java#execute()#130b3181d10b8f89ee785ff0a0e608b9c3001ca3#2004-05-21 18:45:07#696ca5278150b8ca6ae726c36e477e3e819280e5#2007-04-11 06:04:46#-1#9.0#10.0#34.0#33.0#94.0#68.0#7.0#7.0#3.0#3.0#// TODO CG The conversion of levelStr should be more general#130b3181d10b8f89ee785ff0a0e608b9c3001ca3#- In order to avoid having DBReceiver depend on vhainsaw, moved the LOG4J_ID_KEY from ChainsawConstants to o.a.l.helpers.Constants interface.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/concurrent/WriterPreferenceReadWriteLock.java#startReadFromNewReader()#94eff9a041300970516ea866f8f0420d1cc75355#2007-01-26 05:44:59#94eff9a041300970516ea866f8f0420d1cc75355#2007-01-26 05:44:59#-1#2.0#2.0#3.0#3.0#5.0#5.0#2.0#2.0#1.0#1.0#/* log4j,     Each of these variants is needed to maintain atomicitylog4j,     of wait counts during wait loops. They could belog4j,     made faster by manually inlining each other. We hope thatlog4j,     compilers do this for us though.log4j,  */#94eff9a041300970516ea866f8f0420d1cc75355#Bug 19004 - Add concurrent rolling appender and tests. Use a reentrant read/write lock instead of plain RW lock. Add package.html file#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/concurrent/WriterPreferenceReadWriteLock.java#acquire()#94eff9a041300970516ea866f8f0420d1cc75355#2007-01-26 05:44:59#94eff9a041300970516ea866f8f0420d1cc75355#2007-01-26 05:44:59#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// fall through outside synch on interrupt. // This notification is not really needed here,  //   but may be in plausible subclasses#94eff9a041300970516ea866f8f0420d1cc75355#Bug 19004 - Add concurrent rolling appender and tests. Use a reentrant read/write lock instead of plain RW lock. Add package.html file#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/xml/DOMConfigurator.java#findAppenderByReference(Element)#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#2000-12-19 13:14:10#e6aade6f7feefd92fbdce88df52f5c0f47387c34#2007-04-27 19:53:38#-1#5.0#4.0#14.0#12.0#35.0#33.0#5.0#5.0#3.0#3.0#// Endre's hack:#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#Removed the dependence on DOM Level 2 due to a patch submited by Endre St�lsvik <Endre@Stolsvik.com>.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/xml/DOMConfigurator.java#findAppenderByReference(Element)#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#2000-12-19 13:14:10#e6aade6f7feefd92fbdce88df52f5c0f47387c34#2007-04-27 19:53:38#-1#5.0#4.0#14.0#12.0#35.0#33.0#5.0#5.0#3.0#3.0#// Hack finished.#d5d9779ebba5f8bb25a2d1cf1df0312153e1f955#Removed the dependence on DOM Level 2 due to a patch submited by Endre St�lsvik <Endre@Stolsvik.com>.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/FileAppender.java#closeFile()#4649eee6fc9a5efa1253be942d21a239b2a71227#2001-02-20 08:05:12#db451258c9d7f8724d6543c8c02b786b6abdee79#2001-08-13 15:12:10#-1#5.0#8.0#2.0#2.0#13.0#13.0#3.0#3.0#2.0#2.0#// FIXME (remove qwIsOurs)#4649eee6fc9a5efa1253be942d21a239b2a71227#FileAppender remains backward compatible.#ebc274ee0733441ed2acb2a401c059020e7fe1b3#Added MDC support in AsyncAppender.
log4j#DESIGN#src/java/org/apache/log4j/rolling/FixedWindowRollingPolicy.java#getActiveFileName()#e6d0c5a232e2d63de06f5b588cf7c1837141b78a#2004-12-08 15:33:23#532c5ca2102386382f099e4920e93ec9f29f49bb#2005-05-22 07:57:07#-1#1.0#2.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO This is clearly bogus.#e6d0c5a232e2d63de06f5b588cf7c1837141b78a#- Renamed SlidingWindowRollingPolicy as FixedWindowRollingPolicy. - Improved documentation for FixedWindowRollingPolicy.#0cf5cda0dc3b4560a71807fcbd80bade1e2c40a8#Bug 34979: rolling refactoring, asynchronous compression
log4j#DESIGN#src/java/org/apache/log4j/HTMLLayout.java#escapeHTMLTags(String)#b47560410ce7c66fb139031057ad594dfcba04f2#2001-04-29 13:48:59#a97e7224ded6c3f94fccd4d3670b1f46af539705#2002-04-24 01:16:14#-1#3.0#3.0#5.0#5.0#28.0#28.0#5.0#5.0#2.0#2.0#//Use a StringBuffer in lieu of String concatenation -- it is //much more efficient this way.#b47560410ce7c66fb139031057ad594dfcba04f2#Nicer layout, now escapes HTML tags (< and >), and uses Layout.LINE_SEP#dc4f1e77bef3185fffaf264a005f744e38696ae1#Fixed bug 7550 in XMLLayout.
log4j#DESIGN#src/java/org/apache/log4j/net/SocketHubAppender.java#append(LoggingEvent)#1a29e3ec91205f488d5ad379ecf61282a520bb2c#2002-03-25 22:05:36#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#3.0#3.0#8.0#8.0#45.0#45.0#7.0#7.0#2.0#2.0#// catch this, but just don't assign a value // this should not really occur as this method is // the only one that can remove oos's (besides cleanUp).#1a29e3ec91205f488d5ad379ecf61282a520bb2c#Added SocketHubAppender as supplied by Mark Womack. Renamed the package of JDBCAppender#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/net/SocketHubAppender.java#append(LoggingEvent)#1a29e3ec91205f488d5ad379ecf61282a520bb2c#2002-03-25 22:05:36#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#3.0#3.0#8.0#8.0#45.0#45.0#7.0#7.0#2.0#2.0#// Failing to reset the object output stream every now and // then creates a serious memory leak. // right now we always reset. TODO - set up frequency counter per oos?#1a29e3ec91205f488d5ad379ecf61282a520bb2c#Added SocketHubAppender as supplied by Mark Womack. Renamed the package of JDBCAppender#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/helpers/BoundedFIFO.java#resize(int)#80387e1d3e02134a8e24cb7d81b1ae6a7b3b6113#2001-01-23 22:07:43#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#10.0#9.0#7.0#7.0#36.0#36.0#4.0#4.0#1.0#1.0#// er.. how much do we actually need to copy? // We should not copy more than the actual number of elements.#80387e1d3e02134a8e24cb7d81b1ae6a7b3b6113#Added the BufferSize option to the AsyncAppender and updated UnitTestBoundedFIFO to test this new feature.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/NDC.java#lazyRemove()#26f8d8a8cd3f272b3fa5d912889207c64844aa61#2000-12-14 02:19:28#68d68c3b312fb0fb6ccf4dc30f4a2e59d6d5ef94#2004-09-01 17:10:52#-1#4.0#3.0#3.0#11.0#32.0#41.0#3.0#5.0#1.0#2.0#// The synchronization on ht is necessary to prevent JDK 1.2.x from // throwing ConcurrentModificationExceptions at us. This sucks BIG-TIME. // One solution is to write our own hashtable implementation.#26f8d8a8cd3f272b3fa5d912889207c64844aa61#initial Apache commit#3ee1b6521cba8b30b0b534a6b44a51a95c3ecf58#New sandbox home for log4jMini
log4j#DESIGN#src/java/org/apache/log4j/NDC.java#lazyRemove()#26f8d8a8cd3f272b3fa5d912889207c64844aa61#2000-12-14 02:19:28#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#4.0#3.0#3.0#11.0#32.0#42.0#3.0#6.0#1.0#2.0#// The synchronization on ht is necessary to prevent JDK 1.2.x from // throwing ConcurrentModificationExceptions at us. This sucks BIG-TIME. // One solution is to write our own hashtable implementation.#26f8d8a8cd3f272b3fa5d912889207c64844aa61#initial Apache commit#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#b702f7145d3f660ac350ec862df9e8e913c1fffa#2001-01-20 16:02:22#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing the Class would be nicer, except that serialized // classed can not be read back by JDK 1.1.x. We have to resort // to this hack instead.#b702f7145d3f660ac350ec862df9e8e913c1fffa#Changed LoggingEvent fields to be either private or public final instead of all public.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#writePriority(ObjectOutputStream)#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#2001-01-22 10:57:29#c6b4fcb791c4d0f46974a1515f317858e6eeab55#2007-04-21 03:46:53#-1#4.0#4.0#5.0#5.0#14.0#14.0#2.0#2.0#1.0#1.0#// writing directly the Class object would be nicer, except that // serialized a Class object can not be read back by JDK // 1.1.x. We have to resort to this hack instead.#2586dda3d3d2d78414119dd9c49a734ce1b5a8d2#Changed LoggingEvent to let Appenders/Layouts to access the raw message object. The old message field is now called renderedMessage. Also added a new category field.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/spi/LoggingEvent.java#readLevel(ObjectInputStream)#21c50bd181a2b62ade54f2ab926b2da30bc23311#2002-05-09 15:43:44#c6b4fcb791c4d0f46974a1515f317858e6eeab55#2007-04-21 03:46:53#-1#7.0#7.0#11.0#11.0#29.0#29.0#4.0#4.0#3.0#3.0#// Note that we use Class.getDeclaredMethod instead of // Class.getMethod. This assumes that the Level subclass // implements the toLevel(int) method which is a // requirement. Actually, it does not make sense for Level // subclasses NOT to implement this method. Also note that // only Level can be subclassed and not Priority.#21c50bd181a2b62ade54f2ab926b2da30bc23311#Added support for resursive variable substitution in OptionConverter.java.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/helpers/Loader.java#getResource(String)#caa8e432af35512216b58492e3d8499f7262e109#2001-10-11 15:10:21#e4bb5e96052e534613fcd43f74efba6e12339d32#2007-02-23 17:48:53#-1#4.0#5.0#8.0#7.0#39.0#40.0#6.0#7.0#4.0#4.0#// We could not find resource. Ler us now try with the // classloader that loaded this class.#caa8e432af35512216b58492e3d8499f7262e109#Search for "resource" using the thread context class loader under Java2. If that fails, search for "resource" using the class loader that loaded this class (Loader). Under JDK 1.1, only the the class loader that loaded this class (Loader) is used.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/test/Shallow.java#test()#4e7121c85b7353a8dff17f7669c270ad963763a6#2000-12-14 09:16:58#ef8533d6c669647b9db34297fd9219e72f698c88#2005-05-24 05:06:25#-1#3.0#3.0#9.0#14.0#43.0#41.0#1.0#1.0#0.0#0.0#// It is always a good idea to call this method when exiting an // application.#4e7121c85b7353a8dff17f7669c270ad963763a6#initial log4j commit on Apache#5acb6467f22f695ff58ff1116943e90eaca679c4#Bug 41373: T113 causes the build to fail
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ChainsawCyclicBufferTableModel.java#run()#c554e534361610b689c2cb81c5492901e948c964#2003-09-03 05:44:51#b11afeb035f8b3bb9489a2a29ef53909254212cd#2003-09-05 03:39:43#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//          TODO change when filtering refactor done.#c554e534361610b689c2cb81c5492901e948c964#Refactor of the model to store LoggingEvents rather than Vectors.#bffbaa46fd83985467185561669576bcf600f501#The model now correctly uses the Rule infrastructure, being notified of Rule change, and able to automatically filter and sort when it does.
log4j#DESIGN#src/java/org/apache/log4j/AppenderSkeleton.java#doAppend(LoggingEvent)#25517ae23def94e51e9c3b77ff3d0089c9279f8e#2005-01-22 18:18:33#25517ae23def94e51e9c3b77ff3d0089c9279f8e#2005-01-22 18:18:33#-1#7.0#7.0#6.0#6.0#47.0#47.0#8.0#8.0#3.0#3.0#// FIXME: We should not flood other appenders but at the same time // should output something meaningful (only once though). // Logging not allowed: //getLogger().error( //  "Attempted to append to closed appender named [{}].", name);#25517ae23def94e51e9c3b77ff3d0089c9279f8e#an appender should not flood other appenders with indiscriminate logging.#7db3e1f0e0bb4c4b77e638df7580b4b8377aeb4a#- Added the isClosed(), activate(), isActive() methods to the Appender interface.
log4j#DESIGN#src/java/org/apache/log4j/AppenderSkeleton.java#activate()#200bdbf75b61b68118ab32bd793ef035846b78f5#2005-03-08 22:32:58#200bdbf75b61b68118ab32bd793ef035846b78f5#2005-03-08 22:32:58#-1#0.0#0.0#1.0#1.0#3.0#3.0#1.0#1.0#0.0#0.0#/**log4j,   *   Synonym for activateOptions.log4j,   *   @deprecated TODO: this weird signature is an attempt to flushlog4j,   * out the remaining uses of activate since mixing activate andlog4j,   * activateOptions can lead to very bad things.log4j,   */#200bdbf75b61b68118ab32bd793ef035846b78f5#Reversion of AppenderInterface per 2005-02-28 vote#9cbe0056df7627bf47b99df046e8b27a101511d3#Removal of last remnants of abandoned renaming to OptionConverter.activate
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ChainsawStatusBar.java#remoteConnectionReceived(String)#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#a3857cf4bd42e788007ca7edadbb80185237a2e0#2004-07-26 07:39:32#-1#3.0#3.0#4.0#6.0#7.0#7.0#1.0#1.0#0.0#0.0#//    TODO and maybe play a sound?#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/helpers/Transform.java#escapeTags(String)#7bd0c413a7902328b3e48de73486b7076ae0efbb#2002-04-26 12:31:42#e6aade6f7feefd92fbdce88df52f5c0f47387c34#2007-04-27 19:53:38#-1#4.0#4.0#5.0#5.0#27.0#27.0#5.0#5.0#2.0#2.0#//Use a StringBuffer in lieu of String concatenation -- it is //much more efficient this way.#7bd0c413a7902328b3e48de73486b7076ae0efbb#Missing file.#8d15fcd9068d1e762b488bfc0d6fec3f0e6671fe#Bug 37930: Move src/java to src/main/java
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ChainsawToolBarAndMenus.java#createShowPreferencesAction()#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#4d735d9762e0acb248f97b2ac7b55a9ec3b0ac23#2005-01-02 09:51:40#-1#2.0#3.0#2.0#6.0#18.0#18.0#1.0#1.0#0.0#0.0#// TODO think of good mnemonics and HotKey for this action#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ChainsawToolBarAndMenus.java#createUndockAction()#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#4d735d9762e0acb248f97b2ac7b55a9ec3b0ac23#2005-01-02 09:51:40#-1#2.0#2.0#2.0#2.0#19.0#19.0#1.0#1.0#0.0#0.0#//	TODO think of some mnemonics and HotKeys for this action#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ChainsawToolBarAndMenus.java#createToolbar()#7bb51aa12cb6f6db2b152a5c83783aba4048d64b#2003-09-02 03:39:16#7bb51aa12cb6f6db2b152a5c83783aba4048d64b#2003-09-02 03:39:16#-1#16.0#16.0#17.0#17.0#77.0#77.0#1.0#1.0#0.0#0.0#//	logTreePaneButton.setText(null); //	TODO add accelerator to this action#7bb51aa12cb6f6db2b152a5c83783aba4048d64b#Changes to menus/toolbar and Log panel so that the Logger Tree can be hidden/shown.#da6f1e2096c5c2ad078fcbc85ca5edcf9b2b369b#Added accelerator to the toggle of the Logger tree (ALT-T), plus updated the Welcome html to reflect that.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/ColumnComparator.java#compare(Object,Object)#d41228cc95ab66bc19e91207f2093bd6cbfd09dc#2003-09-05 04:17:16#130b3181d10b8f89ee785ff0a0e608b9c3001ca3#2004-05-21 18:45:07#-1#13.0#18.0#12.0#19.0#82.0#134.0#20.0#32.0#3.0#4.0#//		TODO not everything catered for here yet...#d41228cc95ab66bc19e91207f2093bd6cbfd09dc#Sorting should now work in the majority of cases now that we're using the native LoggingEvent as the source.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/rolling/helpers/FileNamePatternParser.java#parse()#2633cc86eeae1947fa08d7b907c5030bb4f456a7#2003-05-13 22:32:49#579d6f525526f317fa3cccd4bf8cbf11e8023361#2003-05-19 13:50:10#-1#2.0#2.0#8.0#7.0#53.0#53.0#6.0#6.0#3.0#3.0#// At this stage, we can suppose that i < len -1#2633cc86eeae1947fa08d7b907c5030bb4f456a7#Work in progress on rolling#af97c9ee085a698d9ea3530bc7234b53f969907b#Still work in progress, but progress there is.
log4j#DESIGN#src/java/org/apache/log4j/rolling/helpers/FileNamePattern.java#parse()#af97c9ee085a698d9ea3530bc7234b53f969907b#2003-05-21 19:00:00#2816a0b6f858c8bd56a6f0556c0d3573e7bf7262#2005-01-06 19:27:04#-1#4.0#3.0#9.0#10.0#76.0#71.0#8.0#8.0#4.0#4.0#// At this stage, we can suppose that i < patternLen -1#af97c9ee085a698d9ea3530bc7234b53f969907b#Still work in progress, but progress there is.#532c5ca2102386382f099e4920e93ec9f29f49bb#Bug 34979: Refactor rolling file appenders to use pattern layout parser and converters
log4j#DESIGN#LICENSE.APL#parse()#b883df650806e112982688dd1c4ff3e158c217b5#2000-12-14 01:46:05#3b12c48961f80caeab4b540b40ecfc369c33b18a#2001-07-05 18:12:15#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#// At this stage, we can suppose that i < patternLen -1#b883df650806e112982688dd1c4ff3e158c217b5#initial locus.apache.org commit#54e0894a235cf32342eb9ccc6776b3172c67a65c#Apply excellent patch from Paul Smith. There are numerous checkstyle errors that will need to be fixed at some stage. Also wonder what the best strategy is for the log4j.xml file. Note, I really like the approach for finder strategies.
log4j#DESIGN#src/java/org/apache/log4j/FileAppender.java#closeFile()#4649eee6fc9a5efa1253be942d21a239b2a71227#2001-02-20 08:05:12#db451258c9d7f8724d6543c8c02b786b6abdee79#2001-08-13 15:12:10#-1#5.0#8.0#2.0#2.0#13.0#13.0#3.0#3.0#2.0#2.0#// FIXME (remove qwIsOurs)#4649eee6fc9a5efa1253be942d21a239b2a71227#FileAppender remains backward compatible.#ebc274ee0733441ed2acb2a401c059020e7fe1b3#Added MDC support in AsyncAppender.
log4j#DESIGN#src/java/org/apache/log4j/multiplex/MDCKeySelector.java#activateOptions()#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#2004-10-17 23:24:13#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#2004-10-17 23:24:13#-1#1.0#1.0#0.0#0.0#4.0#4.0#1.0#1.0#0.0#0.0#// TODO ?#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#Committing very _very_ early version of the MultiplexAppender and related paraphernalia.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/FileLoadAction.java#actionPerformed(ActionEvent)#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#d8530a7ba0a823db98022edabcc018e5864ab2a5#2004-09-02 00:30:19#-1#6.0#7.0#12.0#3.0#40.0#22.0#4.0#1.0#2.0#0.0#// TODO Handle the error with a nice msg#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/FileLoadAction.java#actionPerformed(ActionEvent)#b89b60ad7d80a4c800f31f9b4088ebe81b699394#2003-11-20 22:10:19#d8530a7ba0a823db98022edabcc018e5864ab2a5#2004-09-02 00:30:19#-1#5.0#5.0#13.0#11.0#72.0#55.0#7.0#8.0#0.0#3.0#// TODO: handle exception#b89b60ad7d80a4c800f31f9b4088ebe81b699394#added the ability to load remote URLs into Chainsaw#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/multiplex/MultiplexAppender.java#activateOptions()#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#2004-10-17 23:24:13#200bdbf75b61b68118ab32bd793ef035846b78f5#2005-03-08 22:32:58#-1#1.0#1.0#1.0#1.0#13.0#11.0#2.0#2.0#1.0#1.0#// TODO work out how the Selector has it's AppenderFactory configured by Joran#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#Committing very _very_ early version of the MultiplexAppender and related paraphernalia.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/multiplex/MultiplexAppender.java#requiresLayout()#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#2004-10-17 23:24:13#200bdbf75b61b68118ab32bd793ef035846b78f5#2005-03-08 22:32:58#-1#0.0#0.0#1.0#1.0#4.0#4.0#1.0#1.0#0.0#0.0#//        TODO check this is correct#2fefbb9bbeb0a094d22ae551e317e3ab425efed4#Committing very _very_ early version of the MultiplexAppender and related paraphernalia.#719d93cd529c1f406668242393ff188d7ae77025#Bug 37930: Maven build for log4j 1.3
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer(MouseEvent)#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#1296787db5726686701f25ac30bd899bad914d47#2003-07-09 06:10:01#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//          TODO should also tidy up any other references to things... Might need to be able to recover this pane again...#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#ddd173fcdb476c83256f72efa862edfb0275dab5#New 'show tabs' menu added to the 'View' menu.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateDetailPane()#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#cd4524d7e50644d9ea3a7b14a3ccb9c3e1d62100#2003-09-03 00:44:55#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//            TODO refactor to use a single getEvent(row) call, and use a Formatter interface for pluggable formatting#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//            TODO This could be done and look better in a custom Dialog#679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//              TODO search for Log4j config            #679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//                TODO handle if they don't choose a file#679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#main(String[])#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#-1#1.0#1.0#9.0#9.0#18.0#18.0#1.0#1.0#0.0#0.0#//    TODO remove this when ready#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#0cc749b722a851cd985cfaa98c143c9535355ff5#Refactored LogPanel into a standalone class instead of an inner class of LogUI.  More work needs to be done to remove dependencies, but at least it's a separate class now (good start).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateEntryMap(ChainsawEventBatchEntry)#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#0cc749b722a851cd985cfaa98c143c9535355ff5#2003-09-09 07:00:39#-1#-1#12.0#-1#19.0#-1#42.0#-1#3.0#-1#1.0#//        TODO fix up this Set Cast-O-Rama //also add it to the unique values list#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#554511eabc7fa964de70990882050bdd4ed73b5e#a large number of changes done as a further effort to decouple LogPanel from LogUI.  LogPanel now only needs a reference to the StatusBar, and this too can be eventually removed by replacing with a listener style framework. (coming soon).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateEntryMap(ChainsawEventBatchEntry)#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#0cc749b722a851cd985cfaa98c143c9535355ff5#2003-09-09 07:00:39#-1#-1#12.0#-1#19.0#-1#42.0#-1#3.0#-1#1.0#//          TODO MDC event stuff is not being output correctly#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#554511eabc7fa964de70990882050bdd4ed73b5e#a large number of changes done as a further effort to decouple LogPanel from LogUI.  LogPanel now only needs a reference to the StatusBar, and this too can be eventually removed by replacing with a listener style framework. (coming soon).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#mouseMoved(MouseEvent)#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#0cc749b722a851cd985cfaa98c143c9535355ff5#2003-09-09 07:00:39#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//			TODO refactor so that LogPanel itself knows if Tooltips are enabled#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#A large number of changes because of the move to the new Rule structure.#554511eabc7fa964de70990882050bdd4ed73b5e#a large number of changes done as a further effort to decouple LogPanel from LogUI.  LogPanel now only needs a reference to the StatusBar, and this too can be eventually removed by replacing with a listener style framework. (coming soon).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogPanel.java#propertyChange(PropertyChangeEvent)#adafc1e6d9bf474c6f666a2afd1f6c9a7f888692#2003-09-17 01:31:36#a1ce62d66f2977ac596df9c1b794cb62f153cd89#2004-01-19 07:11:42#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//			TODO need to work out how to suspend the DocumentChangeListener reFilter temporarily while this bit updates#adafc1e6d9bf474c6f666a2afd1f6c9a7f888692#[Possibly controversial]#f8d25ba4a3689d3c8e9aa06b4ef100113bcbd5f3#- reorganized logpanel - added complete javadoc comments, applied jalopy formatting, removed unused methods, reduced scope of variables and visibility of methods where possible - logpanel's tablemodel no longer exposed to other classes, added helper methods where needed - removed unused methods and renamed methods to clarify functionality - removed location from chainsaw's default eventdetail layout
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogPanel.java#mouseMoved(MouseEvent)#53a315279bd3541c2bcbece3a4a9d6ba5c5bcd7d#2003-09-26 08:16:27#94b1e818a9aab722aa1828ac8ec27b7d0515897c#2003-12-04 08:53:02#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//    TODO This is a Bug or something, but InputEvent.CTRL_DOWN_MASK only works // in JDK 1.4.2 when the LoggerTreePanel is open, if it is closed, it doesn't work... CTRL_DOWN_MASK // is ok though... Strange. Copied the mask from 1.4.2 here#53a315279bd3541c2bcbece3a4a9d6ba5c5bcd7d#Still trying to track down a bug in JDK 1.4.2 (I think it's only this version).#ac9e0003d5766df2f9f5b4052e3dd968911bd4fc#* Re-implemented support for 'refine focus on' text field on the log panel * Added support for multiple-word operands in expression rules (enclose operand in single quotes * New colorpanel layout with drop down color list and browse button - much smaller layout * Added mouse support for setting and adding event fields to the refine focus rule.
log4j#DESIGN#src/java/org/apache/log4j/NDC.java#lazyRemove()#26f8d8a8cd3f272b3fa5d912889207c64844aa61#2000-12-14 02:19:28#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#4.0#3.0#3.0#11.0#32.0#44.0#3.0#6.0#1.0#2.0#// The synchronization on ht is necessary to prevent JDK 1.2.x from // throwing ConcurrentModificationExceptions at us. This sucks BIG-TIME. // One solution is to write our own hashtable implementation.#26f8d8a8cd3f272b3fa5d912889207c64844aa61#initial Apache commit##
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer(MouseEvent)#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#1296787db5726686701f25ac30bd899bad914d47#2003-07-09 06:10:01#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//          TODO should also tidy up any other references to things... Might need to be able to recover this pane again...#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#ddd173fcdb476c83256f72efa862edfb0275dab5#New 'show tabs' menu added to the 'View' menu.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateDetailPane()#e932b0f81efea5a6372513e317a4e753c8335ed2#2003-06-25 04:05:24#cd4524d7e50644d9ea3a7b14a3ccb9c3e1d62100#2003-09-03 00:44:55#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//            TODO refactor to use a single getEvent(row) call, and use a Formatter interface for pluggable formatting#e932b0f81efea5a6372513e317a4e753c8335ed2#Chainsaw v2 has been promoted into the jakarta-log4j module.#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//            TODO This could be done and look better in a custom Dialog#679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//              TODO search for Log4j config            #679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#activateViewer()#679aa15746508e08c36a7b2e32463c8096a6a9b5#2003-06-29 22:57:55#75527ec29038aea09de07cb4798050a2ea7f60ce#2003-08-07 07:56:04#-1#28.0#28.0#34.0#34.0#295.0#291.0#6.0#6.0#0.0#0.0#//                TODO handle if they don't choose a file#679aa15746508e08c36a7b2e32463c8096a6a9b5#If there are no receivers defined after Log4j starts up, then the user is prompted for a decision.  They can now choose to search for a Log4j configuration file, be taken to the Receivers panel to enter them manually, or do nothing.#76c5f0f0ea04e508126eb052f3787b662ace594d#Hooked up the new No Receivers warning panel.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#main(String[])#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#ee31bda74f98d9758124ace66aaaa09b0a2c51ca#2003-09-19 03:56:56#-1#1.0#1.0#9.0#9.0#18.0#18.0#1.0#1.0#0.0#0.0#//    TODO remove this when ready#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#e839435777099eff5f45032f153d97aac6b871e7#When the Tutorial is kicked off, it is now located in a separate floating JFrame which resizes everything to sit next to the main GUI like a real help/tutorial should.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateEntryMap(ChainsawEventBatchEntry)#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//        TODO fix up this Set Cast-O-Rama //also add it to the unique values list#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#0cc749b722a851cd985cfaa98c143c9535355ff5#Refactored LogPanel into a standalone class instead of an inner class of LogUI.  More work needs to be done to remove dependencies, but at least it's a separate class now (good start).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#updateEntryMap(ChainsawEventBatchEntry)#0f5f5baf2d50a23710365d884520a4861df4b9b7#2003-09-03 05:50:01#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//          TODO MDC event stuff is not being output correctly#0f5f5baf2d50a23710365d884520a4861df4b9b7#* refactored Pause functionality#0cc749b722a851cd985cfaa98c143c9535355ff5#Refactored LogPanel into a standalone class instead of an inner class of LogUI.  More work needs to be done to remove dependencies, but at least it's a separate class now (good start).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#mouseMoved(MouseEvent)#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#2003-09-09 03:03:32#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#-1#//			TODO refactor so that LogPanel itself knows if Tooltips are enabled#3fd8fbc941ca5c9a9c2cc62361516784b54ff72d#A large number of changes because of the move to the new Rule structure.#0cc749b722a851cd985cfaa98c143c9535355ff5#Refactored LogPanel into a standalone class instead of an inner class of LogUI.  More work needs to be done to remove dependencies, but at least it's a separate class now (good start).
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#initPlugins()#765875de40b96ca5be0d2e96479a015dadd6a739#2003-12-31 07:03:34#cc7597a8064f4911ebad7bf599c963365dcb4526#2004-07-28 08:02:18#-1#1.0#3.0#3.0#11.0#19.0#31.0#1.0#2.0#0.0#1.0#// TODO this should all be in a config file#765875de40b96ca5be0d2e96479a015dadd6a739#moved some code within the acivation area into new methods.#d8530a7ba0a823db98022edabcc018e5864ab2a5#* Added Drag & Drop (rudimentary) support to Chainsaw.   You can drag any File to Chainsaw's   Tabbed Pane area and it will try to load it.  If there are no events in the file, not a lot happens...
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#initPlugins(PluginRegistry)#5f1358759db4a4bb599f835af6a13afc21d9565e#2004-05-15 06:32:44#4d735d9762e0acb248f97b2ac7b55a9ec3b0ac23#2005-01-02 09:51:40#-1#3.0#3.0#11.0#9.0#31.0#31.0#2.0#2.0#1.0#1.0#//    TODO this should also be fixed up, as VFS bits and pieces might not be built in an Ant build when they don't have all the VFS jars local#5f1358759db4a4bb599f835af6a13afc21d9565e#added tiny bit of code to start the VFS Plugin using reflection, if and only if the class can be found on the classpath.  This gets around conditions where VFS and it's dependencies are not available.#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/chainsaw/LogUI.java#initPlugins(PluginRegistry)#d8530a7ba0a823db98022edabcc018e5864ab2a5#2004-09-02 00:30:19#4d735d9762e0acb248f97b2ac7b55a9ec3b0ac23#2005-01-02 09:51:40#-1#3.0#3.0#9.0#9.0#31.0#31.0#2.0#2.0#1.0#1.0#// TODO this should all be in a config file //    ChainsawCentral cc = new ChainsawCentral(); //    pluginRegistry.addPlugin(cc); //    cc.activateOptions();#d8530a7ba0a823db98022edabcc018e5864ab2a5#* Added Drag & Drop (rudimentary) support to Chainsaw.   You can drag any File to Chainsaw's   Tabbed Pane area and it will try to load it.  If there are no events in the file, not a lot happens...#0c831191c19467e54fa8f30e640d8e41e4e99328#And with a click of her heals, Chainsaw v2 heads off home to Kansas.
log4j#DESIGN#src/java/org/apache/log4j/helpers/BoundedFIFO.java#resize(int)#80387e1d3e02134a8e24cb7d81b1ae6a7b3b6113#2001-01-23 22:07:43#95bd0fe7b9f2d37836d88d1c04aba0beeba8e921#2014-02-11 13:21:15#-1#10.0#9.0#7.0#7.0#36.0#38.0#4.0#4.0#1.0#1.0#// er.. how much do we actually need to copy? // We should not copy more than the actual number of elements.#80387e1d3e02134a8e24cb7d81b1ae6a7b3b6113#Added the BufferSize option to the AsyncAppender and updated UnitTestBoundedFIFO to test this new feature.##
